# Copyright (C) 2024, Qwen Team, Alibaba Group.
# This file is distributed under the same license as the Qwen package.
#
msgid ""
msgstr ""
"Project-Id-Version: Qwen \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-09-18 21:18+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.15.0\n"

#: ../../source/web_ui/text_generation_webui.md:1
#: 17cad91e01fe478c8304e95600efbea7
msgid "Text Generation Web UI"
msgstr "Text Generation Web UI"

#: ../../source/web_ui/text_generation_webui.md:3
#: 5530606755964168b3d726dc1bf248e3
msgid "[Text Generation Web UI](https://github.com/oobabooga/text-generation-webui) (TGW, or usually referred to \"oobabooga\") is a popular web UI for text generation, similar to[AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui). It has multiple interfaces, and supports multiple model backends, including"
msgstr "[Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)（简称TGW，通常被称为“oobabooga”）是一款流行的文本生成Web界面工具，类似于[AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)。它拥有多个交互界面，并支持多种模型后端，包括"

#: ../../source/web_ui/text_generation_webui.md:5
#: 447cb259b9a649cfa458710565600031
msgid "[Transformers](https://github.com/huggingface/transformers),"
msgstr ""

#: ../../source/web_ui/text_generation_webui.md:6
#: 0ba32dbfa6894cc99d9a70cbf86c9333
msgid "[llama.cpp](https://github.com/ggerganov/llama.cpp) (through [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)),"
msgstr "[llama.cpp](https://github.com/ggerganov/llama.cpp) (基于 [llama-cpp-python](https://github.com/abetlen/llama-cpp-python))"

#: ../../source/web_ui/text_generation_webui.md:7
#: e5d1810cdff842468536ec5bccfdae52
msgid "[ExLlamaV2](https://github.com/turboderp/exllamav2),"
msgstr ""

#: ../../source/web_ui/text_generation_webui.md:8
#: ed6d98a047e849b3b14f2b8f3c774e03
msgid "[AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ),"
msgstr ""

#: ../../source/web_ui/text_generation_webui.md:9
#: 4725d5b506434145ba5ea52d5806bbda
msgid "[AutoAWQ](https://github.com/casper-hansen/AutoAWQ),"
msgstr ""

#: ../../source/web_ui/text_generation_webui.md:10
#: 5fa93219aac44485a45e98dbfe405e9d
msgid "[GPTQ-for-LLaMa](https://github.com/qwopqwop200/GPTQ-for-LLaMa),"
msgstr ""

#: ../../source/web_ui/text_generation_webui.md:11
#: bff38627d3554a83ab3cd937f45e59e1
msgid "[CTransformers](https://github.com/marella/ctransformers),"
msgstr ""

#: ../../source/web_ui/text_generation_webui.md:12
#: 446e92782d9847158b60c74dad44a0bf
msgid "[QuIP#](https://github.com/Cornell-RelaxML/quip-sharp)."
msgstr ""

#: ../../source/web_ui/text_generation_webui.md:14
#: eaccef4a87e94072856ae0b65da5a4b9
msgid "In this section, we introduce how to run Qwen locally with TGW."
msgstr "在本节中，我们将介绍如何在本地环境中使用TGW运行Qwen。"

#: ../../source/web_ui/text_generation_webui.md:16
#: 26bce3f84a574b0091802f7ed3d04694
msgid "Quickstart"
msgstr "快速开始"

#: ../../source/web_ui/text_generation_webui.md:18
#: 35a47bc0147e43329284d5d20281cfe1
msgid "The simplest way to run TGW is to use the provided shell scripts in the [repo](https://github.com/oobabooga/text-generation-webui).  For the first step, clone the repo and enter the directory:"
msgstr "最简单的运行TGW（Text Generation WebUI）的方法是使用 [repo](https://github.com/oobabooga/text-generation-webui) 中提供的Shell脚本。首先，克隆repo并进去文件夹中："

#: ../../source/web_ui/text_generation_webui.md:26
#: 0ff92b4b26e74df8a26f4a39c5f0036e
msgid "You can directly run the `start_linux.sh`, `start_windows.bat`, `start_macos.sh`, or `start_wsl.bat` script depending on your OS. Alternatively you can manually install the requirements in your conda environment. Here I take the practice on MacOS as an example:"
msgstr "你可以根据你的操作系统直接运行相应的脚本，例如在Linux系统上运行 `start_linux.sh` ，在Windows系统上运行 `start_windows.bat` ，在MacOS系统上运行 `start_macos.sh` ，或者在Windows子系统Linux（WSL）上运行 `start_wsl.bat` 。另外，你也可以选择手动在conda环境中安装所需的依赖项。这里以MacOS系统为例进行实践操作。"

#: ../../source/web_ui/text_generation_webui.md:36
#: 9046c24b86b84dfc8844f1d10ae64146
msgid "Then you can install the requirements by running `pip install -r` based on your OS, e.g.,"
msgstr "接下来，您可以根据您的操作系统执行 `pip install -r` 命令来安装相应的依赖项，例如，"

#: ../../source/web_ui/text_generation_webui.md:42
#: 47fc55c698fc4ecb9d69ef8d1c2823a0
msgid "For `bitsandbytes` and `llama-cpp-python` inside the requirements, I advise you to install them through `pip` directly.  After finishing the installation of required packages, you need to prepare your models by putting the model files or directories in the folder `./models`. For example, you should put the transformers model directory of `Qwen2.5-7B-Instruct` in the way shown below:"
msgstr "对于requirements中的 `bitsandbytes` 和 `llama-cpp-python` ，我建议您直接通过 `pip` 进行安装。在完成所需包的安装之后，您需要准备模型，将模型文件或目录放在 `./models` 文件夹中。例如，您应按照以下方式将 `Qwen2.5-7B-Instruct` 的transformers模型目录放置到相应位置。"

#: ../../source/web_ui/text_generation_webui.md:62
#: 31ddc7d4ebe6407e9eaa8bd81584e61e
msgid "Then you just need to run"
msgstr "随后你需要运行"

#: ../../source/web_ui/text_generation_webui.md:68
#: 3f094e9fb18d42e7b3fcb602587335fb
msgid "to launch your web UI service. Please browse to"
msgstr "来启动你的网页服务。请点击进入"

#: ../../source/web_ui/text_generation_webui.md:74
#: 9f94b143bc72437e91713b52b51d46db
msgid "and enjoy playing with Qwen in a web UI!"
msgstr "然后享受使用Qwen的Web UI吧！"

#: ../../source/web_ui/text_generation_webui.md:76
#: a86604d7409944bfb2e45b55bffc8532
msgid "Next Step"
msgstr "下一步"

#: ../../source/web_ui/text_generation_webui.md:78
#: a79b8e62f0fb489ab2c58042c94b8d60
msgid "There are a lot more usages in TGW, where you can even enjoy role play, use different types of quantized models, train LoRA, incorporate extensions like stable diffusion and whisper, etc.  Go to figure out more advanced usages and apply them to Qwen models!"
msgstr "TGW 中包含了许多更多用途，您甚至可以在其中享受角色扮演的乐趣，并使用不同类型的量化模型。您可以训练诸如LoRA这样的算法，并将Stable Diffusion和Whisper等扩展功能纳入其中。赶快去探索更多高级用法，并将它们应用于Qwen模型中吧！"


