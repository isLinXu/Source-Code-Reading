<p align="left">
   <a href="README.md">English</a>  ï½œ ä¸­æ–‡</a>&nbsp
</p>
<br><br>

<p align="center">
 <img src="https://dscache.tencent-cloud.cn/upload/uploader/hunyuan-64b418fd052c033b228e04bc77bbc4b54fd7f5bc.png" width="400"/> <br>
</p><p></p>

<p align="center">
    ğŸ«£&nbsp<a href="https://huggingface.co/tencent/Tencent-Hunyuan-Large"><b>Hugging Face</b></a>&nbsp&nbsp |  &nbsp&nbspğŸ–¥ï¸&nbsp&nbsp<a href="https://llm.hunyuan.tencent.com/" style="color: red;"><b>å®˜ç½‘</b></a>&nbsp&nbspï½œ&nbsp&nbspğŸ•–&nbsp&nbsp <a href="https://cloud.tencent.com/product/hunyuan" ><b>æ··å…ƒAPI</b></a>ï½œ&nbsp&nbspğŸ³&nbsp&nbsp <a href="https://gitee.com/Tencent/Tencent-Hunyuan-Large" ><b>Gitee</b></a>
</p><p align="center">
    <a href="https://arxiv.org/abs/2411.02265" style="color: red;"><b>æŠ€æœ¯æŠ¥å‘Š</b></a>&nbsp&nbspï½œ&nbsp&nbsp <a href="https://huggingface.co/spaces/tencent/Hunyuan-Large"><b>Demo</b></a>&nbsp&nbsp&nbspï½œ&nbsp&nbsp <a href="https://cloud.tencent.com/document/product/851/112032" style="color: red;"><b>Tencent Cloud TI</b></a>&nbsp&nbsp&nbsp</p>



## æ¨¡å‹ä»‹ç»

éšç€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’Œç§‘å­¦ä»»åŠ¡ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œéšç€æ¨¡å‹è§„æ¨¡çš„æ‰©å¤§ï¼Œå¦‚ä½•åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ä¼˜åŒ–èµ„æºæ¶ˆè€—æˆä¸ºä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Œå½“å‰äº®ç›¸çš„Hunyuan-Largeï¼ˆHunyuan-MoE-A52Bï¼‰æ¨¡å‹ï¼Œè¿™æ˜¯ç›®å‰ä¸šç•Œå·²ç»å¼€æºçš„åŸºäºTransformerçš„æœ€å¤§MoEæ¨¡å‹ï¼Œæ‹¥æœ‰3890äº¿æ€»å‚æ•°å’Œ520äº¿æ¿€æ´»å‚æ•°ã€‚

æœ¬æ¬¡é€šè¿‡å¼€æºHunyuan-Largeçš„æŠ€æœ¯æˆæœï¼Œæˆ‘ä»¬å¸Œæœ›æ¿€å‘æ›´å¤šç ”ç©¶è€…çš„åˆ›æ–°çµæ„Ÿï¼Œå…±åŒæ¨åŠ¨AIæŠ€æœ¯çš„è¿›æ­¥å’Œåº”ç”¨ã€‚æ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„å¼€æºç¤¾åŒºï¼Œå…±åŒæ¢ç´¢å’Œä¼˜åŒ–æœªæ¥çš„AIæ¨¡å‹ï¼

### æŠ€æœ¯ä¼˜åŠ¿ä»‹ç»

#### æ¨¡å‹  
- **é«˜è´¨é‡åˆæˆæ•°æ®**ï¼šé€šè¿‡åˆæˆæ•°æ®å¢å¼ºè®­ç»ƒï¼ŒHunyuan-Largeèƒ½å¤Ÿå­¦ä¹ åˆ°æ›´ä¸°å¯Œçš„è¡¨ç¤ºï¼Œå¤„ç†é•¿ä¸Šä¸‹æ–‡è¾“å…¥ï¼Œå¹¶æ›´å¥½åœ°æ³›åŒ–åˆ°æœªè§æ•°æ®

- **KVç¼“å­˜å‹ç¼©**ï¼šé‡‡ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGQAï¼‰å’Œè·¨å±‚æ³¨æ„åŠ›ï¼ˆCLAï¼‰ç­–ç•¥ï¼Œæ˜¾è‘—å‡å°‘äº†KVç¼“å­˜çš„å†…å­˜å ç”¨å’Œè®¡ç®—å¼€é”€ï¼Œæé«˜äº†æ¨ç†åå

- **ä¸“å®¶ç‰¹å®šå­¦ä¹ ç‡ç¼©æ”¾**ï¼šä¸ºä¸åŒä¸“å®¶è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡ï¼Œç¡®ä¿æ¯ä¸ªå­æ¨¡å‹éƒ½èƒ½æœ‰æ•ˆåœ°ä»æ•°æ®ä¸­å­¦ä¹ ï¼Œå¹¶ä¸ºæ•´ä½“æ€§èƒ½åšå‡ºè´¡çŒ®

- **é•¿ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›**ï¼šé¢„è®­ç»ƒæ¨¡å‹æ”¯æŒé«˜è¾¾256Kçš„æ–‡æœ¬åºåˆ—ï¼ŒInstructæ¨¡å‹æ”¯æŒ128Kçš„æ–‡æœ¬åºåˆ—ï¼Œæ˜¾è‘—æå‡äº†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡çš„å¤„ç†èƒ½åŠ›

- **å¹¿æ³›çš„åŸºå‡†æµ‹è¯•**ï¼šåœ¨å¤šç§è¯­è¨€å’Œä»»åŠ¡ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒï¼ŒéªŒè¯äº†Hunyuan-Largeçš„å®é™…åº”ç”¨æ•ˆæœå’Œå®‰å…¨æ€§

#### æ¨ç†æ¡†æ¶
- Hunyuan-Largeæ¨¡å‹æ”¯æŒ TRT-LLM-backend å’Œ [vLLM-backend](https://github.com/quinnrong94/vllm/tree/dev_hunyuan) æ¨ç†æ¡†æ¶ã€‚æˆ‘ä»¬åœ¨å¼€æºæ¡†æ¶çš„åŸºç¡€ä¸Šé€‚é…äº†Hunyuan-Largeæ¨¡å‹ï¼Œè­¬å¦‚ï¼Œæ–°å¢çš„CLAç»“æ„å¯ä»¥å¾ˆå¤§ç¨‹åº¦èŠ‚çº¦æ˜¾å­˜(KV-Cacheéƒ¨åˆ†èŠ‚çœ50%)ï¼Œä¿éšœè¶…é•¿æ–‡æœ¬åœºæ™¯ã€‚æ­¤å¤–é€šè¿‡FP8çš„é‡åŒ–ä¼˜åŒ–ï¼Œç›¸æ¯”FP16/BF16å¸¸è§„é‡åŒ–ï¼Œåœ¨æœ€å¤§é™åº¦ä¿éšœç²¾åº¦çš„æ¡ä»¶ä¸‹ï¼ŒèŠ‚çœ50%æ˜¾å­˜ï¼Œååæå‡70%ã€‚åŒæ—¶ï¼ŒåŸºäºTRT-LLMçš„åº•å±‚é«˜æ•ˆç®—å­ï¼Œå…¶æ€§èƒ½ç›¸æ¯”vLLMæå‡30%ä»¥ä¸Šï¼Œç›®å‰TRT-LLMæ–¹æ¡ˆåœ¨è…¾è®¯æ··å…ƒé¡¹ç›®å¹¿æ³›ä½¿ç”¨ã€‚æœ¬æ¬¡ä¼˜å…ˆå¼€æºvLLMæ¡†æ¶ï¼ŒTRT-LLMå°†åœ¨è¿‘æœŸæ¨å‡ºã€‚

#### è®­ç»ƒæ¡†æ¶
- Hunyuan-Largeå¼€æºæ¨¡å‹å·²ç»æ”¯æŒhuggingfaceæ ¼å¼ï¼Œæ”¯æŒç”¨æˆ·é‡‡ç”¨hf-deepspeedæ¡†æ¶è¿›è¡Œæ¨¡å‹ç²¾è°ƒï¼Œ åŒæ—¶æˆ‘ä»¬ä¹Ÿæ”¯æŒåˆ©ç”¨flash-attnè¿›è¡Œè®­ç»ƒåŠ é€Ÿï¼Œä¸ºæ­¤ï¼Œæˆ‘ä»¬æŠŠç›¸å…³çš„è®­ç»ƒè„šæœ¬å’Œæ¨¡å‹å®ç°ä¹Ÿå¼€æ”¾ç»™åˆ°ç¤¾åŒºï¼Œæ–¹ä¾¿ç ”å‘è€…åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œåç»­çš„æ¨¡å‹è®­ç»ƒå’Œç²¾è°ƒçš„æ“ä½œ

&nbsp;

## æ–°é—»
* 2024.11.25 æˆ‘ä»¬è‡ªä¸»å¼€å‘çš„é•¿ä¸Šä¸‹æ–‡è¯„ä¼°é›†â€”â€”PenguinScrollsï¼Œå·²ç»æ­£å¼å‘å¸ƒï¼è¯¦è§[GitHub](https://github.com/Penguin-Scrolls/PenguinScrolls)å’Œ [Hugging Face](https://huggingface.co/datasets/Penguin-Scrolls/PenguinScrolls)ã€‚  
* 2024.11.20 **Hunyuan-A52B-Instruct** å’Œ**Hunyuan-A52B-Instruct-FP8**æ¨¡å‹æƒé‡æ›´æ–°ã€‚
* 2024.11.5 [TIå¹³å°](https://cloud.tencent.com/product/ti) å·²ç»é›†æˆäº†Hunyuan-Largeæ¨¡å‹ï¼Œæ‚¨åªéœ€å‡ æ­¥å³å¯è½»æ¾è¿›è¡Œè®­ç»ƒå’Œéƒ¨ç½²ã€‚è®¿é—® [Chat with Hunyuan-Large](https://console.cloud.tencent.com/tione/v2/aimarket/detail/hunyuan_series?PublicAlgoGroupId=hunyuan-large-chat&detailTab=demo) ä¸æ¨¡å‹çš„å®æ—¶å¯¹è¯ï¼Œå¹¶åœ¨TIä¸Šæ¢ç´¢ [Hunyuan-Large Best Practice on TI](https://cloud.tencent.com/document/product/851/112032) å¹¶åˆ›å»ºè‡ªå·±çš„å®šåˆ¶åŒ–Hunyuan-Largeã€‚
* 2024.11.5 æˆ‘ä»¬åœ¨Hugging Faceå¼€æºäº†**Hunyuan-A52B-Pretrain** ã€ **Hunyuan-A52B-Instruct** å’Œ**Hunyuan-A52B-Instruct-FP8**ã€‚å¹¶å‘å¸ƒäº†æŠ€æœ¯æŠ¥å‘Šå’Œè®­ç»ƒæ¨ç†æ“ä½œæ‰‹å†Œï¼Œè¯¦ç»†ä»‹ç»äº†æ¨¡å‹èƒ½åŠ›å’Œè®­ç»ƒä¸æ¨ç†çš„æ“ä½œã€‚
<br>


## Benchmarkè¯„ä¼°æ¦œå• 

**Hunyuan-Large é¢„è®­ç»ƒæ¨¡å‹**ä¸å…·æœ‰ç›¸ä¼¼æ¿€æ´»å‚æ•°å¤§å°çš„Denseå’ŒMoEç«äº‰å¯¹æ‰‹ç›¸æ¯”ï¼Œå®ç°äº†æœ€ä½³çš„æ•´ä½“æ€§èƒ½ã€‚
å¯¹äºMMLUã€MMLU-proã€CMMLUç­‰åŸºå‡†è¯„æµ‹ï¼ŒHunyuan-Largeçš„æ€§èƒ½å§‹ç»ˆä¿æŒåœ¨æœ€ä½³æ°´å‡†ï¼Œè¯å®äº†å®ƒåœ¨èšåˆä»»åŠ¡ä¸Šçš„ç»¼åˆèƒ½åŠ›ã€‚
Hunyuan-Largeåœ¨å¸¸è¯†ç†è§£å’Œæ¨ç†ä»¥åŠç»å…¸çš„NLPä»»åŠ¡ï¼Œå¦‚QAå’Œé˜…è¯»ç†è§£ä»»åŠ¡ï¼ˆCommonsenseQAï¼Œ PIQAï¼Œå’ŒTriviaQAï¼‰æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰²ã€‚
åœ¨æ•°å­¦èƒ½åŠ›æ–¹é¢ï¼ŒHunyuan-Largeåœ¨GSM8Kå’ŒMathæ•°å­¦æ•°æ®é›†ä¸Šä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œåœ¨CMATHä¸­æ–‡æ•°æ®é›†ä¸Šä¹Ÿå–å¾—äº†æœ€å¥½çš„æˆç»©ã€‚
åŒæ—¶æˆ‘ä»¬è§‚å¯Ÿåˆ°Hunyuan-Largeåœ¨æ‰€æœ‰ä¸­æ–‡ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼ŒCMMLU, C-Evalï¼‰ä¸­å®ç°äº†æ•´ä½“æœ€ä½³çš„æ€§èƒ½ã€‚


| Model            | LLama3.1-405B | LLama3.1-70B | Mixtral-8x22B | DeepSeek-V2 | Hunyuan-Large |
|------------------|---------------|--------------|---------------|-------------|---------------|
| MMLU             | 85.2          | 79.3         | 77.8          | 78.5        | **88.4**          |
| MMLU-Pro         | **61.6**          | 53.8         | 49.5          | -           | 60.2          |
| BBH              | 85.9          | 81.6         | 78.9          | 78.9        | **86.3**          |
| HellaSwag        | -             | -            | **88.7**      | 87.8        | 86.8          |
| CommonsenseQA    | 85.8          | 84.1         | 82.4          | -           | **92.9**          |
| WinoGrande       | 86.7          | 85.3         | 85.0          | 84.9        | **88.7**          |
| PIQA             | -             | -            | 83.6          | 83.7        | **88.3**          |
| NaturalQuestions | -             | -            | 39.6          | 38.7        | **52.8**          |
| DROP             | 84.8          | 79.6         | 80.4          | 80.1        | **88.9**          |
| ARC-C            | **96.1**          | 92.9         | 91.2          | 92.4        | 95.0          |
| TriviaQA         | -             | -            | 82.1          | 79.9        | **89.2**          |
| CMMLU            | -             | -            | 60.0          | 84.0        | **90.2**          |
| C-Eval           | -             | -            | 59.6          | 81.7        | **91.9**          |
| C3               | -             | -            | 71.4          | 77.4        | **82.3**          |
| GSM8K            | 89.0          | 83.7         | 83.7          | 79.2        | **92.8**          |
| MATH             | 53.8          | 41.4         | 42.5          | 43.6        | **69.8**          |
| CMATH            | -             | -            | 72.3          | 78.7        | **91.3**          |
| HumanEval        | 61.0          | 58.5         | 53.1          | 48.8        | **71.4**          |
| MBPP             | **73.4**          | 68.6         | 64.2          | 66.6        | 72.6          |

**Hunyuan-Large-Instruct**ä¸å…·æœ‰ç›¸ä¼¼æ¿€æ´»å‚æ•°çš„llmç›¸æ¯”åœ¨å¤§å¤šæ•°çš„ä»»åŠ¡ä¸Šå®ç°äº†ä¸€è‡´çš„æ€§èƒ½æå‡ï¼Œè¡¨æ˜æˆ‘ä»¬çš„post-trainingååˆ†æœ‰æ•ˆã€‚
åœ¨ä¸åŒç±»åˆ«çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å‘ç°æˆ‘ä»¬çš„Instructæ¨¡å‹åœ¨MMLUå’ŒMATHæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å¥½çš„æ€§èƒ½ã€‚
å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨MMLUæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¡¨ç°å‡ºäº†æ˜¾è‘—çš„æå‡ï¼Œ ç›¸æ¯”ä¸LLama3.1-405Bæ¨¡å‹é«˜å‡º2.6%ã€‚
è¿™ç§å¢å¼ºè¡¨æ˜Hunyuan-Large-Instructåœ¨å¹¿æ³›çš„è¯­è¨€ç†è§£ä»»åŠ¡ä¸­å…·æœ‰ä¼˜è¶Šçš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚
è¯¥æ¨¡å‹åœ¨MATHæ•°æ®é›†ä¸Šçš„è¡¨ç°è¿›ä¸€æ­¥å¼ºè°ƒäº†å®ƒçš„å®åŠ›ï¼Œç›¸æ¯”äºLLama3.1-405Bé«˜å‡ºäº†3.6%çš„æŒ‡æ ‡ã€‚
å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä»…ç”¨520äº¿ä¸ªæ¿€æ´»å‚æ•°å°±å®ç°äº†ç²¾åº¦çš„é£è·ƒï¼Œè¯æ˜äº†Hunyuan-Large-Instructçš„å“è¶Šèƒ½åŠ›ã€‚

| Model                | LLama3.1 405B Inst. | LLama3.1 70B Inst. | Mixtral 8x22B Inst. | DeepSeekV2.5 Chat | Hunyuan-Large Inst. |
|----------------------|---------------------|--------------------|---------------------|-------------------|---------------------|
| MMLU                 | 87.3                | 83.6               | 77.8                | 80.4              | **89.9**            |
| CMMLU                | -                   | -                  | 61.0                | -                 | **90.4**            |
| C-Eval               | -                   | -                  | 60.0                | -                 | **88.6**            |
| BBH                  | -                   | -                  | 78.4                | 84.3              | **89.5**            |
| HellaSwag            | -                   | -                  | 86.0                | **90.3**          | 88.5                |
| ARC-C                | **96.9**            | 94.8               | 90.0                | -                 | 94.6                |
| GPQA_diamond         | **51.1**            | 46.7               | -                   | -                 | 42.4                |
| MATH                 | 73.8                | 68.0               | 49.8                | 74.7              | **77.4**            |
| HumanEval            | 89.0                | 80.5               | 75.0                | 89.0              | **90.0**            |
| AlignBench           | 6.0                 | 5.9                | 6.2                 | 8.0               | **8.3**             |
| MT-Bench             | 9.1                 | 8.8                | 8.1                 | 9.0               | **9.4**             |
| IFEval strict-prompt | **86.0**            | 83.6               | 71.2                | -                 | 85.0                |
| Arena-Hard |  69.3            | 55.7               |  -                | 76.2                 | **81.8**            |
| AlpacaEval-2.0 | 39.3            | 34.3               | 30.9                | 50.5                 | **51.8**            |

&nbsp;
## æ•°æ®

Hunyuan-Largeæä¾›äº†æ¨¡å‹è®­ç»ƒç›¸å…³æµç¨‹ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤ç« èŠ‚å¯¹è®­ç»ƒæ•°æ®æ ¼å¼è¿›è¡Œå¤„ç†ä»¥ä¾›æ¨¡å‹è®­ç»ƒä½¿ç”¨ã€‚

### è®­ç»ƒæ•°æ®æ ¼å¼åŠå¤„ç† 

è®­ç»ƒæ•°æ®æŒ‰ç…§ä»¥ä¸‹å½¢å¼å¤„ç†ä¸ºmessagesæ ¼å¼ï¼Œè®­ç»ƒå’Œæ¨ç†çš„é»˜è®¤system promptä¸º"You are a helpful assistant."ï¼Œä»¥ä¸‹åˆ†åˆ«ä¸ºå•è½®æ•°æ®å’Œå¤šè½®æ•°æ®æ ·ä¾‹ï¼š

```python
# å•è½®æ•°æ®æ ¼å¼
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "æµ·æ°´ä¸ºä»€ä¹ˆæ˜¯å’¸çš„" },
    {"role": "assistant", "content": "æµ·æ°´æ˜¯å’¸çš„ä¸»è¦æ˜¯å› ä¸ºå…¶ä¸­å«æœ‰è®¸å¤šæº¶è§£åœ¨æ°´ä¸­çš„ç›ç±»å’ŒçŸ¿ç‰©è´¨ã€‚è¿™äº›ç›ç±»å’ŒçŸ¿ç‰©è´¨æ¥è‡ªäºåœ°çƒè¡¨é¢çš„å²©çŸ³å’ŒåœŸå£¤ä¸­çš„åŒ–å­¦ç‰©è´¨ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œå®ƒä»¬è¢«å¸¦åˆ°äº†æµ·æ´‹ä¸­ã€‚å½“æµ·æ°´è’¸å‘æ—¶ï¼Œæ°´åˆ†è’¸å‘æ‰äº†ï¼Œä½†ç›ç±»å’ŒçŸ¿ç‰©è´¨ä»ç„¶ç•™åœ¨æ°´ä¸­ï¼Œå¯¼è‡´æµ·æ°´å˜å¾—æ›´åŠ å’¸å‘³ã€‚å› æ­¤ï¼Œæµ·æ°´çš„å’¸åº¦æ˜¯ç”±å…¶ä¸­çš„ç›ç±»å’ŒçŸ¿ç‰©è´¨çš„å«é‡å†³å®šçš„ã€‚"}
]

# å¤šè½®æ•°æ®æ ¼å¼
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "çŸ¥é“é‡åº†æ£®æ—è¿™éƒ¨ç”µå½±å—ï¼Ÿ" },
    {"role": "assistant", "content": "çŸ¥é“å‘€ï¼Œæ˜¯ä¸€éƒ¨ç”±ç‹å®¶å«å¯¼æ¼”çš„ç‰‡å­ã€‚" },
    {"role": "user", "content": " è€Œä¸»æ¼”é‡Œæ›´æ˜¯æœ‰ç‹è²ï¼Œä¸€ä¸Šæ˜ ä¾¿å—åˆ°è¿½æ§ã€‚" },
    {"role": "assistant", "content": "æ‰€ä»¥æ­¤ç‰‡è·å¾—äº†ç¬¬14å±Šé¦™æ¸¯ç”µå½±é‡‘åƒå¥–æœ€ä½³å½±ç‰‡å¥–ã€‚"}
]

from tokenizers import ByteLevelBPETokenizer
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("./models", use_fast=False, trust_remote_code=True)

ids = tokenizer.apply_chat_template(messages)

```

æ›´å¤šè°ƒç”¨å‚è€ƒå‚è€ƒ`./models/test.py`æ–‡ä»¶ã€‚


&nbsp;

## å¿«é€Ÿå¼€å§‹

æ‚¨å¯ä»¥å‚ç…§<a href="examples/README.md">å¿«é€Ÿå¼€å§‹æ–‡æ¡£</a>ä¸­çš„å†…å®¹è¿›è¡Œå¿«é€Ÿä¸Šæ‰‹ã€‚

## æ¨¡å‹è®­ç»ƒ 

ä¸ºäº†ç®€åŒ–éƒ¨ç½²è¿‡ç¨‹ï¼ŒHunyuanLLMæä¾›äº†é¢„æ„å»ºdockeré•œåƒï¼š
 [hunyuaninfer/hunyuan-large](https://hub.docker.com/repository/docker/hunyuaninfer/hunyuan-large/general) ã€‚

### ç¡¬ä»¶éœ€æ±‚

ç»è¿‡åœ¨ H20 ä¸Šæµ‹è¯•ï¼Œä¸å¼€ make_moe_param_leaf_module ä»¥åŠ zero3+offloadï¼Œmax_seq_length ä¸º 2048ï¼Œå…¨é‡å¾®è°ƒæœ€å°‘éœ€è¦ 32 å¡ï¼Œlora å¾®è°ƒæœ€å°‘éœ€è¦ 8 å¡ã€‚

### è®­ç»ƒæ€§èƒ½

æœ€ä½é…ç½®ï¼ˆ8 å¡ lora ç²¾è°ƒï¼‰æµ‹è¯•ä¸‹ï¼Œper_device_train_batch_size ä¸º 1ï¼Œgradient_accumulation_steps ä¸º 1ï¼Œå¤§çº¦ 35s ä¸€ä¸ª iterationã€‚

### å¯åŠ¨æ–¹å¼

å‚è€ƒï¼š[HuggingFace Transformers Trainer](https://huggingface.co/docs/transformers/v4.19.2/en/main_classes/trainer)

#### å•æœºå¯åŠ¨è®­ç»ƒ

åœ¨`train`ç›®å½•ä¸‹ï¼Œæ‰§è¡Œï¼š

```sh
pip install -r requirements.txt
bash train.sh
```

#### å¤šæœºå¯åŠ¨è®­ç»ƒ

å¦‚æœè¦ç”¨å¤šå°æœºå™¨å¯åŠ¨è®­ç»ƒï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ‰§è¡Œï¼Œå¹¶ä¿è¯å¤šå°æœºå™¨åœ¨ä¸€ä¸ªé›†ç¾¤å†…ã€‚

##### é…ç½®æœºå™¨é—´å…å¯† ssh ç™»å½•

ä»¥ä¸‹æ“ä½œä»¥ä¸¤ä¸ªæœºå™¨ä¸ºä¾‹ï¼Œä¸¤å°æœºå™¨çš„ ip åˆ†åˆ«ä»¥`${ip1}`å’Œ`${ip2}`æ ‡è¯†ï¼Œä»¥ä¸‹æ“ä½œå‡åœ¨ docker container å†…æ‰§è¡Œã€‚

é¦–å…ˆï¼Œé…ç½®å¤šæœºcontainerå…å¯†ï¼Œåœ¨æ¯å°æœºå™¨ä¸Šæ‰§è¡Œã€‚

```sh
ssh-keygen			# ç”Ÿæˆid_rsaå’Œid_rsa.pubï¼Œç”¨äºå…å¯†ç™»å½•
ssh-keygen -t rsa -A    # ç”Ÿæˆ/etc/ssh/ssh_host_rsa_keyå’Œssh_host_ecdsa_keyï¼Œ ç”¨äºåé¢å¯åŠ¨ssh listen
/usr/sbin/sshd -p 36005 -o ListenAddress=0.0.0.0        # å¯åŠ¨Listen
echo "Port 36005" > ~/.ssh/config   # ssh è¿æ¥ç«¯å£ä¿®æ”¹ä¸º 36005
passwd root    # éœ€è¦é…ç½®rootå¯†ç ï¼Œå¦åˆ™ç›‘æµ‹å¹³å°ä¼šæŠ¥è­¦
```

æ³¨æ„ï¼šè¿™é‡Œçš„`36005`æ˜¯ä¸€ä¸ªç¤ºä¾‹ç«¯å£ï¼Œå¯ä»¥é€‰ç”¨ä»»æ„ç«¯å£ï¼Œä½†éœ€è¦ä¿è¯ä½¿ç”¨çš„ç«¯å£**å¼€æ”¾**ä¸”**ä¸è¢«å…¶ä»–çš„è¿›ç¨‹å ç”¨**ã€‚

æ¥ä¸‹æ¥ï¼Œåœ¨æ¯å°æœºå™¨çš„ container å†…ï¼Œæ‰§è¡Œï¼š

```sh
cat ~/.ssh/id_rsa.pub
```

**å°†è¾“å‡ºçš„ ssh å…¬é’¥å¤åˆ¶å¹¶ç²˜è´´åˆ°`~/.ssh/authorized_keys`æ–‡ä»¶ä¸­ï¼Œæ¯è¡Œä¸€ä¸ªå…¬é’¥ï¼Œæ¯å°æœºå™¨ä¸Šéƒ½è¦åšè¿™ä¸ªæ“ä½œ**ã€‚æœ€ç»ˆæ¯å°æœºå™¨ä¸Šçš„`~/.ssh/authorized_keys`æ–‡ä»¶å†…å®¹åº”å½“æ˜¯ä¸€è‡´çš„ï¼Œå¹¶ä¸”åŒ…å«äº†æ‰€æœ‰æœºå™¨çš„å…¬é’¥ã€‚

éœ€è¦æ³¨æ„ï¼Œå¤šèŠ‚ç‚¹è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šæ‰§è¡Œçš„ä»£ç éƒ½å¾—ä¸€è‡´ï¼Œå»ºè®®æŒ‚è½½ä¸€ä¸ªå…±äº«çš„ç½‘ç»œç›˜ï¼Œå¦‚æœæ— æ³•æŒ‚è½½å…±äº«ç½‘ç›˜ï¼Œåˆ™éœ€è¦æ‰‹åŠ¨å°†æ•°æ®é›†ã€è„šæœ¬ã€ä»£ç å¤åˆ¶åœ¨å¤šå°æœºå™¨çš„ç›¸åŒç›®å½•ä¸‹ã€‚

##### å¯åŠ¨å¤šæœºè®­ç»ƒ

åœ¨ä»¥ä¸Šå‡†å¤‡æ­¥éª¤å‡†å¤‡å¥½äº†ä¹‹åï¼Œä»¥åŠç¡®è®¤ä¾èµ–å·²ç»å®‰è£…å®Œæˆï¼ˆå¦‚æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œ`pip install -r requirements.txt`å®‰è£…ï¼‰ï¼Œå°±å¯ä»¥åœ¨`train.sh`ä¸­çš„å¼€å¤´å¢åŠ ä»¥ä¸‹é…ç½®ï¼š

```shell
export HOST_GPU_NUM=8
# å½“å‰æœºå™¨ip
export LOCAL_IP=${ip1}
# å¤šèŠ‚ç‚¹æœºå™¨ipï¼Œé€—å·éš”å¼€
export NODE_IP_LIST="${ip1}:8,${ip2}:8"
# æœºå™¨èŠ‚ç‚¹ä¸ªæ•°
export NODES=2
export NODE_NUM=$((${NODES} * ${HOST_GPU_NUM}))
```

æ³¨æ„ï¼šå°†ä»¥ä¸Šçš„`${ip1}`å’Œ`${ip2}`æ›¿æ¢ä¸ºçœŸå®çš„ ip åœ°å€ï¼

ç„¶åï¼Œåœ¨`${ip1}`çš„æœºå™¨ä¸Šï¼Œåœ¨`train/`ç›®å½•ä¸‹ï¼Œæ‰§è¡Œ`bash train.sh`å³å¯ï¼Œæ³¨æ„ç¬¬ä¸€æ¬¡å¯åŠ¨æ—¶å¯èƒ½ä¼šçœ‹è§ä»¥ä¸‹çš„è¾“å‡ºï¼š

```ssh
The authenticity of host '[ip]:36005 ([ip]:36005)' can't be established.
ECDSA key fingerprint is xxxxxx.
ECDSA key fingerprint is MD5:xxxxxx.
Are you sure you want to continue connecting (yes/no)?
```

æ­¤æ—¶è¾“å…¥`yes`å³å¯ç»§ç»­ã€‚

##### å…³é”®å‚æ•°

è„šæœ¬ä¸­çš„å…³é”®å‚æ•°å¦‚ä¸‹ï¼š

- `--deepspeed`: æ­¤å‚æ•°åº”å½“æŒ‡å‘ä¸€ä¸ª deepspeed çš„é…ç½®æ–‡ä»¶ï¼Œ`train`æ–‡ä»¶å¤¹ä¸‹æä¾›äº†ä¸‰ç§ DeepSpeed çš„é»˜è®¤é…ç½®æ–‡ä»¶ï¼š`ds_zero2_no_offload.json`, `ds_zero3_no_offload.json`, `ds_zero3_offload.json`ï¼Œè¿™ä¸‰ä¸ªé…ç½®æ–‡ä»¶æ‰€éœ€æ˜¾å­˜ä¾æ¬¡å‡å°‘
- `--model_name_or_path`: è¦åŠ è½½çš„ HF é¢„è®­ç»ƒæ¨¡å‹æƒé‡ï¼Œç¡®ä¿è¿™ä¸ªè·¯å¾„ä¸‹åŒ…å«äº† `modeling_hunyuan.py` å’Œ `configuration_hunyuan.py` æ–‡ä»¶ï¼Œå¦åˆ™æ— æ³•åŠ è½½
- `--tokenizer_name_or_path`: tokenizer æ–‡ä»¶å¤¹è·¯å¾„ï¼Œç¡®ä¿è¿™ä¸ªè·¯å¾„ä¸‹åŒ…å«äº†`tokenization_hy.py` æ–‡ä»¶ï¼Œå¦åˆ™æ— æ³•åŠ è½½
- `--train_data_file`: è®­ç»ƒæ–‡ä»¶è·¯å¾„ï¼Œåº”è¯¥ä¸ºä¸€ä¸ª jsonl æ–‡ä»¶
- `--output_dir`: è¾“å‡ºæ–‡ä»¶å¤¹ï¼Œlogã€tensorboard å’Œæƒé‡éƒ½ä¼šå­˜å‚¨åœ¨è¿™ä¸ªè·¯å¾„ä¸‹
- `--per_device_train_batch_size`: æ¯å¼ å¡ä¸Šçš„ batch size
- `--gradient_accumulation_steps`: æ¢¯åº¦ç´¯è®¡æ¬¡æ•°ï¼Œ`per_device_train_batch_size * gradient_accumulation_steps * dp_size`ä¸º global_batch_size
- `--max_steps`: è®­ç»ƒçš„æ€»æ­¥æ•°
- `--save_steps`: æ¯å¤šå°‘ä¸ª step å­˜å‚¨ä¸€ä¸ª checkpoint
- `--use_lora`: æ˜¯å¦ç”¨ lora è®­ç»ƒï¼ŒåŒæ—¶æ¥æ”¶`--lora_rank`ï¼Œ`--lora_alpha`å’Œ`--lora_dropout`å‚æ•°ã€‚lora é»˜è®¤åº”ç”¨äº "q_proj", "k_proj", "v_proj", "o_proj" å››ä¸ªå‚æ•°ï¼Œå¦‚æœéœ€è¦æ”¹å˜çš„è¯åœ¨ä»£ç ä¸­ä¿®æ”¹å³å¯ã€‚æ³¨æ„ï¼š**ä½¿ç”¨ lora è®­ç»ƒæ—¶ï¼Œåªä¼šä¿å­˜ lora çš„æƒé‡ï¼Œè€Œä¸ä¼šä¿å­˜ base æ¨¡å‹çš„æƒé‡**ï¼Œå¦‚æœéœ€è¦åˆå¹¶ lora æƒé‡ï¼Œçœ‹ä¸‹é¢çš„â€œLora æƒé‡åˆå¹¶â€ä¸€èŠ‚
- `--make_moe_param_leaf_module`ï¼šå½“ç”¨ zero3 ä»¥åŠ MoE è®­ç»ƒæ—¶ï¼Œå°† MoE æ¨¡å—è§†ä½œä¸€ä¸ª leaf moduleï¼Œå³å®ƒçš„å‚æ•°ä¸è¿›è¡Œ zero3 åˆ‡åˆ†ï¼Œè¿™ä¸ªé€‰é¡¹é¢„è®¡ä¼šæ˜¾è‘—å¢åŠ æ˜¾å­˜å ç”¨
- `--gradient_checkpointing`ï¼šå¼€å¯æ¢¯åº¦é‡è®¡ç®—
- `--train_attention_params_only`: æ˜¯å¦åªè®­ç»ƒ attention å‚æ•°
- `--learning_rate`: è®­ç»ƒæ—¶çš„æœ€å¤§å­¦ä¹ ç‡
- `--min_lr`: è®­ç»ƒæ—¶çš„æœ€å°å­¦ä¹ ç‡
- `--use_flash_attn`: å¼€å¯ flash-attention è¿›è¡Œè®­ç»ƒåŠ é€Ÿ

**æ³¨æ„ï¼š**

- å¦‚æœæƒ³ä»ä¸€ä¸ªä¸­é€”ä¿å­˜çš„ ckpt ç»§ç»­è®­ç»ƒï¼Œè€Œä¸æ˜¯åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„æƒé‡ï¼Œç›´æ¥æŒ‡å®š`--resume_from_checkpoint`ä¸ºä¹‹å‰è®­ç»ƒä¿å­˜çš„ ckpt è·¯å¾„ï¼Œä¸è¦æŒ‡å®š`--model_name_or_path`ï¼Œè¿™æ ·åªä¼šåŠ è½½æƒé‡ï¼Œè€Œä¸ä¼šåŠ è½½è®­ç»ƒçŠ¶æ€
- ä» ckpt ç»§ç»­è®­ç»ƒæ—¶ï¼Œloss å¯èƒ½ä¼šæœ‰å¾®å°çš„åå·®ï¼Œè¿™æ˜¯ç”±ä¸€äº›éç¡®å®šæ€§ç®—æ³•å¸¦æ¥çš„éšæœºæ€§ï¼Œæ˜¯æ­£å¸¸ç°è±¡ã€‚å‚è€ƒï¼š[HuggingFace Transformers Trainer Randomness 
- å½“ `--model_name_or_path` æœ‰æ•ˆæ—¶ï¼Œæ‰€æœ‰æ¨¡å‹ç›¸å…³çš„å‚æ•°éƒ½ä¼šè¢«å¿½ç•¥
- ä¸€ä¸ª batch å†…çš„æ ·æœ¬ä¼šé€šè¿‡ padding å¯¹é½ batch å†…æœ€é•¿çš„æ ·æœ¬ï¼Œè€Œæ¯æ¡æ ·æœ¬çš„é•¿åº¦æœ€é•¿ä¸º max_seq_lengthï¼Œè¶…å‡ºçš„éƒ¨åˆ†ä¼šè¢«è£å‰ª
- å¦‚æœæŠ¥å‡º bias æƒé‡æ²¡æœ‰ load çš„ warningï¼Œå¿½ç•¥å³å¯ï¼ŒHunyuan-Large ä¸­ä¸ä¼šç”¨åˆ° bias

#### æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

å‚è€ƒï¼š[DeepSpeed Configuration](https://www.deepspeed.ai/docs/config-json/)

å¯ä»¥å°è¯•ä¿®æ”¹ ds configï¼Œå»æ‰è¿™å‡ ä¸ªå‚æ•°çš„ auto å±æ€§ï¼Œæ”¹å°è¯•è¯•çœ‹ï¼š

- `stage3_param_persistence_threshold`
- `stage3_prefetch_bucket_size`
- `stage3_max_reuse_distance`
- `stage3_max_reuse_distance`


#### Lora æ¨¡å‹åˆå¹¶

ä¿å­˜ä¸‹æ¥çš„ lora æƒé‡æ²¡æ³•åœ¨è®­ç»ƒè¿è¡Œæ—¶åˆå¹¶åˆ° zero3 æ¨¡å‹ä¸­ï¼Œå› ä¸º zero3 å¼€å¯æ—¶æ¨¡å‹æƒé‡ä¼šåˆ‡åˆ†åˆ°å„ dp rank ä¸Šã€‚å› æ­¤å¦‚æœæƒ³æŠŠ lora æƒé‡åˆå¹¶åˆ° base æ¨¡å‹ä¸Šï¼Œå¯ä»¥é€šè¿‡ç¦»çº¿çš„æ–¹å¼åˆå¹¶åå¾—åˆ°æƒé‡æ–‡ä»¶ã€‚æ‰§è¡Œ`merge_lora_weight.sh`å³å¯å®Œæˆ lora æƒé‡å’Œ base æ¨¡å‹æƒé‡çš„åˆå¹¶ï¼Œå…¶ä¸­çš„å‚æ•°æœ‰ï¼š

- `--base_model_path`ï¼šbase æ¨¡å‹çš„æƒé‡ç›®å½•
- `--adapter_model_path`ï¼šlora æƒé‡ç›®å½•
- `--output_path`ï¼šåˆå¹¶åçš„æƒé‡ä¿å­˜ç›®å½•
- `--save_dtype`ï¼š ä»¥ä»€ä¹ˆæ•°æ®æ ¼å¼å­˜å‚¨åˆå¹¶åçš„æƒé‡ï¼Œå¯é€‰å€¼ï¼šfp16ï¼Œbf16ï¼Œfp32

&nbsp;

## æ¨ç†å’Œéƒ¨ç½² 

HunyuanLLMæ”¯æŒTRT-LLMå’ŒvLLMä¸¤ç§éƒ¨ç½²æ–¹å¼ã€‚æœ¬æ¬¡æˆ‘ä»¬å¼€æºvLLMéƒ¨ç½²æ–¹å¼(è¯¦è§'ä½¿ç”¨vLLMæ¨ç†'ç« èŠ‚)ï¼ŒTRT-LLMéƒ¨ç½²æ–¹å¼(è¯¦è§'ä½¿ç”¨TRT-LLMæ¨ç†'ç« èŠ‚)å°†åœ¨è¿‘æœŸå¼€æ”¾ã€‚

## ä½¿ç”¨TRT-LLMæ¨ç†
å¾…å¼€æ”¾

## ä½¿ç”¨vLLMæ¨ç†
### Docker:

ä¸ºäº†ç®€åŒ–éƒ¨ç½²è¿‡ç¨‹ï¼ŒHunyuanLLMæä¾›äº†é¢„æ„å»ºdockeré•œåƒï¼š

 [hunyuaninfer/hunyuan-large](https://hub.docker.com/repository/docker/hunyuaninfer/hunyuan-large/general) ã€‚æ‚¨åªéœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶å¹¶ç”¨ä¸‹é¢ä»£ç å¯åŠ¨dockerå³å¯å¼€å§‹æ¨ç†æ¨¡å‹ã€‚
```shell
docker run --name hunyuanLLM_infer -itd --privileged --user root  --net=host --ipc=host --gpus=8 hunyuaninfer/hunyuan-large:infer-open-source
```

æ³¨: Dockerå®¹å™¨æƒé™ç®¡ç†ã€‚ä»¥ä¸Šä»£ç é‡‡ç”¨ç‰¹æƒæ¨¡å¼ï¼ˆ--privilegedï¼‰å¯åŠ¨Dockerå®¹å™¨ä¼šèµ‹äºˆå®¹å™¨è¾ƒé«˜çš„æƒé™ï¼Œå¢åŠ æ•°æ®æ³„éœ²å’Œé›†ç¾¤å®‰å…¨é£é™©ã€‚å»ºè®®åœ¨éå¿…è¦æƒ…å†µä¸‹é¿å…ä½¿ç”¨ç‰¹æƒæ¨¡å¼ï¼Œä»¥é™ä½å®‰å…¨å¨èƒã€‚å¯¹äºå¿…é¡»ä½¿ç”¨ç‰¹æƒæ¨¡å¼çš„åœºæ™¯ï¼Œåº”è¿›è¡Œä¸¥æ ¼çš„å®‰å…¨è¯„ä¼°ï¼Œå¹¶å®æ–½ç›¸åº”çš„å®‰å…¨ç›‘æ§ã€åŠ å›ºæªæ–½ã€‚


### é…ç½®æœºå™¨é—´å…å¯† ssh ç™»å½•

ä»¥ä¸‹æ“ä½œä»¥ä¸¤ä¸ªæœºå™¨ä¸ºä¾‹ï¼Œä¸¤å°æœºå™¨çš„ ip åˆ†åˆ«ä»¥`${ip1}`å’Œ`${ip2}`æ ‡è¯†ï¼Œä»¥ä¸‹æ“ä½œå‡åœ¨ docker container å†…æ‰§è¡Œã€‚

é¦–å…ˆåœ¨ä¸¤å°æœºå™¨ä¸Šé¢è¿è¡Œï¼š`passwd`è®¾ç½®å¯†ç ï¼Œä¾‹å¦‚ï¼š`Tmp123,./`

å°†`inference/login_ssh.py`æ‹·è´åˆ°å®¹å™¨ä¸­ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œæ³¨æ„IPå’Œå¯†ç å¡«å…¥æ­£ç¡®å€¼ã€‚

```shell
python3 login_ssh.py --ips ${ip1},${ip2} --port 36000 --password=Tmp123,./
```

**æ³¨æ„ğŸ“¢ï¼šåœ¨å¯åŠ¨å‰è¯·åŠ¡å¿…é€šè¿‡VLLMçš„å¤šæœºéªŒè¯è„šæœ¬:https://docs.vllm.ai/en/latest/getting_started/debugging.html**

### BF16éƒ¨ç½²

BF16éœ€è¦16å¡H20éƒ¨ç½²ã€‚éªŒè¯å¤šæœºé€šä¿¡æ— è¯¯åï¼ŒæŒ‰å¦‚ä¸‹æ­¥éª¤æ‰§è¡Œï¼š

è¿è¡Œå‘½ä»¤å‰è¯·å…ˆè®¾ç½®å¦‚ä¸‹ç¯å¢ƒå˜é‡ï¼š

```shell
${LOCAL_IP}ï¼šå½“å‰æœºå™¨bond1å¯¹åº”IP
${MODEL_PATH}ï¼šHunyuan LLMæ¨¡å‹è·¯å¾„
```

#### Step1ï¼šRayå¯åŠ¨

Ray æ˜¯ä¸€ä¸ªå¹¶è¡Œå’Œåˆ†å¸ƒå¼ Python çš„å¼€æºåº“ï¼Œæœ¬ç« èŠ‚æˆ‘ä»¬é‡‡ç”¨Rayæ¥å®ç°å¤šæœºé€šä¿¡ã€‚

Rayç»„ä»¶é…ç½®åŠ å›ºï¼šRayç»„ä»¶é»˜è®¤é…ç½®ä¸­æœåŠ¡ç«¯å£ï¼ˆå¦‚6379ã€8265ï¼‰æœªå¯ç”¨èº«ä»½éªŒè¯æœºåˆ¶ï¼Œå­˜åœ¨æœªæˆæƒè®¿é—®å’Œå‘½ä»¤æ‰§è¡Œçš„é£é™©ã€‚å»ºè®®åœ¨éƒ¨ç½²Rayç»„ä»¶æ—¶ï¼Œä»…åœ¨å—ä¿¡ä»»çš„å†…éƒ¨ç½‘ç»œç¯å¢ƒä¸­è¿›è¡Œï¼Œæˆ–ç¡®ä¿å¯¹è¿™äº›ç«¯å£å®æ–½ä¸¥æ ¼çš„è®¿é—®æ§åˆ¶åˆ—è¡¨ï¼ˆACLï¼‰ç­–ç•¥ï¼Œç¦æ­¢éæˆæƒç½‘ç»œè®¿é—®ã€‚

é¦–å…ˆæˆ‘ä»¬åœ¨å„ä¸ªèŠ‚ç‚¹ä¸Šå¯åŠ¨rayï¼ˆæ”¾åœ¨åå°å¯åŠ¨æˆ–è€…ä¿æŒç»ˆç«¯è¿è¡ŒçŠ¶æ€ï¼‰:

ä¸»èŠ‚ç‚¹ä¸Šï¼š
```shell
export VLLM_HOST_IP=${LOCAL_IP}
export NCCL_SOCKET_IFNAME=bond1
export GLOO_SOCKET_IFNAME=bond1
ray start --block  --head --node-ip-address=${LOCAL_IP} --port=6379
```

æ‰€æœ‰å­èŠ‚ç‚¹ï¼š

æ³¨æ„ï¼š{ä¸»èŠ‚ç‚¹$LOCAL_IP}éœ€å¡«å…¥ä¸»èŠ‚ç‚¹çš„${LOCAL_IP}
```shell
export VLLM_HOST_IP=${LOCAL_IP}
export NCCL_SOCKET_IFNAME=bond1
export GLOO_SOCKET_IFNAME=bond1
ray start --block --address={ä¸»èŠ‚ç‚¹$LOCAL_IP}:6379  --node-ip-address=${LOCAL_IP} 
```
å¦‚æœå¯åŠ¨rayå¤±è´¥ï¼Œæ‰§è¡Œ`ray stop`åå†æ¬¡æ‰§è¡Œä¸Šè¿°å‘½ä»¤ã€‚


#### Step2ï¼šæ‰§è¡Œæ¨ç†

#### æ–¹å¼1ï¼šå‘½ä»¤è¡Œæ¨ç†

ä¸‹é¢æˆ‘ä»¬å±•ç¤ºä¸€ä¸ªä»£ç ç‰‡æ®µï¼Œé‡‡ç”¨`vLLM`å¿«é€Ÿè¯·æ±‚chat modelï¼š

æ³¨: vLLMç»„ä»¶è¿œç¨‹ä»£ç æ‰§è¡Œé˜²æŠ¤ã€‚ä¸‹åˆ—ä»£ç ä¸­vLLMç»„ä»¶çš„trust-remote-codeé…ç½®é¡¹è‹¥è¢«å¯ç”¨ï¼Œå°†å…è®¸åŠ è½½å¹¶æ‰§è¡Œæ¥è‡ªè¿œç¨‹æ¨¡å‹ä»“åº“çš„ä»£ç ï¼Œè¿™å¯èƒ½å¯¼è‡´æ¶æ„ä»£ç çš„æ‰§è¡Œã€‚é™¤éä¸šåŠ¡éœ€æ±‚æ˜ç¡®è¦æ±‚ï¼Œå¦åˆ™å»ºè®®è¯¥é…ç½®é¡¹å¤„äºç¦ç”¨çŠ¶æ€ï¼Œä»¥é™ä½æ½œåœ¨çš„å®‰å…¨å¨èƒã€‚


```python
import os
from vllm import LLM, SamplingParams

model_path=os.environ.get('MODEL_PATH')

llm = LLM(model=model_path,
        tokenizer=model_path,
        trust_remote_code=True,
        max_model_len=10240,
        dtype='bfloat16',
        tensor_parallel_size=16,
        pipeline_parallel_size=1,
        disable_log_stats=False,
        gpu_memory_utilization=0.98,
        disable_custom_all_reduce=True,
        #distributed_executor_backend='ray',
        enforce_eager=True,
        max_num_seqs=8,
        use_v2_block_manager=True,
        quantization=None)

prompts = ["æµ·æ°´ä¸ºä»€ä¹ˆæ˜¯å’¸çš„"]

sampling_params = SamplingParams(
    temperature=0.7, top_p=0.6, max_tokens=200, top_k=20, repetition_penalty=1.05)

outputs = llm.generate(prompts, sampling_params)

# Print the outputs.
for output in outputs:
    prompt = output.prompt
    generated_text = output.outputs[0].text
    print(f"Prompt: {prompt!r}, Generated text: {generated_text!r}")
```

#### æ–¹å¼2ï¼šæœåŠ¡åŒ–æ¨ç†

ä¸‹é¢æˆ‘ä»¬å±•ç¤ºä½¿ç”¨`vLLM`æœåŠ¡åŒ–çš„æ–¹å¼éƒ¨ç½²æ¨¡å‹å¹¶è¯·æ±‚

åœ¨ä¸»èŠ‚ç‚¹ä¸Šè¿è¡Œï¼š

```shell
export VLLM_HOST_IP=${LOCAL_IP}
export NCCL_SOCKET_IFNAME=bond1
export GLOO_SOCKET_IFNAME=bond1
```
æ¥ç€æˆ‘ä»¬å¯åŠ¨æœåŠ¡ï¼Œè¿è¡Œ :
```shell
cd inference
sh run_server.sh
```

*Tips*ï¼šæ•…éšœå¤„ç†ï¼Œå¦‚æœé‡åˆ°
```python
ray, exceptions.RaySystemError: System error: No module named 'transformers_modules' traceback: Traceback (most recent call last):
ModuleNotFoundError: No module named 'transformers modules'
```
å°†ä¸»èŠ‚ç‚¹ä¸Šçš„ ~/.cache/huggingface/modules/æ‹·è´åˆ°æ‰€æœ‰å­èŠ‚ç‚¹ç›¸åº”è·¯å¾„ã€‚

è¿è¡Œ`run_server.sh`æˆåŠŸå, è¿è¡Œè¯·æ±‚è„šæœ¬ï¼š
```shell
sh openapi.sh
```

æ³¨æ„ä¿®æ”¹`openapi.sh`ä¸­çš„`${LOCAL_IP}`å’Œ`${MODEL_PATH}`ä¸ºæœåŠ¡å¯¹åº”å€¼ã€‚


### é‡åŒ–æ¨¡å‹éƒ¨ç½²ï¼š

æœ¬éƒ¨åˆ†ä»‹ç»é‡‡ç”¨vLLMéƒ¨ç½²é‡åŒ–åæ¨¡å‹çš„æµç¨‹ã€‚

é•œåƒï¼šéƒ¨ç½²é•œåƒåŒBF16ã€‚


#### Int8é‡åŒ–æ¨¡å‹éƒ¨ç½²ï¼š
éƒ¨ç½²Int8-weight-onlyç‰ˆæœ¬Hunyuan-Læ¨¡å‹åªéœ€è®¾ç½®`run_server_int8.sh`ä¸­çš„ç¯å¢ƒå˜é‡ï¼š
```SHELL
${MODEL_PATH} : BF16æ¨¡å‹è·¯å¾„
${LOCAL_IP} : å½“å‰æœºå™¨bond1å¯¹åº”IP
```

æ¥ç€æˆ‘ä»¬å¯åŠ¨Int8æœåŠ¡ã€‚è¿è¡Œï¼š
```shell
sh run_server_int8.sh
```

è¿è¡Œ`run_server_int8.sh`æˆåŠŸå, è¿è¡Œè¯·æ±‚è„šæœ¬ï¼š
```shell
sh openapi.sh
```

#### FP8é‡åŒ–æ¨¡å‹éƒ¨ç½²ï¼š
éƒ¨ç½²W8A8C8ç‰ˆæœ¬Hunyuan-Læ¨¡å‹åªéœ€è®¾ç½®`run_server_int8.sh`ä¸­çš„ç¯å¢ƒå˜é‡ï¼š
```shell
${MODEL_PATH} : FP8æ¨¡å‹è·¯å¾„
${LOCAL_IP} : å½“å‰æœºå™¨bond1å¯¹åº”IP
```

æ¥ç€æˆ‘ä»¬å¯åŠ¨FP8æœåŠ¡ã€‚è¿è¡Œï¼š
```shell
sh run_server_fp8.sh
```

è¿è¡Œ`run_server_fp8.sh`æˆåŠŸå, è¿è¡Œè¯·æ±‚è„šæœ¬ï¼š
```shell
sh openapi.sh
```

#### FP8 BENCHMARK

æœ¬éƒ¨åˆ†ä»‹ç»Hunyuan Large Instruct FP8é‡åŒ–æ¨¡å‹çš„æ•ˆæœè¯„ä¼°ã€‚

| Dataset | BF16 | W8A8C8-FP8 |
|---------|------|------------|
| ARC-C   | 94.6 | 94.2       |
| C-Eval  | 88.6 | 89.2       |
| CMMLU   | 90.4 | 89.8       |
| MMLU    | 89.9 | 88.9       |

### æ€§èƒ½è¯„ä¼°ï¼š

æœ¬éƒ¨åˆ†ä»‹ç»é‡‡ç”¨vLLMéƒ¨ç½²å„ä¸ªæ¨¡å‹ï¼ˆåŸå§‹æ¨¡å‹å’Œé‡åŒ–æ¨¡å‹ï¼‰çš„æ•ˆç‡æµ‹è¯•ç»“æœï¼ŒåŒ…æ‹¬ä¸åŒBatchsizeä¸‹çš„æ¨ç†é€Ÿåº¦(tokens/s)ã€‚

| Inference Framework | Model                                                                                                  | Number of GPUs (H20) | input_length | batch=1 | batch=4 |
| ------------------- | ------------------------------------------------------------------------------------------------------ | -------------------- | ------------ |---------|---------|
| vLLM                | Hunyuan-Large                                                                                              | 16                   | 2048         | 20.2    | 75.5    |
| vLLM                | Hunyuan-Large(int8 weight only)                                                                            | 8                    | 2048         | 19.3    | 73.6    |
| vLLM                | Hunyuan-Large(W8A8C8-FP8)                                                                                  | 8                    | 2048         | 19.8    | 74.9    |
## Tokenizer

HunYuan-Largeæ¨¡å‹ä¸­é‡‡ç”¨çš„tokenizerå¹³è¡¡äº†å‹ç¼©ç‡å’Œæ•ˆæœä¸¤ä¸ªå› ç´ ï¼Œä¿è¯embeddingå¯ä»¥å¾—åˆ°å……åˆ†çš„è®­ç»ƒã€‚è¯è¡¨åŒ…å«äº†ä»tiktokenä¸­é›†æˆçš„100Kä¸ªtokenï¼Œåœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨å¤§é‡çš„ä¼˜è´¨ä¸­æ–‡è®­ç»ƒæ•°æ®ï¼Œè®­ç»ƒäº†é¢å¤–çš„29Kçš„ä¸­æ–‡tokenï¼Œä»¥å¢å¼ºæ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›å’Œtokenizerå¯¹æ–‡æœ¬çš„å‹ç¼©ç‡ï¼ŒäºŒè€…ç»“åˆåï¼Œä¸LLaMA3åˆ†è¯å™¨ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–°åˆ†è¯å™¨åœ¨å‹ç¼©ç‡ä¸Šæœ‰æ‰€æ”¹å–„ï¼Œä»2.78ä¸ªå­—ç¬¦/tokenæé«˜åˆ°3.13ä¸ªå­—ç¬¦/tokenã€‚


## æ··å…ƒAPI
æ‚¨å¯ä»¥åœ¨è…¾è®¯äº‘ä½“éªŒæˆ‘ä»¬çš„hunyuan-largeæ¨¡å‹ï¼Œå…·ä½“è¯·è§ï¼šhttps://cloud.tencent.com/document/product/1729/97730ã€‚

## äº¤äº’å¼Demo Web 
Hunyuan-Largeç°å·²å¼€æ”¾ç½‘é¡µdemoã€‚è®¿é—® https://huggingface.co/spaces/tencent/Hunyuan-Large å³å¯ç®€å•ä½“éªŒæˆ‘ä»¬çš„æ¨¡å‹ã€‚

<br>

## ä½¿ç”¨TIè®­ç»ƒ/æ¨ç† 
è…¾è®¯äº‘çš„ [TIå¹³å°](https://cloud.tencent.com/product/ti) æ˜¯ä¸“é—¨ä¸ºAIå·¥ç¨‹å¸ˆè®¾è®¡çš„å…¨é¢çš„æœºå™¨å­¦ä¹ å¹³å°ã€‚é€šè¿‡é›†æˆHunyuan-Largeæ¨¡å‹ï¼Œæ‚¨åªéœ€å‡ æ­¥å³å¯è½»æ¾è¿›è¡Œè®­ç»ƒå’Œéƒ¨ç½²ã€‚è®¿é—® [Chat with Hunyuan-Large](https://console.cloud.tencent.com/tione/v2/aimarket/detail/hunyuan_series?PublicAlgoGroupId=hunyuan-large-chat&detailTab=demo) æ¨¡å—ï¼Œä½“éªŒä¸æ¨¡å‹çš„å®æ—¶å¯¹è¯ï¼Œå¹¶åœ¨TIä¸Šæ¢ç´¢ [Hunyuan-Large Best Practice](https://cloud.tencent.com/document/product/851/112032) ï¼Œåˆ›å»ºè‡ªå·±çš„å®šåˆ¶Hunyuan-Largeæ¨¡å‹ã€‚

## å¼•ç”¨
å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨æˆ‘ä»¬ï¼

```
@misc{sun2024hunyuanlargeopensourcemoemodel,
      title={Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent}, 
      author={Xingwu Sun and Yanfeng Chen and Yiqing Huang and Ruobing Xie and Jiaqi Zhu and Kai Zhang and Shuaipeng Li and Zhen Yang and Jonny Han and Xiaobo Shu and Jiahao Bu and Zhongzhi Chen and Xuemeng Huang and Fengzong Lian and Saiyong Yang and Jianfeng Yan and Yuyuan Zeng and Xiaoqin Ren and Chao Yu and Lulu Wu and Yue Mao and Tao Yang and Suncong Zheng and Kan Wu and Dian Jiao and Jinbao Xue and Xipeng Zhang and Decheng Wu and Kai Liu and Dengpeng Wu and Guanghui Xu and Shaohua Chen and Shuang Chen and Xiao Feng and Yigeng Hong and Junqiang Zheng and Chengcheng Xu and Zongwei Li and Xiong Kuang and Jianglu Hu and Yiqi Chen and Yuchi Deng and Guiyang Li and Ao Liu and Chenchen Zhang and Shihui Hu and Zilong Zhao and Zifan Wu and Yao Ding and Weichao Wang and Han Liu and Roberts Wang and Hao Fei and Peijie She and Ze Zhao and Xun Cao and Hai Wang and Fusheng Xiang and Mengyuan Huang and Zhiyuan Xiong and Bin Hu and Xuebin Hou and Lei Jiang and Jiajia Wu and Yaping Deng and Yi Shen and Qian Wang and Weijie Liu and Jie Liu and Meng Chen and Liang Dong and Weiwen Jia and Hu Chen and Feifei Liu and Rui Yuan and Huilin Xu and Zhenxiang Yan and Tengfei Cao and Zhichao Hu and Xinhua Feng and Dong Du and Tinghao She and Yangyu Tao and Feng Zhang and Jianchen Zhu and Chengzhong Xu and Xirui Li and Chong Zha and Wen Ouyang and Yinben Xia and Xiang Li and Zekun He and Rongpeng Chen and Jiawei Song and Ruibin Chen and Fan Jiang and Chongqing Zhao and Bo Wang and Hao Gong and Rong Gan and Winston Hu and Zhanhui Kang and Yong Yang and Yuhong Liu and Di Wang and Jie Jiang},
      year={2024},
      eprint={2411.02265},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.02265}, 
}
```
<br>

## è”ç³»æˆ‘ä»¬
å¦‚æœä½ æƒ³ç»™æˆ‘ä»¬çš„ç ”å‘å’Œäº§å“å›¢é˜Ÿç•™è¨€ï¼Œæ¬¢è¿è”ç³»æˆ‘ä»¬è…¾è®¯æ··å…ƒLLMå›¢é˜Ÿã€‚ä½ å¯ä»¥é€šè¿‡é‚®ä»¶ï¼ˆhunyuan_opensource@tencent.comï¼‰è”ç³»æˆ‘ä»¬ã€‚
