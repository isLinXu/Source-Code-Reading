<p align="left">
   <a href="README.md">English</a>  ï½œ ä¸­æ–‡</a>&nbsp
</p>
<br><br>

<p align="center">
 <img src="https://dscache.tencent-cloud.cn/upload/uploader/hunyuan-64b418fd052c033b228e04bc77bbc4b54fd7f5bc.png" width="400"/> <br>
</p><p></p>

<p align="center">
    ğŸ«£&nbsp<a href="https://huggingface.co/tencent/"><b>Hugging Face</b></a>&nbsp&nbsp

## æ¨¡å‹ä»‹ç»

æœ¬æ¬¡æ··å…ƒå‘å¸ƒçš„7Bæ¨¡å‹ï¼š[Hunyuan-7B-Pretrain](https://huggingface.co/tencent/Hunyuan-7B-Pretrain)å’Œ[Hunyuan-7B-Instruct](https://huggingface.co/tencent/Hunyuan-7B-Instruct) ï¼Œé‡‡ç”¨äº†æ›´ä¼˜çš„æ•°æ®é…æ¯”ä¸è®­ç»ƒï¼Œæ‹¥æœ‰å¼ºåŠ²çš„æ€§èƒ½ï¼Œåœ¨è®¡ç®—ä¸æ€§èƒ½é—´å–å¾—è‰¯å¥½å¹³è¡¡çš„ä¼˜åŠ¿ä»ä¼—å¤šè§„æ¨¡çš„è¯­è¨€æ¨¡å‹ä¸­è„±é¢–è€Œå‡ºï¼Œæ˜¯ç›®å‰æœ€å¼ºçš„ä¸­æ–‡7B Denseæ¨¡å‹ä¹‹ä¸€ã€‚
### æŠ€æœ¯ä¼˜åŠ¿ä»‹ç»

#### æ¨¡å‹  

- ä½¿ç”¨äº†GQAçš„åŒæ—¶ï¼Œå°†é•¿æ–‡èƒ½åŠ›æ‹“å±•åˆ°256Kã€‚

#### æ¨ç†æ¡†æ¶
- æ¨¡å‹æ”¯æŒ TRT-LLM-backend å’Œ [vLLM-backend](https://github.com/quinnrong94/vllm/tree/dev_hunyuan) æ¨ç†æ¡†æ¶ã€‚æœ¬æ¬¡ä¼˜å…ˆå¼€æºvLLMæ¡†æ¶ï¼ŒTRT-LLMå°†åœ¨è¿‘æœŸæ¨å‡ºã€‚

#### è®­ç»ƒæ¡†æ¶
- Hunyuan-7Bå¼€æºæ¨¡å‹å·²ç»æ”¯æŒhuggingfaceæ ¼å¼ï¼Œæ”¯æŒç”¨æˆ·é‡‡ç”¨hf-deepspeedæ¡†æ¶è¿›è¡Œæ¨¡å‹ç²¾è°ƒã€‚è¯¦æƒ…å¯ä»¥å‚ç…§[Tencent-Hunyuan-Large](https://github.com/Tencent/Tencent-Hunyuan-Large) ã€‚

&nbsp;

## æ–°é—»
* 2025.1 æˆ‘ä»¬åœ¨Hugging Faceå¼€æºäº†**Hunyuan-7B-Pretrain** ã€ **Hunyuan-7B-Instruct** ã€‚
<br>


## Benchmarkè¯„ä¼°æ¦œå• 

æ³¨ï¼šä¸‹åˆ—Benchmarkå‡ä¸º TRT-LLM-backend æµ‹è¯„å¾—å‡º
**Hunyuan-7B-Pretrain**

|                  | Qwen2.5-7B | Llama3-8B  | OLMO2-7B | HunYuan-7B-V2 |
|------------------|------------|------------|----------|---------------|
| MMLU             | 74.26      | 66.95      | 63.7     | **75.37**         |
| MMLU-Pro         | 46.17      | 34.04      | 31       | **47.54**         |
| MMLU-CF          | **61.01**      | 55.21      | 52.94    | 59.62         |
| MMLU-Redux       | 73.47      | 66.44      | 63.74    | **74.54**         |
| BBH              | 70.4       | 62.16      | 38.01    | **70.77**         |
| HellaSwag        | 75.82      | 78.24      | 61.97    | **80.77**         |
| WinoGrande       | 69.69      | 73.64      | **74.43**    | 71.51         |
| PIQA             | 79.33      | 80.52      | **80.63**    | 81.45         |
| SIQA             | 77.48      | 61.05      | 65.2     | **79.73**         |
| NaturalQuestions | 31.77      | 35.43      | **36.9**     | 33.52         |
| DROP             | 68.2       | 60.13      | 60.8     | **68.63**         |
| ARC-C            | 91.64      | 77.59      | 74.92    | **91.97**         |
| TriviaQA         | 69.31      | **78.61**      | 78       | 74.31         |
| Chinese-SimpleQA | 30.37      | 19.4       | 7.35     | **30.51**         |
| SimpleQA         | 4.98       | **7.68**       | 4.51     | 3.73          |
| CMMLU            | 81.39      | 50.25      | 38.79    | **82.19**         |
| C-Eval           | 81.11      | 50.4       | 38.53    | **82.12**         |
| C3               | 71.77      | 61.5       | 54       | **79.07**         |
| GSM8K            | 82.71      | 57.54      | 67.5     | **93.33**         |
| MATH             | 49.6       | 18.45      | 19       | **62.15**         |
| CMATH            | 84.33      | 52.83      | 44       | **88.5**          |
| HumanEval        | 57.93      | 35.98      | 15.24    | **59.15**         |




**Hunyuan-7B-Instruct**

| Model       | Qwen2.5-7B-Instruct | Llama-3-8B-Instruct | OLMo-2-1124-7B-DPO | Hunyuan-7B-Instruct | 
|-------------|---------------------|---------------------|--------------------|-------------------|
| ARC-C       | **89.83**           | 82.4                | -                  | 88.81             | 
| BBH         | 66.24               | -                   | 46.6               | **76.47**         |
| CEval       | 76.82               | -                   | -                  | **81.8**          | 
| CMMLU       | 78.55               | -                   | -                  | **82.29**         | 
| DROP_F1     | 80.63               | -                   | 60.5               | **82.96**         | 
| GPQA        | 36.87               | 34.6                | -                  | **47.98**         | 
| Gsm8k       | 80.14               | 80.6                | 85.1               | **90.14**         | 
| HellaSwag   | 83.34               | -                   | -                  | **86.57**         | 
| HumanEval   | **84.8**            | 60.4                | -                  | 84.0              | 
| MATH        | **72.86**           | -                   | 32.5               | 70.64             | 
| MMLU        | 72.36               | 68.5                | 61.3               | **79.18**         | 



## å¿«é€Ÿå¼€å§‹

æ‚¨å¯ä»¥å‚è€ƒ[Tencent-Hunyuan-Large](https://github.com/Tencent/Tencent-Hunyuan-Large) ä¸­çš„å†…å®¹è¿›è¡Œå¿«é€Ÿä¸Šæ‰‹ï¼Œè®­ç»ƒæ¨ç†ä»£ç ä½¿ç”¨æœ¬githubä»“åº“æä¾›ç‰ˆæœ¬å³å¯ã€‚

## é•œåƒ

ä¸ºäº†ç®€åŒ–éƒ¨ç½²è¿‡ç¨‹ï¼ŒHunyuanLLMæä¾›äº†é¢„å…ˆæ„å»ºçš„Dockeré•œåƒï¼š
[hunyuaninfer/hunyuan-large:dense-infer-open-source](https://hub.docker.com/layers/hunyuaninfer/hunyuan-large/dense-infer-open-source/images/sha256-3a39561d8262dac04fcb46e7860663158909720b76a28b94a54eb852524ae6a4). 

### æ€§èƒ½è¯„ä¼°ï¼š

æœ¬éƒ¨åˆ†ä»‹ç»é‡‡ç”¨vLLMéƒ¨ç½²å„ä¸ªæ¨¡å‹çš„æ•ˆç‡æµ‹è¯•ç»“æœï¼ŒåŒ…æ‹¬ä¸åŒBatchsizeä¸‹çš„æ¨ç†é€Ÿåº¦(tokens/s)ã€‚

| æ¨ç†æ¡†æ¶ | æ¨¡å‹                      | éƒ¨ç½²å¡æ•°ï¼ˆå¡å‹1ï¼‰ | input_length | batch=1             | batch=4              |
|------|-----------------------------|-----------|-------------------------|---------------------|----------------------|
| vLLM | hunyuan-7B                  | 1         | 2048                  | 78.9                | 279.5                  |

## è”ç³»æˆ‘ä»¬
å¦‚æœä½ æƒ³ç»™æˆ‘ä»¬çš„ç ”å‘å’Œäº§å“å›¢é˜Ÿç•™è¨€ï¼Œæ¬¢è¿è”ç³»æˆ‘ä»¬è…¾è®¯æ··å…ƒLLMå›¢é˜Ÿã€‚ä½ å¯ä»¥é€šè¿‡é‚®ä»¶ï¼ˆhunyuan_opensource@tencent.comï¼‰è”ç³»æˆ‘ä»¬ã€‚
