# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""
Train a YOLOv5 classifier model on a classification dataset.

Usage - Single-GPU training:
    $ python classify/train.py --model yolov5s-cls.pt --data imagenette160 --epochs 5 --img 224

Usage - Multi-GPU DDP training:
    $ python -m torch.distributed.run --nproc_per_node 4 --master_port 2022 classify/train.py --model yolov5s-cls.pt --data imagenet --epochs 5 --img 224 --device 0,1,2,3

Datasets:           --data mnist, fashion-mnist, cifar10, cifar100, imagenette, imagewoof, imagenet, or 'path/to/data'
YOLOv5-cls models:  --model yolov5n-cls.pt, yolov5s-cls.pt, yolov5m-cls.pt, yolov5l-cls.pt, yolov5x-cls.pt
Torchvision models: --model resnet50, efficientnet_b0, etc. See https://pytorch.org/vision/stable/models.html
"""

import argparse
import os
import subprocess
import sys
import time
from copy import deepcopy
from datetime import datetime
from pathlib import Path

import torch
import torch.distributed as dist
import torch.hub as hub
import torch.optim.lr_scheduler as lr_scheduler
import torchvision
from torch.cuda import amp
from tqdm import tqdm

FILE = Path(__file__).resolve()
# è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
ROOT = FILE.parents[1]  # YOLOv5 root directory
# è·å–YOLOv5æ ¹ç›®å½•ï¼ˆå½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•çš„çˆ¶ç›®å½•ï¼‰
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
    # å¦‚æœæ ¹ç›®å½•ä¸åœ¨ç³»ç»Ÿè·¯å¾„ä¸­ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative
# å°†æ ¹ç›®å½•è½¬æ¢ä¸ºç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•çš„è·¯å¾„

from classify import val as validate
# ä»classifyæ¨¡å—å¯¼å…¥éªŒè¯å‡½æ•°
from models.experimental import attempt_load
# ä»experimentalæ¨¡å—å¯¼å…¥å°è¯•åŠ è½½æ¨¡å‹çš„å‡½æ•°
from models.yolo import ClassificationModel, DetectionModel
# ä»yoloæ¨¡å—å¯¼å…¥åˆ†ç±»æ¨¡å‹å’Œæ£€æµ‹æ¨¡å‹
from utils.dataloaders import create_classification_dataloader
# ä»dataloadersæ¨¡å—å¯¼å…¥åˆ›å»ºåˆ†ç±»æ•°æ®åŠ è½½å™¨çš„å‡½æ•°
from utils.general import (
    DATASETS_DIR,
    LOGGER,
    TQDM_BAR_FORMAT,
    WorkingDirectory,
    check_git_info,
    check_git_status,
    check_requirements,
    colorstr,
    download,
    increment_path,
    init_seeds,
    print_args,
    yaml_save,
)
# ä»generalæ¨¡å—å¯¼å…¥å„ç§å®ç”¨å·¥å…·å‡½æ•°å’Œå¸¸é‡

from utils.loggers import GenericLogger
# ä»loggersæ¨¡å—å¯¼å…¥é€šç”¨æ—¥å¿—è®°å½•å™¨
from utils.plots import imshow_cls
# ä»plotsæ¨¡å—å¯¼å…¥æ˜¾ç¤ºåˆ†ç±»å›¾åƒçš„å‡½æ•°
from utils.torch_utils import (
    ModelEMA,
    de_parallel,
    model_info,
    reshape_classifier_output,
    select_device,
    smart_DDP,
    smart_optimizer,
    smartCrossEntropyLoss,
    torch_distributed_zero_first,
)
# ä»torch_utilsæ¨¡å—å¯¼å…¥å„ç§ä¸PyTorchç›¸å…³çš„å·¥å…·å‡½æ•°å’Œç±»

LOCAL_RANK = int(os.getenv("LOCAL_RANK", -1))  # https://pytorch.org/docs/stable/elastic/run.html
# è·å–å½“å‰è¿›ç¨‹çš„æœ¬åœ°æ’åï¼Œé»˜è®¤ä¸º-1
RANK = int(os.getenv("RANK", -1))
# è·å–å½“å‰è¿›ç¨‹çš„å…¨å±€æ’åï¼Œé»˜è®¤ä¸º-1
WORLD_SIZE = int(os.getenv("WORLD_SIZE", 1))
# è·å–å…¨å±€è¿›ç¨‹æ•°é‡ï¼Œé»˜è®¤ä¸º1
GIT_INFO = check_git_info()
# æ£€æŸ¥Gitä¿¡æ¯

def train(opt, device):
    """Trains a YOLOv5 model, managing datasets, model optimization, logging, and saving checkpoints."""
    # è®­ç»ƒYOLOv5æ¨¡å‹ï¼Œç®¡ç†æ•°æ®é›†ã€æ¨¡å‹ä¼˜åŒ–ã€æ—¥å¿—è®°å½•å’Œä¿å­˜æ£€æŸ¥ç‚¹
    init_seeds(opt.seed + 1 + RANK, deterministic=True)
    # åˆå§‹åŒ–éšæœºç§å­ï¼Œç¡®ä¿å¯é‡å¤æ€§
    save_dir, data, bs, epochs, nw, imgsz, pretrained = (
        opt.save_dir,
        Path(opt.data),
        opt.batch_size,
        opt.epochs,
        min(os.cpu_count() - 1, opt.workers),
        opt.imgsz,
        str(opt.pretrained).lower() == "true",
    )
    # è§£åŒ…è®­ç»ƒé€‰é¡¹ï¼ŒåŒ…æ‹¬ä¿å­˜ç›®å½•ã€æ•°æ®é›†è·¯å¾„ã€æ‰¹å¤„ç†å¤§å°ã€è®­ç»ƒè½®æ•°ã€å·¥ä½œçº¿ç¨‹æ•°ã€å›¾åƒå¤§å°å’Œæ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
    cuda = device.type != "cpu"
    # åˆ¤æ–­å½“å‰è®¾å¤‡æ˜¯å¦ä¸ºCUDAï¼ˆGPUï¼‰

    # Directories
    wdir = save_dir / "weights"
    # è®¾ç½®æƒé‡ä¿å­˜ç›®å½•
    wdir.mkdir(parents=True, exist_ok=True)  # make dir
    # åˆ›å»ºæƒé‡ä¿å­˜ç›®å½•ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™ä¸æŠ¥é”™
    last, best = wdir / "last.pt", wdir / "best.pt"
    # å®šä¹‰æœ€åä¸€æ¬¡å’Œæœ€ä½³æ¨¡å‹çš„ä¿å­˜è·¯å¾„

    # Save run settings
    yaml_save(save_dir / "opt.yaml", vars(opt))
    # å°†è®­ç»ƒé€‰é¡¹ä¿å­˜ä¸ºYAMLæ–‡ä»¶

    # Logger
    logger = GenericLogger(opt=opt, console_logger=LOGGER) if RANK in {-1, 0} else None
    # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨ï¼Œå¦‚æœå½“å‰è¿›ç¨‹æ˜¯ä¸»è¿›ç¨‹åˆ™å¯ç”¨æ—¥å¿—è®°å½•

    # Download Dataset
    with torch_distributed_zero_first(LOCAL_RANK), WorkingDirectory(ROOT):
        # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œç¡®ä¿åªæœ‰ä¸€ä¸ªè¿›ç¨‹ä¸‹è½½æ•°æ®é›†
        data_dir = data if data.is_dir() else (DATASETS_DIR / data)
        # æ£€æŸ¥æ•°æ®é›†è·¯å¾„ï¼Œå¦‚æœæ˜¯ç›®å½•åˆ™ä½¿ç”¨è¯¥è·¯å¾„ï¼Œå¦åˆ™æ‹¼æ¥ä¸ºå®Œæ•´è·¯å¾„
        if not data_dir.is_dir():
            LOGGER.info(f"\nDataset not found âš ï¸, missing path {data_dir}, attempting download...")
            # å¦‚æœæ•°æ®é›†ç›®å½•ä¸å­˜åœ¨ï¼Œè®°å½•ä¿¡æ¯å¹¶å°è¯•ä¸‹è½½æ•°æ®é›†
            t = time.time()
            if str(data) == "imagenet":
                subprocess.run(["bash", str(ROOT / "data/scripts/get_imagenet.sh")], shell=True, check=True)
                # å¦‚æœæ•°æ®é›†æ˜¯imagenetï¼Œè¿è¡Œä¸‹è½½è„šæœ¬
            else:
                url = f"https://github.com/ultralytics/yolov5/releases/download/v1.0/{data}.zip"
                download(url, dir=data_dir.parent)
                # ç”Ÿæˆæ•°æ®é›†ä¸‹è½½é“¾æ¥å¹¶ä¸‹è½½æ•°æ®é›†
            s = f"Dataset download success âœ… ({time.time() - t:.1f}s), saved to {colorstr('bold', data_dir)}\n"
            LOGGER.info(s)
            # è®°å½•ä¸‹è½½æˆåŠŸçš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬è€—æ—¶å’Œä¿å­˜è·¯å¾„

    # Dataloaders
    nc = len([x for x in (data_dir / "train").glob("*") if x.is_dir()])  # number of classes
    # è®¡ç®—è®­ç»ƒæ•°æ®é›†ä¸­ç±»åˆ«çš„æ•°é‡ï¼Œé€šè¿‡æ£€æŸ¥è®­ç»ƒç›®å½•ä¸‹çš„å­ç›®å½•æ•°é‡

    trainloader = create_classification_dataloader(
        path=data_dir / "train",
        imgsz=imgsz,
        batch_size=bs // WORLD_SIZE,
        augment=True,
        cache=opt.cache,
        rank=LOCAL_RANK,
        workers=nw,
    )
    # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼Œè®¾ç½®æ•°æ®è·¯å¾„ã€å›¾åƒå¤§å°ã€æ‰¹å¤„ç†å¤§å°ã€æ•°æ®å¢å¼ºã€ç¼“å­˜é€‰é¡¹ã€è¿›ç¨‹æ’åå’Œå·¥ä½œçº¿ç¨‹æ•°

    test_dir = data_dir / "test" if (data_dir / "test").exists() else data_dir / "val"  # data/test or data/val
    # è®¾ç½®æµ‹è¯•æ•°æ®é›†è·¯å¾„ï¼Œå¦‚æœæµ‹è¯•ç›®å½•å­˜åœ¨åˆ™ä½¿ç”¨æµ‹è¯•ç›®å½•ï¼Œå¦åˆ™ä½¿ç”¨éªŒè¯ç›®å½•
    if RANK in {-1, 0}:
        testloader = create_classification_dataloader(
            path=test_dir,
            imgsz=imgsz,
            batch_size=bs // WORLD_SIZE * 2,
            augment=False,
            cache=opt.cache,
            rank=-1,
            workers=nw,
        )
        # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼Œè®¾ç½®æ•°æ®è·¯å¾„ã€å›¾åƒå¤§å°ã€æ‰¹å¤„ç†å¤§å°ï¼ˆä¸ºè®­ç»ƒæ—¶çš„ä¸¤å€ï¼‰ã€ä¸è¿›è¡Œæ•°æ®å¢å¼ºã€ç¼“å­˜é€‰é¡¹ã€è¿›ç¨‹æ’åå’Œå·¥ä½œçº¿ç¨‹æ•°

    # Model
    with torch_distributed_zero_first(LOCAL_RANK), WorkingDirectory(ROOT):
        # åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œç¡®ä¿åªæœ‰ä¸€ä¸ªè¿›ç¨‹åŠ è½½æ¨¡å‹
        if Path(opt.model).is_file() or opt.model.endswith(".pt"):
            model = attempt_load(opt.model, device="cpu", fuse=False)
            # å¦‚æœæ¨¡å‹è·¯å¾„æ˜¯æ–‡ä»¶æˆ–ä»¥.ptç»“å°¾ï¼Œåˆ™å°è¯•åŠ è½½è¯¥æ¨¡å‹
        elif opt.model in torchvision.models.__dict__:  # TorchVision models i.e. resnet50, efficientnet_b0
            model = torchvision.models.__dict__[opt.model](weights="IMAGENET1K_V1" if pretrained else None)
            # å¦‚æœæ¨¡å‹åœ¨TorchVisionæ¨¡å‹å­—å…¸ä¸­ï¼Œåˆ™åŠ è½½ç›¸åº”çš„TorchVisionæ¨¡å‹
        else:
            m = hub.list("ultralytics/yolov5")  # + hub.list('pytorch/vision')  # models
            raise ModuleNotFoundError(f"--model {opt.model} not found. Available models are: \n" + "\n".join(m))
            # å¦‚æœæ¨¡å‹ä¸åœ¨å·²çŸ¥æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œåˆ™å¼•å‘æœªæ‰¾åˆ°æ¨¡å‹çš„é”™è¯¯ï¼Œå¹¶åˆ—å‡ºå¯ç”¨æ¨¡å‹

        if isinstance(model, DetectionModel):
            LOGGER.warning("WARNING âš ï¸ pass YOLOv5 classifier model with '-cls' suffix, i.e. '--model yolov5s-cls.pt'")
            # å¦‚æœæ¨¡å‹æ˜¯æ£€æµ‹æ¨¡å‹ï¼Œå‘å‡ºè­¦å‘Šï¼Œæç¤ºåº”ä½¿ç”¨å¸¦æœ‰'-cls'åç¼€çš„åˆ†ç±»æ¨¡å‹
            model = ClassificationModel(model=model, nc=nc, cutoff=opt.cutoff or 10)  # convert to classification model
            # å°†æ£€æµ‹æ¨¡å‹è½¬æ¢ä¸ºåˆ†ç±»æ¨¡å‹

        reshape_classifier_output(model, nc)  # update class count
        # æ›´æ–°åˆ†ç±»æ¨¡å‹çš„ç±»åˆ«æ•°é‡

    for m in model.modules():
        if not pretrained and hasattr(m, "reset_parameters"):
            m.reset_parameters()
            # å¦‚æœæ¨¡å‹ä¸æ˜¯é¢„è®­ç»ƒçš„ï¼Œå¹¶ä¸”æ¨¡å—å…·æœ‰é‡ç½®å‚æ•°çš„æ–¹æ³•ï¼Œåˆ™é‡ç½®æ¨¡å—çš„å‚æ•°
        if isinstance(m, torch.nn.Dropout) and opt.dropout is not None:
            m.p = opt.dropout  # set dropout
            # å¦‚æœæ¨¡å—æ˜¯Dropoutå±‚ï¼Œå¹¶ä¸”è®¾ç½®äº†dropoutå‚æ•°ï¼Œåˆ™æ›´æ–°Dropoutçš„æ¦‚ç‡

    for p in model.parameters():
        p.requires_grad = True  # for training
        # è®¾ç½®æ¨¡å‹å‚æ•°ä¸ºå¯è®­ç»ƒ

    model = model.to(device)
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰

    # Info
    if RANK in {-1, 0}:
        model.names = trainloader.dataset.classes  # attach class names
        # å°†ç±»åˆ«åç§°é™„åŠ åˆ°æ¨¡å‹ä¸­
        model.transforms = testloader.dataset.torch_transforms  # attach inference transforms
        # å°†æ¨ç†è½¬æ¢é™„åŠ åˆ°æ¨¡å‹ä¸­
        model_info(model)
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        if opt.verbose:
            LOGGER.info(model)
            # å¦‚æœè®¾ç½®äº†è¯¦ç»†è¾“å‡ºï¼Œåˆ™è®°å½•æ¨¡å‹ä¿¡æ¯
        images, labels = next(iter(trainloader))
        # ä»è®­ç»ƒåŠ è½½å™¨ä¸­è·å–ä¸‹ä¸€æ‰¹å›¾åƒå’Œæ ‡ç­¾
        file = imshow_cls(images[:25], labels[:25], names=model.names, f=save_dir / "train_images.jpg")
        # æ˜¾ç¤ºå‰25å¼ å›¾åƒåŠå…¶æ ‡ç­¾ï¼Œå¹¶ä¿å­˜ä¸ºtrain_images.jpg
        logger.log_images(file, name="Train Examples")
        # è®°å½•è®­ç»ƒç¤ºä¾‹å›¾åƒ
        logger.log_graph(model, imgsz)  # log model
        # è®°å½•æ¨¡å‹ç»“æ„å›¾

    # Optimizer
    optimizer = smart_optimizer(model, opt.optimizer, opt.lr0, momentum=0.9, decay=opt.decay)
    # åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼Œä½¿ç”¨è‡ªå®šä¹‰çš„æ™ºèƒ½ä¼˜åŒ–å™¨ï¼Œè®¾ç½®ä¼˜åŒ–å™¨ç±»å‹ã€åˆå§‹å­¦ä¹ ç‡ã€åŠ¨é‡å’Œè¡°å‡ç‡

    # Scheduler
    lrf = 0.01  # final lr (fraction of lr0)
    # è®¾ç½®æœ€ç»ˆå­¦ä¹ ç‡ä¸ºåˆå§‹å­¦ä¹ ç‡çš„1%

    # lf = lambda x: ((1 + math.cos(x * math.pi / epochs)) / 2) * (1 - lrf) + lrf  # cosine
    # å®šä¹‰ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å‡½æ•°ï¼ˆå·²æ³¨é‡Šæ‰ï¼‰
    lf = lambda x: (1 - x / epochs) * (1 - lrf) + lrf  # linear
    # å®šä¹‰çº¿æ€§å­¦ä¹ ç‡è°ƒåº¦å‡½æ•°
    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œä½¿ç”¨å®šä¹‰çš„çº¿æ€§è°ƒåº¦å‡½æ•°

    # EMA
    ema = ModelEMA(model) if RANK in {-1, 0} else None
    # å¦‚æœå½“å‰è¿›ç¨‹æ˜¯ä¸»è¿›ç¨‹ï¼Œåˆ™åˆå§‹åŒ–æ¨¡å‹çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰

    # DDP mode
    if cuda and RANK != -1:
        model = smart_DDP(model)
        # å¦‚æœä½¿ç”¨CUDAå¹¶ä¸”ä¸æ˜¯å•è¿›ç¨‹æ¨¡å¼ï¼Œåˆ™ä½¿ç”¨æ™ºèƒ½åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œï¼ˆDDPï¼‰æ¨¡å‹

    # Train
    t0 = time.time()
    # è®°å½•è®­ç»ƒå¼€å§‹çš„æ—¶é—´
    criterion = smartCrossEntropyLoss(label_smoothing=opt.label_smoothing)  # loss function
    # å®šä¹‰æŸå¤±å‡½æ•°ï¼Œä½¿ç”¨æ™ºèƒ½äº¤å‰ç†µæŸå¤±ï¼Œæ”¯æŒæ ‡ç­¾å¹³æ»‘
    best_fitness = 0.0
    # åˆå§‹åŒ–æœ€ä½³é€‚åº”åº¦ä¸º0
    scaler = amp.GradScaler(enabled=cuda)
    # åˆå§‹åŒ–æ¢¯åº¦ç¼©æ”¾å™¨ï¼Œç”¨äºæ··åˆç²¾åº¦è®­ç»ƒ
    val = test_dir.stem  # 'val' or 'test'
    # è·å–éªŒè¯æˆ–æµ‹è¯•ç›®å½•çš„åŸºæœ¬åç§°
    LOGGER.info(
        f'Image sizes {imgsz} train, {imgsz} test\n'
        f'Using {nw * WORLD_SIZE} dataloader workers\n'
        f"Logging results to {colorstr('bold', save_dir)}\n"
        f'Starting {opt.model} training on {data} dataset with {nc} classes for {epochs} epochs...\n\n'
        f"{'Epoch':>10}{'GPU_mem':>10}{'train_loss':>12}{f'{val}_loss':>12}{'top1_acc':>12}{'top5_acc':>12}"
    )
    # è®°å½•è®­ç»ƒçš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬å›¾åƒå¤§å°ã€æ•°æ®åŠ è½½å™¨å·¥ä½œçº¿ç¨‹æ•°ã€ä¿å­˜è·¯å¾„ã€æ¨¡å‹åç§°ã€æ•°æ®é›†ã€ç±»åˆ«æ•°é‡å’Œè®­ç»ƒè½®æ•°

    for epoch in range(epochs):  # loop over the dataset multiple times
        # éå†è®­ç»ƒè½®æ•°
        tloss, vloss, fitness = 0.0, 0.0, 0.0  # train loss, val loss, fitness
        # åˆå§‹åŒ–è®­ç»ƒæŸå¤±ã€éªŒè¯æŸå¤±å’Œé€‚åº”åº¦
        model.train()
        # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        if RANK != -1:
            trainloader.sampler.set_epoch(epoch)
            # å¦‚æœä¸æ˜¯å•è¿›ç¨‹æ¨¡å¼ï¼Œåˆ™è®¾ç½®è®­ç»ƒæ•°æ®åŠ è½½å™¨çš„å½“å‰è½®æ¬¡
        pbar = enumerate(trainloader)
        # åˆå§‹åŒ–è¿›åº¦æ¡
        if RANK in {-1, 0}:
            pbar = tqdm(enumerate(trainloader), total=len(trainloader), bar_format=TQDM_BAR_FORMAT)
            # å¦‚æœæ˜¯ä¸»è¿›ç¨‹ï¼Œåˆ™ä½¿ç”¨tqdmåº“æ˜¾ç¤ºè¿›åº¦æ¡
        for i, (images, labels) in pbar:  # progress bar
            # éå†è®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼Œè·å–å›¾åƒå’Œæ ‡ç­¾
            images, labels = images.to(device, non_blocking=True), labels.to(device)
            # å°†å›¾åƒå’Œæ ‡ç­¾ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡

            # Forward
            with amp.autocast(enabled=cuda):  # stability issues when enabled
                # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦è¿›è¡Œå‰å‘ä¼ æ’­
                loss = criterion(model(images), labels)
                # è®¡ç®—æŸå¤±

            # Backward
            scaler.scale(loss).backward()
            # ç¼©æ”¾æŸå¤±å¹¶è¿›è¡Œåå‘ä¼ æ’­

            # Optimize
            scaler.unscale_(optimizer)  # unscale gradients
            # åç¼©æ”¾æ¢¯åº¦
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients
            # è£å‰ªæ¢¯åº¦ä»¥é˜²æ­¢çˆ†ç‚¸
            scaler.step(optimizer)
            # æ›´æ–°ä¼˜åŒ–å™¨
            scaler.update()
            # æ›´æ–°ç¼©æ”¾å™¨
            optimizer.zero_grad()
            # æ¸…é›¶æ¢¯åº¦
            if ema:
                ema.update(model)
                # å¦‚æœä½¿ç”¨EMAï¼Œåˆ™æ›´æ–°EMAæ¨¡å‹

            if RANK in {-1, 0}:
                # Print
                tloss = (tloss * i + loss.item()) / (i + 1)  # update mean losses
                # æ›´æ–°å¹³å‡è®­ç»ƒæŸå¤±
                mem = "%.3gG" % (torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0)  # (GB)
                # è·å–å½“å‰GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
                pbar.desc = f"{f'{epoch + 1}/{epochs}':>10}{mem:>10}{tloss:>12.3g}" + " " * 36
                # æ›´æ–°è¿›åº¦æ¡æè¿°

                # Test
                if i == len(pbar) - 1:  # last batch
                    top1, top5, vloss = validate.run(
                        model=ema.ema, dataloader=testloader, criterion=criterion, pbar=pbar
                    )  # test accuracy, loss
                    # åœ¨æœ€åä¸€æ‰¹æ¬¡ä¸­è¿›è¡ŒéªŒè¯ï¼Œè·å–top1å’Œtop5å‡†ç¡®ç‡ä»¥åŠéªŒè¯æŸå¤±
                    fitness = top1  # define fitness as top1 accuracy
                    # å°†é€‚åº”åº¦å®šä¹‰ä¸ºtop1å‡†ç¡®ç‡

        # Scheduler
        scheduler.step()
        # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨

        # Log metrics
        if RANK in {-1, 0}:
            # Best fitness
            if fitness > best_fitness:
                best_fitness = fitness
                # å¦‚æœå½“å‰é€‚åº”åº¦è¶…è¿‡æœ€ä½³é€‚åº”åº¦ï¼Œåˆ™æ›´æ–°æœ€ä½³é€‚åº”åº¦

            # Log
            metrics = {
                "train/loss": tloss,
                f"{val}/loss": vloss,
                "metrics/accuracy_top1": top1,
                "metrics/accuracy_top5": top5,
                "lr/0": optimizer.param_groups[0]["lr"],
            }  # learning rate
            # è®°å½•å½“å‰è®­ç»ƒæŸå¤±ã€éªŒè¯æŸå¤±ã€top1å’Œtop5å‡†ç¡®ç‡ä»¥åŠå­¦ä¹ ç‡
            logger.log_metrics(metrics, epoch)

            # Save model
            final_epoch = epoch + 1 == epochs
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€åä¸€è½®
            if (not opt.nosave) or final_epoch:
                # å¦‚æœä¸ç¦æ­¢ä¿å­˜æ¨¡å‹æˆ–è€…æ˜¯æœ€åä¸€è½®ï¼Œåˆ™ä¿å­˜æ¨¡å‹
                ckpt = {
                    "epoch": epoch,
                    "best_fitness": best_fitness,
                    "model": deepcopy(ema.ema).half(),  # deepcopy(de_parallel(model)).half(),
                    "ema": None,  # deepcopy(ema.ema).half(),
                    "updates": ema.updates,
                    "optimizer": None,  # optimizer.state_dict(),
                    "opt": vars(opt),
                    "git": GIT_INFO,  # {remote, branch, commit} if a git repo
                    "date": datetime.now().isoformat(),
                }
                # åˆ›å»ºæ£€æŸ¥ç‚¹å­—å…¸ï¼ŒåŒ…å«å½“å‰è½®æ¬¡ã€æœ€ä½³é€‚åº”åº¦ã€æ¨¡å‹ã€EMAæ›´æ–°æ¬¡æ•°ã€ä¼˜åŒ–å™¨çŠ¶æ€ã€é€‰é¡¹å’ŒGitä¿¡æ¯

                # Save last, best and delete
                torch.save(ckpt, last)
                # ä¿å­˜æœ€åä¸€æ¬¡æ¨¡å‹
                if best_fitness == fitness:
                    torch.save(ckpt, best)
                    # å¦‚æœå½“å‰é€‚åº”åº¦æ˜¯æœ€ä½³é€‚åº”åº¦ï¼Œåˆ™ä¿å­˜æœ€ä½³æ¨¡å‹
                del ckpt
                # åˆ é™¤æ£€æŸ¥ç‚¹å­—å…¸ä»¥é‡Šæ”¾å†…å­˜

    # Train complete
    if RANK in {-1, 0} and final_epoch:
        LOGGER.info(
            f'\nTraining complete ({(time.time() - t0) / 3600:.3f} hours)'
            f"\nResults saved to {colorstr('bold', save_dir)}"
            f'\nPredict:         python classify/predict.py --weights {best} --source im.jpg'
            f'\nValidate:        python classify/val.py --weights {best} --data {data_dir}'
            f'\nExport:          python export.py --weights {best} --include onnx'
            f"\nPyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '{best}')"
            f'\nVisualize:       https://netron.app\n'
        )
        # è®­ç»ƒå®Œæˆï¼Œè®°å½•è®­ç»ƒæ—¶é—´å’Œä¿å­˜è·¯å¾„ï¼Œå¹¶æä¾›é¢„æµ‹ã€éªŒè¯å’Œå¯¼å‡ºæ¨¡å‹çš„å‘½ä»¤

        # Plot examples
        images, labels = (x[:25] for x in next(iter(testloader)))  # first 25 images and labels
        # è·å–æµ‹è¯•åŠ è½½å™¨ä¸­çš„å‰25å¼ å›¾åƒå’Œæ ‡ç­¾
        pred = torch.max(ema.ema(images.to(device)), 1)[1]
        # ä½¿ç”¨EMAæ¨¡å‹è¿›è¡Œé¢„æµ‹
        file = imshow_cls(images, labels, pred, de_parallel(model).names, verbose=False, f=save_dir / "test_images.jpg")
        # æ˜¾ç¤ºå›¾åƒåŠå…¶çœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾ï¼Œå¹¶ä¿å­˜ä¸ºtest_images.jpg

        # Log results
        meta = {"epochs": epochs, "top1_acc": best_fitness, "date": datetime.now().isoformat()}
        # åˆ›å»ºå…ƒæ•°æ®å­—å…¸ï¼ŒåŒ…å«è®­ç»ƒè½®æ•°ã€æœ€ä½³top1å‡†ç¡®ç‡å’Œå½“å‰æ—¥æœŸ
        logger.log_images(file, name="Test Examples (true-predicted)", epoch=epoch)
        # è®°å½•æµ‹è¯•ç¤ºä¾‹å›¾åƒ
        logger.log_model(best, epochs, metadata=meta)
        # è®°å½•æ¨¡å‹ä¿¡æ¯

def parse_opt(known=False):
    """Parses command line arguments for YOLOv5 training including model path, dataset, epochs, and more, returning
    parsed arguments.
    """
    # è§£æYOLOv5è®­ç»ƒçš„å‘½ä»¤è¡Œå‚æ•°ï¼ŒåŒ…æ‹¬æ¨¡å‹è·¯å¾„ã€æ•°æ®é›†ã€è®­ç»ƒè½®æ•°ç­‰ï¼Œå¹¶è¿”å›è§£æåçš„å‚æ•°
    parser = argparse.ArgumentParser()
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨

    parser.add_argument("--model", type=str, default="yolov5s-cls.pt", help="initial weights path")
    # æ·»åŠ æ¨¡å‹è·¯å¾„å‚æ•°ï¼Œé»˜è®¤ä¸ºyolov5s-cls.pt

    parser.add_argument("--data", type=str, default="imagenette160", help="cifar10, cifar100, mnist, imagenet, ...")
    # æ·»åŠ æ•°æ®é›†å‚æ•°ï¼Œé»˜è®¤ä¸ºimagenette160

    parser.add_argument("--epochs", type=int, default=10, help="total training epochs")
    # æ·»åŠ è®­ç»ƒè½®æ•°å‚æ•°ï¼Œé»˜è®¤ä¸º10

    parser.add_argument("--batch-size", type=int, default=64, help="total batch size for all GPUs")
    # æ·»åŠ æ‰¹å¤„ç†å¤§å°å‚æ•°ï¼Œé»˜è®¤ä¸º64ï¼Œè¡¨ç¤ºæ‰€æœ‰GPUçš„æ€»æ‰¹å¤„ç†å¤§å°

    parser.add_argument("--imgsz", "--img", "--img-size", type=int, default=224, help="train, val image size (pixels)")
    # æ·»åŠ å›¾åƒå¤§å°å‚æ•°ï¼Œé»˜è®¤ä¸º224åƒç´ 

    parser.add_argument("--nosave", action="store_true", help="only save final checkpoint")
    # æ·»åŠ ä¸ä¿å­˜ä¸­é—´æ£€æŸ¥ç‚¹çš„æ ‡å¿—ï¼Œå¦‚æœè®¾ç½®åˆ™ä»…ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹

    parser.add_argument("--cache", type=str, nargs="?", const="ram", help='--cache images in "ram" (default) or "disk"')
    # æ·»åŠ ç¼“å­˜é€‰é¡¹ï¼Œæ”¯æŒåœ¨RAMæˆ–ç£ç›˜ä¸­ç¼“å­˜å›¾åƒ

    parser.add_argument("--device", default="", help="cuda device, i.e. 0 or 0,1,2,3 or cpu")
    # æ·»åŠ è®¾å¤‡å‚æ•°ï¼ŒæŒ‡å®šä½¿ç”¨çš„CUDAè®¾å¤‡æˆ–CPU

    parser.add_argument("--workers", type=int, default=8, help="max dataloader workers (per RANK in DDP mode)")
    # æ·»åŠ æœ€å¤§æ•°æ®åŠ è½½å·¥ä½œçº¿ç¨‹æ•°å‚æ•°ï¼Œé»˜è®¤ä¸º8

    parser.add_argument("--project", default=ROOT / "runs/train-cls", help="save to project/name")
    # æ·»åŠ é¡¹ç›®ä¿å­˜è·¯å¾„å‚æ•°ï¼Œé»˜è®¤ä¸ºruns/train-cls

    parser.add_argument("--name", default="exp", help="save to project/name")
    # æ·»åŠ å®éªŒåç§°å‚æ•°ï¼Œé»˜è®¤ä¸º"exp"

    parser.add_argument("--exist-ok", action="store_true", help="existing project/name ok, do not increment")
    # æ·»åŠ å…è®¸å­˜åœ¨çš„é¡¹ç›®åç§°æ ‡å¿—ï¼Œå¦‚æœè®¾ç½®åˆ™ä¸é€’å¢é¡¹ç›®åç§°

    parser.add_argument("--pretrained", nargs="?", const=True, default=True, help="start from i.e. --pretrained False")
    # æ·»åŠ é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ï¼Œé»˜è®¤ä¸ºTrue

    parser.add_argument("--optimizer", choices=["SGD", "Adam", "AdamW", "RMSProp"], default="Adam", help="optimizer")
    # æ·»åŠ ä¼˜åŒ–å™¨é€‰æ‹©å‚æ•°ï¼Œé»˜è®¤ä¸ºAdam

    parser.add_argument("--lr0", type=float, default=0.001, help="initial learning rate")
    # æ·»åŠ åˆå§‹å­¦ä¹ ç‡å‚æ•°ï¼Œé»˜è®¤ä¸º0.001

    parser.add_argument("--decay", type=float, default=5e-5, help="weight decay")
    # æ·»åŠ æƒé‡è¡°å‡å‚æ•°ï¼Œé»˜è®¤ä¸º5e-5

    parser.add_argument("--label-smoothing", type=float, default=0.1, help="Label smoothing epsilon")
    # æ·»åŠ æ ‡ç­¾å¹³æ»‘å‚æ•°ï¼Œé»˜è®¤ä¸º0.1

    parser.add_argument("--cutoff", type=int, default=None, help="Model layer cutoff index for Classify() head")
    # æ·»åŠ æ¨¡å‹å±‚æˆªæ­¢ç´¢å¼•å‚æ•°ï¼Œç”¨äºåˆ†ç±»å¤´

    parser.add_argument("--dropout", type=float, default=None, help="Dropout (fraction)")
    # æ·»åŠ Dropoutå‚æ•°ï¼Œç”¨äºè®¾ç½®Dropoutçš„æ¯”ä¾‹

    parser.add_argument("--verbose", action="store_true", help="Verbose mode")
    # æ·»åŠ è¯¦ç»†è¾“å‡ºæ¨¡å¼çš„æ ‡å¿—

    parser.add_argument("--seed", type=int, default=0, help="Global training seed")
    # æ·»åŠ å…¨å±€è®­ç»ƒç§å­å‚æ•°ï¼Œé»˜è®¤ä¸º0

    parser.add_argument("--local_rank", type=int, default=-1, help="Automatic DDP Multi-GPU argument, do not modify")
    # æ·»åŠ è‡ªåŠ¨DDPå¤šGPUå‚æ•°ï¼Œé»˜è®¤ä¸º-1ï¼Œä¸è¦ä¿®æ”¹

    return parser.parse_known_args()[0] if known else parser.parse_args()
    # è¿”å›è§£æåçš„å‚æ•°ï¼Œå¦‚æœknownä¸ºTrueï¼Œåˆ™è§£æå·²çŸ¥å‚æ•°ï¼Œå¦åˆ™è§£ææ‰€æœ‰å‚æ•°


def main(opt):
    """Executes YOLOv5 training with given options, handling device setup and DDP mode; includes pre-training checks."""
    # ä½¿ç”¨ç»™å®šé€‰é¡¹æ‰§è¡ŒYOLOv5è®­ç»ƒï¼Œå¤„ç†è®¾å¤‡è®¾ç½®å’ŒDDPæ¨¡å¼ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒæ£€æŸ¥
    if RANK in {-1, 0}:
        print_args(vars(opt))
        # å¦‚æœæ˜¯ä¸»è¿›ç¨‹ï¼Œåˆ™æ‰“å°å‚æ•°
        check_git_status()
        # æ£€æŸ¥GitçŠ¶æ€
        check_requirements(ROOT / "requirements.txt")
        # æ£€æŸ¥æ‰€éœ€çš„ä¾èµ–é¡¹

    # DDP mode
    device = select_device(opt.device, batch_size=opt.batch_size)
    # é€‰æ‹©è®¾å¤‡ï¼Œè®¾ç½®ä¸ºæŒ‡å®šçš„CUDAè®¾å¤‡æˆ–CPU
    if LOCAL_RANK != -1:
        assert opt.batch_size != -1, "AutoBatch is coming soon for classification, please pass a valid --batch-size"
        # ç¡®ä¿æ‰¹å¤„ç†å¤§å°æœ‰æ•ˆ
        assert opt.batch_size % WORLD_SIZE == 0, f"--batch-size {opt.batch_size} must be multiple of WORLD_SIZE"
        # ç¡®ä¿æ‰¹å¤„ç†å¤§å°æ˜¯å…¨å±€è¿›ç¨‹æ•°é‡çš„å€æ•°
        assert torch.cuda.device_count() > LOCAL_RANK, "insufficient CUDA devices for DDP command"
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„CUDAè®¾å¤‡ç”¨äºDDPå‘½ä»¤
        torch.cuda.set_device(LOCAL_RANK)
        # è®¾ç½®å½“å‰CUDAè®¾å¤‡
        device = torch.device("cuda", LOCAL_RANK)
        # å°†è®¾å¤‡è®¾ç½®ä¸ºå½“å‰CUDAè®¾å¤‡
        dist.init_process_group(backend="nccl" if dist.is_nccl_available() else "gloo")
        # åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„ï¼Œä½¿ç”¨NCCLä½œä¸ºåç«¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨Gloo

    # Parameters
    opt.save_dir = increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok)  # increment run
    # è®¾ç½®ä¿å­˜ç›®å½•ï¼Œç¡®ä¿ç›®å½•åç§°å”¯ä¸€

    # Train
    train(opt, device)
    # è°ƒç”¨è®­ç»ƒå‡½æ•°


def run(**kwargs):
    """
    Executes YOLOv5 model training or inference with specified parameters, returning updated options.

    Example: from yolov5 import classify; classify.train.run(data=mnist, imgsz=320, model='yolov5m')
    """
    # æ‰§è¡ŒYOLOv5æ¨¡å‹è®­ç»ƒæˆ–æ¨ç†ï¼Œè¿”å›æ›´æ–°åçš„é€‰é¡¹
    opt = parse_opt(True)
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    for k, v in kwargs.items():
        setattr(opt, k, v)
        # å°†ä¼ å…¥çš„å…³é”®å­—å‚æ•°è®¾ç½®åˆ°é€‰é¡¹ä¸­
    main(opt)
    # è°ƒç”¨ä¸»å‡½æ•°
    return opt
    # è¿”å›è§£æåçš„é€‰é¡¹


if __name__ == "__main__":
    opt = parse_opt()
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    main(opt)
    # è°ƒç”¨ä¸»å‡½æ•°
