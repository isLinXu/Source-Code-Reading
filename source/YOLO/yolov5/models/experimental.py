# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""Experimental modules."""

import math  # å¯¼å…¥æ•°å­¦åº“

import numpy as np  # å¯¼å…¥NumPyåº“
import torch  # å¯¼å…¥PyTorchåº“
import torch.nn as nn  # å¯¼å…¥PyTorchçš„ç¥ç»ç½‘ç»œæ¨¡å—

from utils.downloads import attempt_download  # ä»utilsä¸‹è½½æ¨¡å—å¯¼å…¥attempt_downloadå‡½æ•°


class Sum(nn.Module):
    """Weighted sum of 2 or more layers https://arxiv.org/abs/1911.09070."""
    # åŠ æƒæ±‚å’Œ2ä¸ªæˆ–æ›´å¤šå±‚çš„è¾“å‡º

    def __init__(self, n, weight=False):
        """Initializes a module to sum outputs of layers with number of inputs `n` and optional weighting, supporting 2+
        inputs.
        """
        # åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å—ï¼Œç”¨äºå¯¹å…·æœ‰è¾“å…¥æ•°é‡`n`çš„å±‚çš„è¾“å‡ºè¿›è¡Œæ±‚å’Œï¼Œå¹¶å¯é€‰æ‹©åŠ æƒï¼Œæ”¯æŒ2ä¸ªä»¥ä¸Šçš„è¾“å…¥
        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        self.weight = weight  # apply weights boolean
        # æ˜¯å¦åº”ç”¨æƒé‡çš„å¸ƒå°”å€¼
        self.iter = range(n - 1)  # iter object
        # åˆ›å»ºè¿­ä»£å¯¹è±¡
        if weight:
            self.w = nn.Parameter(-torch.arange(1.0, n) / 2, requires_grad=True)  # layer weights
            # å¦‚æœéœ€è¦æƒé‡ï¼Œåˆ™åˆ›å»ºå¯è®­ç»ƒçš„æƒé‡å‚æ•°

    def forward(self, x):
        """Processes input through a customizable weighted sum of `n` inputs, optionally applying learned weights."""
        # é€šè¿‡å¯å®šåˆ¶çš„åŠ æƒå’Œå¤„ç†è¾“å…¥ï¼Œæ”¯æŒ`n`ä¸ªè¾“å…¥ï¼Œå¹¶å¯é€‰æ‹©åº”ç”¨å­¦ä¹ åˆ°çš„æƒé‡
        y = x[0]  # no weight
        # åˆå§‹åŒ–è¾“å‡ºä¸ºç¬¬ä¸€ä¸ªè¾“å…¥
        if self.weight:
            w = torch.sigmoid(self.w) * 2  # åº”ç”¨sigmoidæ¿€æ´»å‡½æ•°å¹¶ä¹˜ä»¥2
            for i in self.iter:
                y = y + x[i + 1] * w[i]  # åŠ æƒæ±‚å’Œ
        else:
            for i in self.iter:
                y = y + x[i + 1]  # ç›´æ¥æ±‚å’Œ
        return y  # è¿”å›æ±‚å’Œç»“æœ


class MixConv2d(nn.Module):
    """Mixed Depth-wise Conv https://arxiv.org/abs/1907.09595."""
    # æ··åˆæ·±åº¦å·ç§¯

    def __init__(self, c1, c2, k=(1, 3), s=1, equal_ch=True):
        """Initializes MixConv2d with mixed depth-wise convolutional layers, taking input and output channels (c1, c2),
        kernel sizes (k), stride (s), and channel distribution strategy (equal_ch).
        """
        # åˆå§‹åŒ–MixConv2dï¼Œä½¿ç”¨æ··åˆæ·±åº¦å·ç§¯å±‚ï¼Œæ¥å—è¾“å…¥å’Œè¾“å‡ºé€šé“ï¼ˆc1, c2ï¼‰ã€å·ç§¯æ ¸å¤§å°ï¼ˆkï¼‰ã€æ­¥å¹…ï¼ˆsï¼‰å’Œé€šé“åˆ†é…ç­–ç•¥ï¼ˆequal_chï¼‰
        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        n = len(k)  # number of convolutions
        # å·ç§¯çš„æ•°é‡
        if equal_ch:  # equal c_ per group
            i = torch.linspace(0, n - 1e-6, c2).floor()  # c2 indices
            # ç”Ÿæˆå‡åŒ€åˆ†å¸ƒçš„é€šé“ç´¢å¼•
            c_ = [(i == g).sum() for g in range(n)]  # intermediate channels
            # è®¡ç®—æ¯ç»„çš„ä¸­é—´é€šé“æ•°
        else:  # equal weight.numel() per group
            b = [c2] + [0] * n  # åˆå§‹åŒ–b
            a = np.eye(n + 1, n, k=-1)  # åˆ›å»ºå•ä½çŸ©é˜µ
            a -= np.roll(a, 1, axis=1)  # è®¡ç®—å·®åˆ†
            a *= np.array(k) ** 2  # æ ¹æ®å·ç§¯æ ¸å¤§å°è°ƒæ•´
            a[0] = 1  # è®¾ç½®ç¬¬ä¸€è¡Œ
            c_ = np.linalg.lstsq(a, b, rcond=None)[0].round()  # solve for equal weight indices, ax = b
            # é€šè¿‡æœ€å°äºŒä¹˜æ³•æ±‚è§£æ¯ç»„çš„é€šé“æ•°

        self.m = nn.ModuleList(
            [nn.Conv2d(c1, int(c_), k, s, k // 2, groups=math.gcd(c1, int(c_)), bias=False) for k, c_ in zip(k, c_)]
            # åˆ›å»ºå·ç§¯å±‚åˆ—è¡¨
        )
        self.bn = nn.BatchNorm2d(c2)  # æ·»åŠ æ‰¹å½’ä¸€åŒ–å±‚
        self.act = nn.SiLU()  # æ·»åŠ SiLUæ¿€æ´»å‡½æ•°

    def forward(self, x):
        """Performs forward pass by applying SiLU activation on batch-normalized concatenated convolutional layer
        outputs.
        """
        # æ‰§è¡Œå‰å‘ä¼ æ’­ï¼Œå¯¹æ‰¹å½’ä¸€åŒ–åçš„å·ç§¯å±‚è¾“å‡ºåº”ç”¨SiLUæ¿€æ´»
        return self.act(self.bn(torch.cat([m(x) for m in self.m], 1)))
        # å°†æ‰€æœ‰å·ç§¯å±‚çš„è¾“å‡ºæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œå¹¶è¿›è¡Œæ¿€æ´»


class Ensemble(nn.ModuleList):
    """Ensemble of models."""
    # æ¨¡å‹çš„é›†æˆ

    def __init__(self):
        """Initializes an ensemble of models to be used for aggregated predictions."""
        # åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹é›†æˆï¼Œç”¨äºèšåˆé¢„æµ‹
        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•

    def forward(self, x, augment=False, profile=False, visualize=False):
        """Performs forward pass aggregating outputs from an ensemble of models.."""
        # æ‰§è¡Œå‰å‘ä¼ æ’­ï¼Œèšåˆæ¥è‡ªæ¨¡å‹é›†æˆçš„è¾“å‡º
        y = [module(x, augment, profile, visualize)[0] for module in self]
        # éå†æ¯ä¸ªæ¨¡å—ï¼Œè·å–è¾“å‡º
        # y = torch.stack(y).max(0)[0]  # max ensemble
        # y = torch.stack(y).mean(0)  # mean ensemble
        y = torch.cat(y, 1)  # nms ensemble
        # å°†æ‰€æœ‰è¾“å‡ºåœ¨é€šé“ç»´åº¦ä¸Šæ‹¼æ¥
        return y, None  # inference, train output
        # è¿”å›æ¨ç†ç»“æœå’Œè®­ç»ƒè¾“å‡º


def attempt_load(weights, device=None, inplace=True, fuse=True):
    """
    Loads and fuses an ensemble or single YOLOv5 model from weights, handling device placement and model adjustments.

    Example inputs: weights=[a,b,c] or a single model weights=[a] or weights=a.
    """
    # ä»æƒé‡åŠ è½½å¹¶èåˆä¸€ä¸ªæˆ–å¤šä¸ªYOLOv5æ¨¡å‹ï¼Œå¤„ç†è®¾å¤‡æ”¾ç½®å’Œæ¨¡å‹è°ƒæ•´
    from models.yolo import Detect, Model  # ä»yoloæ¨¡å—å¯¼å…¥Detectå’ŒModelç±»

    model = Ensemble()  # åˆ›å»ºæ¨¡å‹é›†æˆ
    for w in weights if isinstance(weights, list) else [weights]:
        ckpt = torch.load(attempt_download(w), map_location="cpu")  # load
        # åŠ è½½æƒé‡
        ckpt = (ckpt.get("ema") or ckpt["model"]).to(device).float()  # FP32 model
        # è·å–æ¨¡å‹å¹¶è½¬æ¢ä¸ºFP32æ ¼å¼

        # Model compatibility updates
        # æ¨¡å‹å…¼å®¹æ€§æ›´æ–°
        if not hasattr(ckpt, "stride"):
            ckpt.stride = torch.tensor([32.0])  # è®¾ç½®é»˜è®¤æ­¥å¹…
        if hasattr(ckpt, "names") and isinstance(ckpt.names, (list, tuple)):
            ckpt.names = dict(enumerate(ckpt.names))  # convert to dict
            # å°†ç±»åˆ«åç§°è½¬æ¢ä¸ºå­—å…¸

        model.append(ckpt.fuse().eval() if fuse and hasattr(ckpt, "fuse") else ckpt.eval())  # model in eval mode
        # å°†æ¨¡å‹æ·»åŠ åˆ°é›†æˆä¸­ï¼Œè®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

    # Module updates
    # æ¨¡å—æ›´æ–°
    for m in model.modules():
        t = type(m)  # è·å–æ¨¡å—ç±»å‹
        if t in (nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU, Detect, Model):
            m.inplace = inplace  # è®¾ç½®æ˜¯å¦å°±åœ°æ“ä½œ
            if t is Detect and not isinstance(m.anchor_grid, list):
                delattr(m, "anchor_grid")  # åˆ é™¤anchor_gridå±æ€§
                setattr(m, "anchor_grid", [torch.zeros(1)] * m.nl)  # é‡æ–°è®¾ç½®anchor_grid
        elif t is nn.Upsample and not hasattr(m, "recompute_scale_factor"):
            m.recompute_scale_factor = None  # torch 1.11.0 compatibility
            # å¤„ç†å‘ä¸Šé‡‡æ ·çš„å…¼å®¹æ€§

    # Return model
    # è¿”å›æ¨¡å‹
    if len(model) == 1:
        return model[-1]  # å¦‚æœåªæœ‰ä¸€ä¸ªæ¨¡å‹ï¼Œç›´æ¥è¿”å›

    # Return detection ensemble
    # è¿”å›æ£€æµ‹æ¨¡å‹é›†æˆ
    print(f"Ensemble created with {weights}\n")  # æ‰“å°åˆ›å»ºçš„æ¨¡å‹é›†æˆä¿¡æ¯
    for k in "names", "nc", "yaml":
        setattr(model, k, getattr(model[0], k))  # ä»ç¬¬ä¸€ä¸ªæ¨¡å‹è·å–å±æ€§å¹¶è®¾ç½®åˆ°é›†æˆæ¨¡å‹
    model.stride = model[torch.argmax(torch.tensor([m.stride.max() for m in model])).int()].stride  # max stride
    # è®¾ç½®æœ€å¤§æ­¥å¹…
    assert all(model[0].nc == m.nc for m in model), f"Models have different class counts: {[m.nc for m in model]}"
    # ç¡®ä¿æ‰€æœ‰æ¨¡å‹çš„ç±»åˆ«æ•°é‡ç›¸åŒ
    return model  # è¿”å›æ¨¡å‹é›†æˆ

