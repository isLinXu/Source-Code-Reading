# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""
TensorFlow, Keras and TFLite versions of YOLOv5
Authored by https://github.com/zldrobit in PR https://github.com/ultralytics/yolov5/pull/1127

Usage:
    $ python models/tf.py --weights yolov5s.pt

Export:
    $ python export.py --weights yolov5s.pt --include saved_model pb tflite tfjs
"""

import argparse  # å¯¼å…¥argparseæ¨¡å—ï¼Œç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°
import sys  # å¯¼å…¥sysæ¨¡å—ï¼Œç”¨äºè®¿é—®ä¸Pythonè§£é‡Šå™¨äº¤äº’çš„å˜é‡å’Œå‡½æ•°
from copy import deepcopy  # ä»copyæ¨¡å—å¯¼å…¥deepcopyå‡½æ•°ï¼Œç”¨äºæ·±æ‹·è´å¯¹è±¡
from pathlib import Path  # ä»pathlibæ¨¡å—å¯¼å…¥Pathç±»ï¼Œç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„

FILE = Path(__file__).resolve()  # è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
ROOT = FILE.parents[1]  # YOLOv5æ ¹ç›®å½•
if str(ROOT) not in sys.path:  # å¦‚æœæ ¹ç›®å½•ä¸åœ¨ç³»ç»Ÿè·¯å¾„ä¸­
    sys.path.append(str(ROOT))  # å°†æ ¹ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­
# ROOT = ROOT.relative_to(Path.cwd())  # relativeï¼ˆç›¸å¯¹è·¯å¾„ï¼‰ - æ³¨é‡Šæ‰çš„ä»£ç 

import numpy as np  # å¯¼å…¥numpyåº“ï¼Œé€šå¸¸ç”¨äºæ•°å€¼è®¡ç®—
import tensorflow as tf  # å¯¼å…¥TensorFlowåº“
import torch  # å¯¼å…¥PyTorchåº“
import torch.nn as nn  # ä»PyTorchå¯¼å…¥nnæ¨¡å—ï¼Œç”¨äºæ„å»ºç¥ç»ç½‘ç»œ
from tensorflow import keras  # ä»TensorFlowå¯¼å…¥Kerasæ¨¡å—ï¼Œç”¨äºæ„å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹

from models.common import (  # ä»commonæ¨¡å—å¯¼å…¥å¸¸ç”¨æ¨¡å‹ç»„ä»¶
    C3,
    SPP,
    SPPF,
    Bottleneck,
    BottleneckCSP,
    C3x,
    Concat,
    Conv,
    CrossConv,
    DWConv,
    DWConvTranspose2d,
    Focus,
    autopad,
)
from models.experimental import MixConv2d, attempt_load  # ä»experimentalæ¨¡å—å¯¼å…¥MixConv2då’Œattempt_load
from models.yolo import Detect, Segment  # ä»yoloæ¨¡å—å¯¼å…¥Detectå’ŒSegmentç±»
from utils.activations import SiLU  # ä»utilsæ¨¡å—å¯¼å…¥SiLUæ¿€æ´»å‡½æ•°
from utils.general import LOGGER, make_divisible, print_args  # ä»utilsæ¨¡å—å¯¼å…¥æ—¥å¿—è®°å½•å™¨ã€make_divisibleå‡½æ•°å’Œprint_argså‡½æ•°


class TFBN(keras.layers.Layer):  # TensorFlow BatchNormalizationåŒ…è£…ç±»
    # TensorFlow BatchNormalization wrapper
    def __init__(self, w=None):  # åˆå§‹åŒ–å‡½æ•°ï¼Œå¯é€‰å‚æ•°wç”¨äºé¢„è®­ç»ƒæƒé‡
        """Initializes a TensorFlow BatchNormalization layer with optional pretrained weights.
        åˆå§‹åŒ–ä¸€ä¸ªTensorFlow BatchNormalizationå±‚ï¼Œæ”¯æŒå¯é€‰çš„é¢„è®­ç»ƒæƒé‡ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        self.bn = keras.layers.BatchNormalization(  # åˆ›å»ºBatchNormalizationå±‚
            beta_initializer=keras.initializers.Constant(w.bias.numpy()),  # åˆå§‹åŒ–beta
            gamma_initializer=keras.initializers.Constant(w.weight.numpy()),  # åˆå§‹åŒ–gamma
            moving_mean_initializer=keras.initializers.Constant(w.running_mean.numpy()),  # åˆå§‹åŒ–ç§»åŠ¨å¹³å‡
            moving_variance_initializer=keras.initializers.Constant(w.running_var.numpy()),  # åˆå§‹åŒ–ç§»åŠ¨æ–¹å·®
            epsilon=w.eps,  # è®¾ç½®epsilon
        )

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Applies batch normalization to the inputs.
        å¯¹è¾“å…¥åº”ç”¨æ‰¹é‡å½’ä¸€åŒ–ã€‚
        """
        return self.bn(inputs)  # è¿”å›å½’ä¸€åŒ–åçš„ç»“æœ


class TFPad(keras.layers.Layer):  # å¡«å……è¾“å…¥çš„å±‚ç±»
    # Pad inputs in spatial dimensions 1 and 2
    def __init__(self, pad):  # åˆå§‹åŒ–å‡½æ•°ï¼Œpadä¸ºå¡«å……å¤§å°
        """
        Initializes a padding layer for spatial dimensions 1 and 2 with specified padding, supporting both int and tuple
        inputs.
        ä¸ºç©ºé—´ç»´åº¦1å’Œ2åˆå§‹åŒ–å¡«å……å±‚ï¼Œæ”¯æŒæ•´æ•°å’Œå…ƒç»„è¾“å…¥ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        if isinstance(pad, int):  # å¦‚æœpadæ˜¯æ•´æ•°
            self.pad = tf.constant([[0, 0], [pad, pad], [pad, pad], [0, 0]])  # åˆ›å»ºå¡«å……å¸¸é‡
        else:  # å¦‚æœpadæ˜¯å…ƒç»„/åˆ—è¡¨
            self.pad = tf.constant([[0, 0], [pad[0], pad[0]], [pad[1], pad[1]], [0, 0]])  # åˆ›å»ºå¡«å……å¸¸é‡

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Pads input tensor with zeros using specified padding, suitable for int and tuple pad dimensions.
        ä½¿ç”¨æŒ‡å®šçš„å¡«å……å¯¹è¾“å…¥å¼ é‡è¿›è¡Œé›¶å¡«å……ï¼Œé€‚ç”¨äºæ•´æ•°å’Œå…ƒç»„å¡«å……ç»´åº¦ã€‚
        """
        return tf.pad(inputs, self.pad, mode="constant", constant_values=0)  # è¿”å›å¡«å……åçš„å¼ é‡


class TFConv(keras.layers.Layer):  # æ ‡å‡†å·ç§¯å±‚ç±»
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """
        Initializes a standard convolution layer with optional batch normalization and activation; supports only
        group=1.
        åˆå§‹åŒ–ä¸€ä¸ªæ ‡å‡†å·ç§¯å±‚ï¼Œæ”¯æŒå¯é€‰çš„æ‰¹é‡å½’ä¸€åŒ–å’Œæ¿€æ´»ï¼Œä»…æ”¯æŒgroup=1ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        assert g == 1, "TF v2.2 Conv2D does not support 'groups' argument"  # ç¡®ä¿groupä¸º1
        # TensorFlowå·ç§¯å¡«å……ä¸PyTorchä¸ä¸€è‡´ï¼ˆä¾‹å¦‚k=3 s=2çš„'SAME'å¡«å……ï¼‰
        # see https://stackoverflow.com/questions/52975843/comparing-conv2d-with-padding-between-tensorflow-and-pytorch
        conv = keras.layers.Conv2D(  # åˆ›å»ºConv2Då±‚
            filters=c2,  # è¾“å‡ºé€šé“æ•°
            kernel_size=k,  # å·ç§¯æ ¸å¤§å°
            strides=s,  # æ­¥å¹…
            padding="SAME" if s == 1 else "VALID",  # å¡«å……æ–¹å¼
            use_bias=not hasattr(w, "bn"),  # æ˜¯å¦ä½¿ç”¨åç½®
            kernel_initializer=keras.initializers.Constant(w.conv.weight.permute(2, 3, 1, 0).numpy()),  # å·ç§¯æ ¸åˆå§‹åŒ–
            bias_initializer="zeros" if hasattr(w, "bn") else keras.initializers.Constant(w.conv.bias.numpy()),  # åç½®åˆå§‹åŒ–
        )
        self.conv = conv if s == 1 else keras.Sequential([TFPad(autopad(k, p)), conv])  # æ ¹æ®æ­¥å¹…é€‰æ‹©å·ç§¯å±‚
        self.bn = TFBN(w.bn) if hasattr(w, "bn") else tf.identity  # å¦‚æœæœ‰bnï¼Œåˆ™ä½¿ç”¨TFBN
        self.act = activations(w.act) if act else tf.identity  # æ ¹æ®æ˜¯å¦æ¿€æ´»é€‰æ‹©æ¿€æ´»å‡½æ•°

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Applies convolution, batch normalization, and activation function to input tensors.
        å¯¹è¾“å…¥å¼ é‡åº”ç”¨å·ç§¯ã€æ‰¹é‡å½’ä¸€åŒ–å’Œæ¿€æ´»å‡½æ•°ã€‚
        """
        return self.act(self.bn(self.conv(inputs)))  # è¿”å›ç»è¿‡å¤„ç†çš„ç»“æœ


class TFDWConv(keras.layers.Layer):  # æ·±åº¦å·ç§¯å±‚ç±»
    # Depthwise convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, act=True, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """
        Initializes a depthwise convolution layer with optional batch normalization and activation for TensorFlow
        models.
        åˆå§‹åŒ–ä¸€ä¸ªæ·±åº¦å·ç§¯å±‚ï¼Œæ”¯æŒå¯é€‰çš„æ‰¹é‡å½’ä¸€åŒ–å’Œæ¿€æ´»ï¼Œç”¨äºTensorFlowæ¨¡å‹ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        assert c2 % c1 == 0, f"TFDWConv() output={c2} must be a multiple of input={c1} channels"  # ç¡®ä¿è¾“å‡ºé€šé“æ˜¯è¾“å…¥é€šé“çš„å€æ•°
        conv = keras.layers.DepthwiseConv2D(  # åˆ›å»ºDepthwiseConv2Då±‚
            kernel_size=k,  # å·ç§¯æ ¸å¤§å°
            depth_multiplier=c2 // c1,  # æ·±åº¦ä¹˜æ•°
            strides=s,  # æ­¥å¹…
            padding="SAME" if s == 1 else "VALID",  # å¡«å……æ–¹å¼
            use_bias=not hasattr(w, "bn"),  # æ˜¯å¦ä½¿ç”¨åç½®
            depthwise_initializer=keras.initializers.Constant(w.conv.weight.permute(2, 3, 1, 0).numpy()),  # æ·±åº¦å·ç§¯æ ¸åˆå§‹åŒ–
            bias_initializer="zeros" if hasattr(w, "bn") else keras.initializers.Constant(w.conv.bias.numpy()),  # åç½®åˆå§‹åŒ–
        )
        self.conv = conv if s == 1 else keras.Sequential([TFPad(autopad(k, p)), conv])  # æ ¹æ®æ­¥å¹…é€‰æ‹©å·ç§¯å±‚
        self.bn = TFBN(w.bn) if hasattr(w, "bn") else tf.identity  # å¦‚æœæœ‰bnï¼Œåˆ™ä½¿ç”¨TFBN
        self.act = activations(w.act) if act else tf.identity  # æ ¹æ®æ˜¯å¦æ¿€æ´»é€‰æ‹©æ¿€æ´»å‡½æ•°

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Applies convolution, batch normalization, and activation function to input tensors.
        å¯¹è¾“å…¥å¼ é‡åº”ç”¨å·ç§¯ã€æ‰¹é‡å½’ä¸€åŒ–å’Œæ¿€æ´»å‡½æ•°ã€‚
        """
        return self.act(self.bn(self.conv(inputs)))  # è¿”å›ç»è¿‡å¤„ç†çš„ç»“æœ


class TFDWConvTranspose2d(keras.layers.Layer):  # æ·±åº¦åå·ç§¯å±‚ç±»
    # Depthwise ConvTranspose2d
    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """
        Initializes depthwise ConvTranspose2D layer with specific channel, kernel, stride, and padding settings.
        åˆå§‹åŒ–æ·±åº¦ConvTranspose2Då±‚ï¼Œè®¾ç½®ç‰¹å®šçš„é€šé“ã€å·ç§¯æ ¸ã€æ­¥å¹…å’Œå¡«å……ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        assert c1 == c2, f"TFDWConv() output={c2} must be equal to input={c1} channels"  # ç¡®ä¿è¾“å…¥è¾“å‡ºé€šé“ç›¸ç­‰
        assert k == 4 and p1 == 1, "TFDWConv() only valid for k=4 and p1=1"  # ç¡®ä¿å·ç§¯æ ¸å¤§å°å’Œå¡«å……ç¬¦åˆè¦æ±‚
        weight, bias = w.weight.permute(2, 3, 1, 0).numpy(), w.bias.numpy()  # è·å–æƒé‡å’Œåç½®
        self.c1 = c1  # ä¿å­˜è¾“å…¥é€šé“æ•°
        self.conv = [  # åˆ›å»ºå¤šä¸ªConvTransposeå±‚
            keras.layers.Conv2DTranspose(
                filters=1,  # è¾“å‡ºé€šé“æ•°ä¸º1
                kernel_size=k,  # å·ç§¯æ ¸å¤§å°
                strides=s,  # æ­¥å¹…
                padding="VALID",  # å¡«å……æ–¹å¼
                output_padding=p2,  # è¾“å‡ºå¡«å……
                use_bias=True,  # ä½¿ç”¨åç½®
                kernel_initializer=keras.initializers.Constant(weight[..., i : i + 1]),  # æƒé‡åˆå§‹åŒ–
                bias_initializer=keras.initializers.Constant(bias[i]),  # åç½®åˆå§‹åŒ–
            )
            for i in range(c1)  # ä¸ºæ¯ä¸ªè¾“å…¥é€šé“åˆ›å»ºä¸€ä¸ªå·ç§¯å±‚
        ]

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Processes input through parallel convolutions and concatenates results, trimming border pixels.
        é€šè¿‡å¹¶è¡Œå·ç§¯å¤„ç†è¾“å…¥å¹¶è¿æ¥ç»“æœï¼Œè£å‰ªè¾¹ç¼˜åƒç´ ã€‚
        """
        return tf.concat([m(x) for m, x in zip(self.conv, tf.split(inputs, self.c1, 3))], 3)[:, 1:-1, 1:-1]  # è¿”å›å¤„ç†åçš„ç»“æœ

class TFFocus(keras.layers.Layer):  # Focus wh information into c-space
    # Focus wh information into c-space
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """
        Initializes TFFocus layer to focus width and height information into channel space with custom convolution
        parameters.
        åˆå§‹åŒ–TFFocuså±‚ï¼Œå°†å®½åº¦å’Œé«˜åº¦ä¿¡æ¯èšç„¦åˆ°é€šé“ç©ºé—´ï¼Œæ”¯æŒè‡ªå®šä¹‰å·ç§¯å‚æ•°ã€‚

        Inputs are ch_in, ch_out, kernel, stride, padding, groups.
        è¾“å…¥å‚æ•°åŒ…æ‹¬è¾“å…¥é€šé“æ•°ã€è¾“å‡ºé€šé“æ•°ã€å·ç§¯æ ¸ã€æ­¥å¹…ã€å¡«å……å’Œåˆ†ç»„ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        self.conv = TFConv(c1 * 4, c2, k, s, p, g, act, w.conv)  # åˆ›å»ºTFConvå±‚ï¼Œè¾“å…¥é€šé“æ•°ä¸ºc1çš„4å€

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """
        Performs pixel shuffling and convolution on input tensor, downsampling by 2 and expanding channels by 4.
        å¯¹è¾“å…¥å¼ é‡æ‰§è¡Œåƒç´ é‡æ’å’Œå·ç§¯ï¼Œè¿›è¡Œ2å€ä¸‹é‡‡æ ·å¹¶å°†é€šé“æ‰©å±•4å€ã€‚

        Example x(b,w,h,c) -> y(b,w/2,h/2,4c).
        ç¤ºä¾‹ï¼šè¾“å…¥å½¢çŠ¶ä¸ºx(b,w,h,c)ï¼Œè¾“å‡ºå½¢çŠ¶ä¸ºy(b,w/2,h/2,4c)ã€‚
        """
        inputs = [inputs[:, ::2, ::2, :], inputs[:, 1::2, ::2, :], inputs[:, ::2, 1::2, :], inputs[:, 1::2, 1::2, :]]  # å°†è¾“å…¥å¼ é‡è¿›è¡Œé‡æ’
        return self.conv(tf.concat(inputs, 3))  # è¿æ¥é‡æ’åçš„å¼ é‡å¹¶é€šè¿‡å·ç§¯å±‚å¤„ç†


class TFBottleneck(keras.layers.Layer):  # æ ‡å‡†ç“¶é¢ˆå±‚
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """
        Initializes a standard bottleneck layer for TensorFlow models, expanding and contracting channels with optional
        shortcut.
        åˆå§‹åŒ–ä¸€ä¸ªæ ‡å‡†ç“¶é¢ˆå±‚ï¼Œç”¨äºTensorFlowæ¨¡å‹ï¼Œæ”¯æŒé€šé“æ‰©å±•å’Œæ”¶ç¼©ä»¥åŠå¯é€‰çš„å¿«æ·è¿æ¥ã€‚

        Arguments are ch_in, ch_out, shortcut, groups, expansion.
        è¾“å…¥å‚æ•°åŒ…æ‹¬è¾“å…¥é€šé“æ•°ã€è¾“å‡ºé€šé“æ•°ã€å¿«æ·è¿æ¥ã€åˆ†ç»„å’Œæ‰©å±•æ¯”ä¾‹ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        c_ = int(c2 * e)  # è®¡ç®—éšè—é€šé“æ•°
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)  # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.cv2 = TFConv(c_, c2, 3, 1, g=g, w=w.cv2)  # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚
        self.add = shortcut and c1 == c2  # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¿«æ·è¿æ¥

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Performs forward pass; if shortcut is True & input/output channels match, adds input to the convolution
        result.
        æ‰§è¡Œå‰å‘ä¼ æ’­ï¼›å¦‚æœå¿«æ·è¿æ¥ä¸ºTrueä¸”è¾“å…¥è¾“å‡ºé€šé“åŒ¹é…ï¼Œåˆ™å°†è¾“å…¥åŠ åˆ°å·ç§¯ç»“æœä¸­ã€‚
        """
        return inputs + self.cv2(self.cv1(inputs)) if self.add else self.cv2(self.cv1(inputs))  # è¿”å›ç»“æœ


class TFCrossConv(keras.layers.Layer):  # äº¤å‰å·ç§¯å±‚
    # Cross Convolution
    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """Initializes cross convolution layer with optional expansion, grouping, and shortcut addition capabilities.
        åˆå§‹åŒ–äº¤å‰å·ç§¯å±‚ï¼Œæ”¯æŒå¯é€‰çš„æ‰©å±•ã€åˆ†ç»„å’Œå¿«æ·è¿æ¥åŠŸèƒ½ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        c_ = int(c2 * e)  # è®¡ç®—éšè—é€šé“æ•°
        self.cv1 = TFConv(c1, c_, (1, k), (1, s), w=w.cv1)  # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.cv2 = TFConv(c_, c2, (k, 1), (s, 1), g=g, w=w.cv2)  # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚
        self.add = shortcut and c1 == c2  # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¿«æ·è¿æ¥

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Passes input through two convolutions optionally adding the input if channel dimensions match.
        å°†è¾“å…¥é€šè¿‡ä¸¤ä¸ªå·ç§¯å¤„ç†ï¼Œå¦‚æœé€šé“ç»´åº¦åŒ¹é…ï¼Œåˆ™å¯é€‰åœ°æ·»åŠ è¾“å…¥ã€‚
        """
        return inputs + self.cv2(self.cv1(inputs)) if self.add else self.cv2(self.cv1(inputs))  # è¿”å›ç»“æœ


class TFConv2d(keras.layers.Layer):  # æ›¿ä»£PyTorchçš„nn.Conv2D
    # Substitution for PyTorch nn.Conv2D
    def __init__(self, c1, c2, k, s=1, g=1, bias=True, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """Initializes a TensorFlow 2D convolution layer, mimicking PyTorch's nn.Conv2D functionality for given filter
        sizes and stride.
        åˆå§‹åŒ–ä¸€ä¸ªTensorFlow 2Då·ç§¯å±‚ï¼Œæ¨¡æ‹ŸPyTorchçš„nn.Conv2DåŠŸèƒ½ï¼Œæ”¯æŒç»™å®šçš„å·ç§¯æ ¸å¤§å°å’Œæ­¥å¹…ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        assert g == 1, "TF v2.2 Conv2D does not support 'groups' argument"  # ç¡®ä¿groupä¸º1
        self.conv = keras.layers.Conv2D(  # åˆ›å»ºConv2Då±‚
            filters=c2,  # è¾“å‡ºé€šé“æ•°
            kernel_size=k,  # å·ç§¯æ ¸å¤§å°
            strides=s,  # æ­¥å¹…
            padding="VALID",  # å¡«å……æ–¹å¼
            use_bias=bias,  # æ˜¯å¦ä½¿ç”¨åç½®
            kernel_initializer=keras.initializers.Constant(w.weight.permute(2, 3, 1, 0).numpy()),  # å·ç§¯æ ¸åˆå§‹åŒ–
            bias_initializer=keras.initializers.Constant(w.bias.numpy()) if bias else None,  # åç½®åˆå§‹åŒ–
        )

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Applies a convolution operation to the inputs and returns the result.
        å¯¹è¾“å…¥æ‰§è¡Œå·ç§¯æ“ä½œå¹¶è¿”å›ç»“æœã€‚
        """
        return self.conv(inputs)  # è¿”å›å·ç§¯ç»“æœ


class TFBottleneckCSP(keras.layers.Layer):  # CSPç“¶é¢ˆå±‚
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """
        Initializes CSP bottleneck layer with specified channel sizes, count, shortcut option, groups, and expansion
        ratio.
        åˆå§‹åŒ–CSPç“¶é¢ˆå±‚ï¼Œæ”¯æŒæŒ‡å®šçš„é€šé“å¤§å°ã€æ•°é‡ã€å¿«æ·è¿æ¥é€‰é¡¹ã€åˆ†ç»„å’Œæ‰©å±•æ¯”ä¾‹ã€‚

        Inputs are ch_in, ch_out, number, shortcut, groups, expansion.
        è¾“å…¥å‚æ•°åŒ…æ‹¬è¾“å…¥é€šé“æ•°ã€è¾“å‡ºé€šé“æ•°ã€æ•°é‡ã€å¿«æ·è¿æ¥ã€åˆ†ç»„å’Œæ‰©å±•æ¯”ä¾‹ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        c_ = int(c2 * e)  # è®¡ç®—éšè—é€šé“æ•°
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)  # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.cv2 = TFConv2d(c1, c_, 1, 1, bias=False, w=w.cv2)  # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚
        self.cv3 = TFConv2d(c_, c_, 1, 1, bias=False, w=w.cv3)  # åˆ›å»ºç¬¬ä¸‰ä¸ªå·ç§¯å±‚
        self.cv4 = TFConv(2 * c_, c2, 1, 1, w=w.cv4)  # åˆ›å»ºç¬¬å››ä¸ªå·ç§¯å±‚
        self.bn = TFBN(w.bn)  # åˆ›å»ºæ‰¹é‡å½’ä¸€åŒ–å±‚
        self.act = lambda x: keras.activations.swish(x)  # å®šä¹‰æ¿€æ´»å‡½æ•°ä¸ºSwish
        self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])  # åˆ›å»ºç“¶é¢ˆåºåˆ—

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Processes input through the model layers, concatenates, normalizes, activates, and reduces the output
        dimensions.
        é€šè¿‡æ¨¡å‹å±‚å¤„ç†è¾“å…¥ï¼Œè¿æ¥ã€å½’ä¸€åŒ–ã€æ¿€æ´»ï¼Œå¹¶å‡å°‘è¾“å‡ºç»´åº¦ã€‚
        """
        y1 = self.cv3(self.m(self.cv1(inputs)))  # å¤„ç†è¾“å…¥å¹¶å¾—åˆ°y1
        y2 = self.cv2(inputs)  # å¤„ç†è¾“å…¥å¾—åˆ°y2
        return self.cv4(self.act(self.bn(tf.concat((y1, y2), axis=3))))  # è¿”å›æœ€ç»ˆç»“æœ


class TFC3(keras.layers.Layer):  # CSPç“¶é¢ˆå±‚ï¼ŒåŒ…å«3ä¸ªå·ç§¯
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """
        Initializes CSP Bottleneck with 3 convolutions, supporting optional shortcuts and group convolutions.
        åˆå§‹åŒ–CSPç“¶é¢ˆï¼ŒåŒ…å«3ä¸ªå·ç§¯ï¼Œæ”¯æŒå¯é€‰çš„å¿«æ·è¿æ¥å’Œåˆ†ç»„å·ç§¯ã€‚

        Inputs are ch_in, ch_out, number, shortcut, groups, expansion.
        è¾“å…¥å‚æ•°åŒ…æ‹¬è¾“å…¥é€šé“æ•°ã€è¾“å‡ºé€šé“æ•°ã€æ•°é‡ã€å¿«æ·è¿æ¥ã€åˆ†ç»„å’Œæ‰©å±•æ¯”ä¾‹ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        c_ = int(c2 * e)  # è®¡ç®—éšè—é€šé“æ•°
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)  # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.cv2 = TFConv(c1, c_, 1, 1, w=w.cv2)  # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚
        self.cv3 = TFConv(2 * c_, c2, 1, 1, w=w.cv3)  # åˆ›å»ºç¬¬ä¸‰ä¸ªå·ç§¯å±‚
        self.m = keras.Sequential([TFBottleneck(c_, c_, shortcut, g, e=1.0, w=w.m[j]) for j in range(n)])  # åˆ›å»ºç“¶é¢ˆåºåˆ—

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """
        Processes input through a sequence of transformations for object detection (YOLOv5).
        é€šè¿‡ä¸€ç³»åˆ—å˜æ¢å¤„ç†è¾“å…¥ï¼Œç”¨äºç›®æ ‡æ£€æµ‹ï¼ˆYOLOv5ï¼‰ã€‚

        See https://github.com/ultralytics/yolov5.
        å‚è§ https://github.com/ultralytics/yolov5ã€‚
        """
        return self.cv3(tf.concat((self.m(self.cv1(inputs)), self.cv2(inputs)), axis=3))  # è¿”å›æœ€ç»ˆç»“æœ

class TFC3x(keras.layers.Layer):  # 3 module with cross-convolutions
    # 3 module with cross-convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """
        Initializes layer with cross-convolutions for enhanced feature extraction in object detection models.
        åˆå§‹åŒ–å±‚ï¼Œä½¿ç”¨äº¤å‰å·ç§¯ä»¥å¢å¼ºç›®æ ‡æ£€æµ‹æ¨¡å‹ä¸­çš„ç‰¹å¾æå–ã€‚

        Inputs are ch_in, ch_out, number, shortcut, groups, expansion.
        è¾“å…¥å‚æ•°åŒ…æ‹¬è¾“å…¥é€šé“æ•°ã€è¾“å‡ºé€šé“æ•°ã€æ•°é‡ã€å¿«æ·è¿æ¥ã€åˆ†ç»„å’Œæ‰©å±•æ¯”ä¾‹ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        c_ = int(c2 * e)  # hidden channels  # è®¡ç®—éšè—é€šé“æ•°
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)  # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.cv2 = TFConv(c1, c_, 1, 1, w=w.cv2)  # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚
        self.cv3 = TFConv(2 * c_, c2, 1, 1, w=w.cv3)  # åˆ›å»ºç¬¬ä¸‰ä¸ªå·ç§¯å±‚
        self.m = keras.Sequential(  # åˆ›å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹
            [TFCrossConv(c_, c_, k=3, s=1, g=g, e=1.0, shortcut=shortcut, w=w.m[j]) for j in range(n)]  # æ·»åŠ nä¸ªäº¤å‰å·ç§¯å±‚
        )

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Processes input through cascaded convolutions and merges features, returning the final tensor output.
        é€šè¿‡çº§è”å·ç§¯å¤„ç†è¾“å…¥å¹¶åˆå¹¶ç‰¹å¾ï¼Œè¿”å›æœ€ç»ˆçš„å¼ é‡è¾“å‡ºã€‚
        """
        return self.cv3(tf.concat((self.m(self.cv1(inputs)), self.cv2(inputs)), axis=3))  # è¿æ¥å·ç§¯ç»“æœå¹¶è¿”å›


class TFSPP(keras.layers.Layer):  # ç©ºé—´é‡‘å­—å¡”æ± åŒ–å±‚
    # Spatial pyramid pooling layer used in YOLOv3-SPP
    def __init__(self, c1, c2, k=(5, 9, 13), w=None):  # åˆå§‹åŒ–å‡½æ•°
        """Initializes a YOLOv3-SPP layer with specific input/output channels and kernel sizes for pooling.
        åˆå§‹åŒ–YOLOv3-SPPå±‚ï¼Œæ”¯æŒç‰¹å®šçš„è¾“å…¥/è¾“å‡ºé€šé“å’Œæ± åŒ–çš„å·ç§¯æ ¸å¤§å°ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        c_ = c1 // 2  # hidden channels  # è®¡ç®—éšè—é€šé“æ•°
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)  # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.cv2 = TFConv(c_ * (len(k) + 1), c2, 1, 1, w=w.cv2)  # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚ï¼Œè¾“å‡ºé€šé“æ•°ä¸ºkçš„é•¿åº¦åŠ 1å€çš„éšè—é€šé“æ•°
        self.m = [keras.layers.MaxPool2D(pool_size=x, strides=1, padding="SAME") for x in k]  # åˆ›å»ºå¤šä¸ªæœ€å¤§æ± åŒ–å±‚

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Processes input through two TFConv layers and concatenates with max-pooled outputs at intermediate stage.
        é€šè¿‡ä¸¤ä¸ªTFConvå±‚å¤„ç†è¾“å…¥ï¼Œå¹¶åœ¨ä¸­é—´é˜¶æ®µä¸æœ€å¤§æ± åŒ–è¾“å‡ºè¿æ¥ã€‚
        """
        x = self.cv1(inputs)  # é€šè¿‡ç¬¬ä¸€ä¸ªå·ç§¯å±‚å¤„ç†è¾“å…¥
        return self.cv2(tf.concat([x] + [m(x) for m in self.m], 3))  # è¿æ¥å·ç§¯è¾“å‡ºå’Œæ± åŒ–è¾“å‡ºï¼Œå¹¶é€šè¿‡ç¬¬äºŒä¸ªå·ç§¯å±‚å¤„ç†


class TFSPPF(keras.layers.Layer):  # ç©ºé—´é‡‘å­—å¡”æ± åŒ–-å¿«é€Ÿå±‚
    # Spatial pyramid pooling-Fast layer
    def __init__(self, c1, c2, k=5, w=None):  # åˆå§‹åŒ–å‡½æ•°
        """Initializes a fast spatial pyramid pooling layer with customizable in/out channels, kernel size, and
        weights.
        åˆå§‹åŒ–ä¸€ä¸ªå¿«é€Ÿç©ºé—´é‡‘å­—å¡”æ± åŒ–å±‚ï¼Œæ”¯æŒè‡ªå®šä¹‰çš„è¾“å…¥/è¾“å‡ºé€šé“ã€å·ç§¯æ ¸å¤§å°å’Œæƒé‡ã€‚
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        c_ = c1 // 2  # hidden channels  # è®¡ç®—éšè—é€šé“æ•°
        self.cv1 = TFConv(c1, c_, 1, 1, w=w.cv1)  # åˆ›å»ºç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.cv2 = TFConv(c_ * 4, c2, 1, 1, w=w.cv2)  # åˆ›å»ºç¬¬äºŒä¸ªå·ç§¯å±‚
        self.m = keras.layers.MaxPool2D(pool_size=k, strides=1, padding="SAME")  # åˆ›å»ºæœ€å¤§æ± åŒ–å±‚

    def call(self, inputs):  # å‰å‘ä¼ æ’­å‡½æ•°
        """Executes the model's forward pass, concatenating input features with three max-pooled versions before final
        convolution.
        æ‰§è¡Œæ¨¡å‹çš„å‰å‘ä¼ æ’­ï¼Œå°†è¾“å…¥ç‰¹å¾ä¸ä¸‰ä¸ªæœ€å¤§æ± åŒ–ç‰ˆæœ¬è¿æ¥ï¼Œç„¶åè¿›è¡Œæœ€ç»ˆå·ç§¯ã€‚
        """
        x = self.cv1(inputs)  # é€šè¿‡ç¬¬ä¸€ä¸ªå·ç§¯å±‚å¤„ç†è¾“å…¥
        y1 = self.m(x)  # å¯¹xè¿›è¡Œæœ€å¤§æ± åŒ–
        y2 = self.m(y1)  # å¯¹y1è¿›è¡Œæœ€å¤§æ± åŒ–
        return self.cv2(tf.concat([x, y1, y2, self.m(y2)], 3))  # è¿æ¥æ‰€æœ‰è¾“å‡ºå¹¶é€šè¿‡ç¬¬äºŒä¸ªå·ç§¯å±‚å¤„ç†

class TFDetect(keras.layers.Layer):
    # TF YOLOv5 Detect layer
    def __init__(self, nc=80, anchors=(), ch=(), imgsz=(640, 640), w=None):
        """Initializes YOLOv5 detection layer for TensorFlow with configurable classes, anchors, channels, and image
        size.
        åˆå§‹åŒ–YOLOv5æ£€æµ‹å±‚ï¼Œæ”¯æŒå¯é…ç½®çš„ç±»åˆ«ã€é”šæ¡†ã€é€šé“å’Œå›¾åƒå¤§å°ã€‚
        """
        super().__init__()
        self.stride = tf.convert_to_tensor(w.stride.numpy(), dtype=tf.float32)
        self.nc = nc  # number of classes  # ç±»åˆ«æ•°é‡
        self.no = nc + 5  # number of outputs per anchor  # æ¯ä¸ªé”šæ¡†çš„è¾“å‡ºæ•°é‡
        self.nl = len(anchors)  # number of detection layers  # æ£€æµ‹å±‚æ•°é‡
        self.na = len(anchors[0]) // 2  # number of anchors  # é”šæ¡†æ•°é‡
        self.grid = [tf.zeros(1)] * self.nl  # init grid  # åˆå§‹åŒ–ç½‘æ ¼
        self.anchors = tf.convert_to_tensor(w.anchors.numpy(), dtype=tf.float32)
        self.anchor_grid = tf.reshape(self.anchors * tf.reshape(self.stride, [self.nl, 1, 1]), [self.nl, 1, -1, 1, 2])
        self.m = [TFConv2d(x, self.no * self.na, 1, w=w.m[i]) for i, x in enumerate(ch)]
        self.training = False  # set to False after building model  # æ„å»ºæ¨¡å‹åè®¾ç½®ä¸ºFalse
        self.imgsz = imgsz
        for i in range(self.nl):
            ny, nx = self.imgsz[0] // self.stride[i], self.imgsz[1] // self.stride[i]
            self.grid[i] = self._make_grid(nx, ny)

    def call(self, inputs):
        """Performs forward pass through the model layers to predict object bounding boxes and classifications.
        é€šè¿‡æ¨¡å‹å±‚æ‰§è¡Œå‰å‘ä¼ æ’­ï¼Œä»¥é¢„æµ‹ç‰©ä½“çš„è¾¹ç•Œæ¡†å’Œåˆ†ç±»ã€‚
        """
        z = []  # inference output  # æ¨ç†è¾“å‡º
        x = []
        for i in range(self.nl):
            x.append(self.m[i](inputs[i]))
            # x(bs,20,20,255) to x(bs,3,20,20,85)
            ny, nx = self.imgsz[0] // self.stride[i], self.imgsz[1] // self.stride[i]
            x[i] = tf.reshape(x[i], [-1, ny * nx, self.na, self.no])

            if not self.training:  # inference  # æ¨ç†é˜¶æ®µ
                y = x[i]
                grid = tf.transpose(self.grid[i], [0, 2, 1, 3]) - 0.5
                anchor_grid = tf.transpose(self.anchor_grid[i], [0, 2, 1, 3]) * 4
                xy = (tf.sigmoid(y[..., 0:2]) * 2 + grid) * self.stride[i]  # xy
                wh = tf.sigmoid(y[..., 2:4]) ** 2 * anchor_grid
                # Normalize xywh to 0-1 to reduce calibration error
                xy /= tf.constant([[self.imgsz[1], self.imgsz[0]]], dtype=tf.float32)
                wh /= tf.constant([[self.imgsz[1], self.imgsz[0]]], dtype=tf.float32)
                y = tf.concat([xy, wh, tf.sigmoid(y[..., 4 : 5 + self.nc]), y[..., 5 + self.nc :]], -1)
                z.append(tf.reshape(y, [-1, self.na * ny * nx, self.no]))

        return tf.transpose(x, [0, 2, 1, 3]) if self.training else (tf.concat(z, 1),)

    @staticmethod
    def _make_grid(nx=20, ny=20):
        """Generates a 2D grid of coordinates in (x, y) format with shape [1, 1, ny*nx, 2].
        ç”Ÿæˆä¸€ä¸ªäºŒç»´åæ ‡ç½‘æ ¼ï¼Œæ ¼å¼ä¸º(x, y)ï¼Œå½¢çŠ¶ä¸º[1, 1, ny*nx, 2]ã€‚
        """
        xv, yv = tf.meshgrid(tf.range(nx), tf.range(ny))
        return tf.cast(tf.reshape(tf.stack([xv, yv], 2), [1, 1, ny * nx, 2]), dtype=tf.float32)



class TFSegment(TFDetect):
    # YOLOv5 Segment head for segmentation models
    # YOLOv5åˆ†å‰²å¤´ï¼Œç”¨äºåˆ†å‰²æ¨¡å‹
    def __init__(self, nc=80, anchors=(), nm=32, npr=256, ch=(), imgsz=(640, 640), w=None):
        """Initializes YOLOv5 Segment head with specified channel depths, anchors, and input size for segmentation
        models.
        """
        # åˆå§‹åŒ–YOLOv5åˆ†å‰²å¤´ï¼ŒæŒ‡å®šé€šé“æ·±åº¦ã€é”šæ¡†å’Œè¾“å…¥å¤§å°
        super().__init__(nc, anchors, ch, imgsz, w)  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        self.nm = nm  # number of masks
        # æ©è†œæ•°é‡
        self.npr = npr  # number of protos
        # åŸå‹æ•°é‡
        self.no = 5 + nc + self.nm  # number of outputs per anchor
        # æ¯ä¸ªé”šæ¡†çš„è¾“å‡ºæ•°é‡
        self.m = [TFConv2d(x, self.no * self.na, 1, w=w.m[i]) for i, x in enumerate(ch)]  # output conv
        # è¾“å‡ºå·ç§¯å±‚
        self.proto = TFProto(ch[0], self.npr, self.nm, w=w.proto)  # protos
        # åŸå‹å±‚
        self.detect = TFDetect.call  # æ£€æµ‹è°ƒç”¨

    def call(self, x):
        """Applies detection and proto layers on input, returning detections and optionally protos if training."""
        # åœ¨è¾“å…¥ä¸Šåº”ç”¨æ£€æµ‹å’ŒåŸå‹å±‚ï¼Œè¿”å›æ£€æµ‹ç»“æœï¼Œå¹¶åœ¨è®­ç»ƒæ—¶å¯é€‰è¿”å›åŸå‹
        p = self.proto(x[0])  # é€šè¿‡åŸå‹å±‚å¤„ç†è¾“å…¥
        # p = TFUpsample(None, scale_factor=4, mode='nearest')(self.proto(x[0]))  # (optional) full-size protos
        # p = TFUpsample(None, scale_factor=4, mode='nearest')(self.proto(x[0]))  # ï¼ˆå¯é€‰ï¼‰å…¨å°ºå¯¸åŸå‹
        p = tf.transpose(p, [0, 3, 1, 2])  # from shape(1,160,160,32) to shape(1,32,160,160)
        # å°†å½¢çŠ¶ä»(1,160,160,32)è½¬æ¢ä¸º(1,32,160,160)
        x = self.detect(self, x)  # è¿›è¡Œæ£€æµ‹
        return (x, p) if self.training else (x[0], p)  # å¦‚æœåœ¨è®­ç»ƒä¸­è¿”å›(x, p)ï¼Œå¦åˆ™è¿”å›(x[0], p)


class TFProto(keras.layers.Layer):
    def __init__(self, c1, c_=256, c2=32, w=None):
        """Initializes TFProto layer with convolutional and upsampling layers for feature extraction and
        transformation.
        """
        # åˆå§‹åŒ–TFProtoå±‚ï¼ŒåŒ…å«å·ç§¯å’Œä¸Šé‡‡æ ·å±‚ï¼Œç”¨äºç‰¹å¾æå–å’Œè½¬æ¢
        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        self.cv1 = TFConv(c1, c_, k=3, w=w.cv1)  # ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.upsample = TFUpsample(None, scale_factor=2, mode="nearest")  # ä¸Šé‡‡æ ·å±‚
        self.cv2 = TFConv(c_, c_, k=3, w=w.cv2)  # ç¬¬äºŒä¸ªå·ç§¯å±‚
        self.cv3 = TFConv(c_, c2, w=w.cv3)  # ç¬¬ä¸‰ä¸ªå·ç§¯å±‚

    def call(self, inputs):
        """Performs forward pass through the model, applying convolutions and upscaling on input tensor."""
        # åœ¨æ¨¡å‹ä¸­æ‰§è¡Œå‰å‘ä¼ æ’­ï¼Œå¯¹è¾“å…¥å¼ é‡åº”ç”¨å·ç§¯å’Œä¸Šé‡‡æ ·
        return self.cv3(self.cv2(self.upsample(self.cv1(inputs))))  # è¿”å›ç»è¿‡ä¸‰ä¸ªå·ç§¯å±‚å’Œä¸Šé‡‡æ ·çš„ç»“æœ


class TFUpsample(keras.layers.Layer):
    # TF version of torch.nn.Upsample()
    # TensorFlowç‰ˆæœ¬çš„torch.nn.Upsample()
    def __init__(self, size, scale_factor, mode, w=None):
        """
        Initializes a TensorFlow upsampling layer with specified size, scale_factor, and mode, ensuring scale_factor is
        even.

        Warning: all arguments needed including 'w'
        """
        # åˆå§‹åŒ–ä¸€ä¸ªTensorFlowä¸Šé‡‡æ ·å±‚ï¼ŒæŒ‡å®šå¤§å°ã€ç¼©æ”¾å› å­å’Œæ¨¡å¼ï¼Œç¡®ä¿ç¼©æ”¾å› å­ä¸ºå¶æ•°
        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        assert scale_factor % 2 == 0, "scale_factor must be multiple of 2"
        # ç¡®ä¿ç¼©æ”¾å› å­æ˜¯2çš„å€æ•°
        self.upsample = lambda x: tf.image.resize(x, (x.shape[1] * scale_factor, x.shape[2] * scale_factor), mode)
        # ä½¿ç”¨tf.image.resizeè¿›è¡Œä¸Šé‡‡æ ·ï¼Œè°ƒæ•´å›¾åƒå¤§å°

        # self.upsample = keras.layers.UpSampling2D(size=scale_factor, interpolation=mode)
        # # ä½¿ç”¨Kerasçš„UpSampling2Då±‚è¿›è¡Œä¸Šé‡‡æ ·ï¼Œæ’å€¼æ¨¡å¼ä¸ºmode
        # with default arguments: align_corners=False, half_pixel_centers=False
        # # é»˜è®¤å‚æ•°ï¼šalign_corners=False, half_pixel_centers=False
        # self.upsample = lambda x: tf.raw_ops.ResizeNearestNeighbor(images=x,
        #                                                            size=(x.shape[1] * 2, x.shape[2] * 2))
        # # ä½¿ç”¨åŸå§‹æ“ä½œResizeNearestNeighborè¿›è¡Œä¸Šé‡‡æ ·ï¼Œå¤§å°ä¸ºåŸæ¥çš„2å€

    def call(self, inputs):
        """Applies upsample operation to inputs using nearest neighbor interpolation."""
        # ä½¿ç”¨æœ€è¿‘é‚»æ’å€¼å¯¹è¾“å…¥åº”ç”¨ä¸Šé‡‡æ ·æ“ä½œ
        return self.upsample(inputs)  # è¿”å›ä¸Šé‡‡æ ·åçš„ç»“æœ


class TFConcat(keras.layers.Layer):
    # TF version of torch.concat()
    # TensorFlowç‰ˆæœ¬çš„torch.concat()
    def __init__(self, dimension=1, w=None):
        """Initializes a TensorFlow layer for NCHW to NHWC concatenation, requiring dimension=1."""
        # åˆå§‹åŒ–ä¸€ä¸ªTensorFlowå±‚ï¼Œç”¨äºNCHWåˆ°NHWCçš„æ‹¼æ¥ï¼Œè¦æ±‚ç»´åº¦ä¸º1
        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        assert dimension == 1, "convert only NCHW to NHWC concat"
        # ç¡®ä¿åªè¿›è¡ŒNCHWåˆ°NHWCçš„æ‹¼æ¥
        self.d = 3  # è®¾ç½®æ‹¼æ¥çš„ç»´åº¦ä¸º3ï¼ˆæœ€åä¸€ä¸ªç»´åº¦ï¼‰

    def call(self, inputs):
        """Concatenates a list of tensors along the last dimension, used for NCHW to NHWC conversion."""
        # åœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šæ‹¼æ¥å¼ é‡åˆ—è¡¨ï¼Œç”¨äºNCHWåˆ°NHWCçš„è½¬æ¢
        return tf.concat(inputs, self.d)  # è¿”å›æ‹¼æ¥åçš„ç»“æœ

def parse_model(d, ch, model, imgsz):
    """Parses a model definition dict `d` to create YOLOv5 model layers, including dynamic channel adjustments."""
    # è§£ææ¨¡å‹å®šä¹‰å­—å…¸`d`ï¼Œåˆ›å»ºYOLOv5æ¨¡å‹å±‚ï¼ŒåŒ…æ‹¬åŠ¨æ€é€šé“è°ƒæ•´
    LOGGER.info(f"\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}")
    # æ‰“å°æ—¥å¿—ä¿¡æ¯ï¼Œæ˜¾ç¤ºæ¨¡å‹çš„æ¥æºã€æ•°é‡ã€å‚æ•°ã€æ¨¡å—å’Œå‚æ•°åˆ—è¡¨
    anchors, nc, gd, gw, ch_mul = (
        d["anchors"],
        d["nc"],
        d["depth_multiple"],
        d["width_multiple"],
        d.get("channel_multiple"),
    )
    # ä»å­—å…¸ä¸­æå–é”šæ¡†ã€ç±»åˆ«æ•°é‡ã€æ·±åº¦å’Œå®½åº¦å€æ•°ä»¥åŠé€šé“å€æ•°
    na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors
    # è®¡ç®—é”šæ¡†çš„æ•°é‡
    no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)
    # è®¡ç®—è¾“å‡ºæ•°é‡ = é”šæ¡†æ•°é‡ * (ç±»åˆ«æ•°é‡ + 5)
    if not ch_mul:
        ch_mul = 8
    # å¦‚æœæ²¡æœ‰æŒ‡å®šé€šé“å€æ•°ï¼Œåˆ™é»˜è®¤è®¾ç½®ä¸º8

    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out
    # åˆå§‹åŒ–å±‚åˆ—è¡¨ã€ä¿å­˜åˆ—è¡¨å’Œè¾“å‡ºé€šé“
    for i, (f, n, m, args) in enumerate(d["backbone"] + d["head"]):  # from, number, module, args
        # éå†éª¨å¹²ç½‘ç»œå’Œå¤´éƒ¨çš„å±‚å®šä¹‰
        m_str = m  # ä¿å­˜æ¨¡å—åç§°
        m = eval(m) if isinstance(m, str) else m  # eval strings
        # å¦‚æœæ¨¡å—åç§°æ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™ä½¿ç”¨evalå°†å…¶è½¬æ¢ä¸ºå®é™…æ¨¡å—
        for j, a in enumerate(args):
            try:
                args[j] = eval(a) if isinstance(a, str) else a  # eval strings
                # å¯¹å‚æ•°è¿›è¡Œevalå¤„ç†ï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ™è½¬æ¢
            except NameError:
                pass  # å¦‚æœå‡ºç°NameErrorï¼Œåˆ™è·³è¿‡

        n = max(round(n * gd), 1) if n > 1 else n  # depth gain
        # è®¡ç®—æ·±åº¦å¢ç›Šï¼Œå¦‚æœnå¤§äº1ï¼Œåˆ™æ ¹æ®æ·±åº¦å€æ•°è°ƒæ•´n
        if m in [
            nn.Conv2d,
            Conv,
            DWConv,
            DWConvTranspose2d,
            Bottleneck,
            SPP,
            SPPF,
            MixConv2d,
            Focus,
            CrossConv,
            BottleneckCSP,
            C3,
            C3x,
        ]:
            # å¦‚æœæ¨¡å—æ˜¯å·ç§¯æˆ–å…¶ä»–ç‰¹å®šç±»å‹
            c1, c2 = ch[f], args[0]  # è·å–è¾“å…¥é€šé“å’Œè¾“å‡ºé€šé“
            c2 = make_divisible(c2 * gw, ch_mul) if c2 != no else c2
            # æ ¹æ®å®½åº¦å€æ•°è°ƒæ•´è¾“å‡ºé€šé“ï¼Œç¡®ä¿å¯è¢«é€šé“å€æ•°æ•´é™¤

            args = [c1, c2, *args[1:]]  # æ›´æ–°å‚æ•°åˆ—è¡¨
            if m in [BottleneckCSP, C3, C3x]:
                args.insert(2, n)  # åœ¨å‚æ•°åˆ—è¡¨ä¸­æ’å…¥n
                n = 1  # å°†nè®¾ç½®ä¸º1
        elif m is nn.BatchNorm2d:
            args = [ch[f]]  # å¦‚æœæ¨¡å—æ˜¯BatchNormï¼Œåˆ™åªéœ€è¾“å…¥é€šé“
        elif m is Concat:
            c2 = sum(ch[-1 if x == -1 else x + 1] for x in f)  # è®¡ç®—è¾“å‡ºé€šé“
        elif m in [Detect, Segment]:
            args.append([ch[x + 1] for x in f])  # æ·»åŠ åç»­é€šé“
            if isinstance(args[1], int):  # number of anchors
                args[1] = [list(range(args[1] * 2))] * len(f)  # å¦‚æœæ˜¯é”šæ¡†æ•°é‡ï¼Œåˆ™ç”Ÿæˆé”šæ¡†åˆ—è¡¨
            if m is Segment:
                args[3] = make_divisible(args[3] * gw, ch_mul)  # å¯¹äºåˆ†å‰²æ¨¡å—ï¼Œè°ƒæ•´å‚æ•°
            args.append(imgsz)  # æ·»åŠ å›¾åƒå¤§å°å‚æ•°
        else:
            c2 = ch[f]  # å¯¹äºå…¶ä»–æ¨¡å—ï¼Œç›´æ¥è·å–è¾“å‡ºé€šé“

        tf_m = eval("TF" + m_str.replace("nn.", ""))  # å°†æ¨¡å—åç§°è½¬æ¢ä¸ºTFæ¨¡å—
        m_ = (
            keras.Sequential([tf_m(*args, w=model.model[i][j]) for j in range(n)])
            if n > 1
            else tf_m(*args, w=model.model[i])
        )  # åˆ›å»ºæ¨¡å—

        torch_m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # åˆ›å»ºTorchæ¨¡å—
        t = str(m)[8:-2].replace("__main__.", "")  # è·å–æ¨¡å—ç±»å‹
        np = sum(x.numel() for x in torch_m_.parameters())  # è®¡ç®—å‚æ•°æ•°é‡
        m_.i, m_.f, m_.type, m_.np = i, f, t, np  # é™„åŠ ç´¢å¼•ã€æ¥æºç´¢å¼•ã€ç±»å‹å’Œå‚æ•°æ•°é‡
        LOGGER.info(f"{i:>3}{str(f):>18}{str(n):>3}{np:>10}  {t:<40}{str(args):<30}")  # æ‰“å°ä¿¡æ¯
        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # å°†ç´¢å¼•æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨
        layers.append(m_)  # å°†æ¨¡å—æ·»åŠ åˆ°å±‚åˆ—è¡¨
        ch.append(c2)  # æ›´æ–°é€šé“åˆ—è¡¨
    return keras.Sequential(layers), sorted(save)  # è¿”å›æ„å»ºçš„Sequentialæ¨¡å‹å’Œä¿å­˜åˆ—è¡¨

class TFModel:
    # TF YOLOv5 model
    # TensorFlow YOLOv5æ¨¡å‹
    def __init__(self, cfg="yolov5s.yaml", ch=3, nc=None, model=None, imgsz=(640, 640)):
        """Initializes TF YOLOv5 model with specified configuration, channels, classes, model instance, and input
        size.
        """
        # ä½¿ç”¨æŒ‡å®šçš„é…ç½®ã€é€šé“ã€ç±»åˆ«ã€æ¨¡å‹å®ä¾‹å’Œè¾“å…¥å¤§å°åˆå§‹åŒ–TF YOLOv5æ¨¡å‹
        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        if isinstance(cfg, dict):
            self.yaml = cfg  # model dict
            # å¦‚æœcfgæ˜¯å­—å…¸ï¼Œåˆ™å°†å…¶ä½œä¸ºæ¨¡å‹å­—å…¸
        else:  # is *.yaml
            import yaml  # for torch hub
            # å¦‚æœcfgæ˜¯yamlæ–‡ä»¶ï¼Œåˆ™å¯¼å…¥yamlåº“

            self.yaml_file = Path(cfg).name  # è·å–yamlæ–‡ä»¶å
            with open(cfg) as f:
                self.yaml = yaml.load(f, Loader=yaml.FullLoader)  # model dict
                # è¯»å–yamlæ–‡ä»¶å¹¶åŠ è½½ä¸ºæ¨¡å‹å­—å…¸

        # Define model
        # å®šä¹‰æ¨¡å‹
        if nc and nc != self.yaml["nc"]:
            LOGGER.info(f"Overriding {cfg} nc={self.yaml['nc']} with nc={nc}")
            # å¦‚æœæä¾›çš„ç±»åˆ«æ•°é‡ä¸yamlä¸­çš„ä¸ä¸€è‡´ï¼Œè®°å½•æ—¥å¿—ä¿¡æ¯
            self.yaml["nc"] = nc  # override yaml value
            # ç”¨æä¾›çš„ç±»åˆ«æ•°é‡è¦†ç›–yamlä¸­çš„å€¼
        self.model, self.savelist = parse_model(deepcopy(self.yaml), ch=[ch], model=model, imgsz=imgsz)
        # è§£ææ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹å±‚å’Œä¿å­˜åˆ—è¡¨

    def predict(
        self,
        inputs,
        tf_nms=False,
        agnostic_nms=False,
        topk_per_class=100,
        topk_all=100,
        iou_thres=0.45,
        conf_thres=0.25,
    ):
        # è¿›è¡Œé¢„æµ‹
        y = []  # outputs
        # åˆå§‹åŒ–è¾“å‡ºåˆ—è¡¨
        x = inputs  # è¾“å…¥æ•°æ®
        for m in self.model.layers:
            if m.f != -1:  # if not from previous layer
                # å¦‚æœä¸æ˜¯æ¥è‡ªå‰ä¸€å±‚
                x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers
                # æ ¹æ®å±‚çš„æ¥æºè·å–è¾“å…¥æ•°æ®

            x = m(x)  # run
            # è¿è¡Œå½“å‰å±‚
            y.append(x if m.i in self.savelist else None)  # save output
            # å¦‚æœå½“å‰å±‚çš„ç´¢å¼•åœ¨ä¿å­˜åˆ—è¡¨ä¸­ï¼Œåˆ™ä¿å­˜è¾“å‡º

        # Add TensorFlow NMS
        # æ·»åŠ TensorFlowéæå¤§å€¼æŠ‘åˆ¶
        if tf_nms:
            boxes = self._xywh2xyxy(x[0][..., :4])  # å°†xywhæ ¼å¼è½¬æ¢ä¸ºxyxyæ ¼å¼
            probs = x[0][:, :, 4:5]  # è·å–ç½®ä¿¡åº¦
            classes = x[0][:, :, 5:]  # è·å–ç±»åˆ«
            scores = probs * classes  # è®¡ç®—å¾—åˆ†
            if agnostic_nms:
                nms = AgnosticNMS()((boxes, classes, scores), topk_all, iou_thres, conf_thres)
                # å¦‚æœä½¿ç”¨æ— å…³ç±»åˆ«çš„NMSï¼Œåˆ™è°ƒç”¨AgnosticNMS
            else:
                boxes = tf.expand_dims(boxes, 2)  # æ‰©å±•ç»´åº¦
                nms = tf.image.combined_non_max_suppression(
                    boxes, scores, topk_per_class, topk_all, iou_thres, conf_thres, clip_boxes=False
                )
                # ä½¿ç”¨TensorFlowçš„combined_non_max_suppressionè¿›è¡ŒNMS
            return (nms,)  # è¿”å›NMSç»“æœ
        return x  # output [1,6300,85] = [xywh, conf, class0, class1, ...]
        # è¿”å›è¾“å‡ºï¼Œæ ¼å¼ä¸º[xywh, ç½®ä¿¡åº¦, ç±»åˆ«0, ç±»åˆ«1, ...]

    @staticmethod
    def _xywh2xyxy(xywh):
        """Converts bounding box format from [x, y, w, h] to [x1, y1, x2, y2], where xy1=top-left and xy2=bottom-
        right.
        """
        # å°†è¾¹ç•Œæ¡†æ ¼å¼ä»[x, y, w, h]è½¬æ¢ä¸º[x1, y1, x2, y2]ï¼Œå…¶ä¸­xy1ä¸ºå·¦ä¸Šè§’ï¼Œxy2ä¸ºå³ä¸‹è§’
        x, y, w, h = tf.split(xywh, num_or_size_splits=4, axis=-1)  # å°†xywhæ‹†åˆ†ä¸ºx, y, w, h
        return tf.concat([x - w / 2, y - h / 2, x + w / 2, y + h / 2], axis=-1)
        # è¿”å›æ‹¼æ¥åçš„ç»“æœï¼Œè®¡ç®—å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡


class AgnosticNMS(keras.layers.Layer):
    # TF Agnostic NMS
    # TensorFlowæ— å…³ç±»åˆ«çš„éæå¤§å€¼æŠ‘åˆ¶
    def call(self, input, topk_all, iou_thres, conf_thres):
        """Performs agnostic NMS on input tensors using given thresholds and top-K selection."""
        # ä½¿ç”¨ç»™å®šçš„é˜ˆå€¼å’ŒTop-Ké€‰æ‹©åœ¨è¾“å…¥å¼ é‡ä¸Šæ‰§è¡Œæ— å…³ç±»åˆ«çš„éæå¤§å€¼æŠ‘åˆ¶
        return tf.map_fn(
            lambda x: self._nms(x, topk_all, iou_thres, conf_thres),
            input,
            fn_output_signature=(tf.float32, tf.float32, tf.float32, tf.int32),
            name="agnostic_nms",
        )
        # å¯¹è¾“å…¥çš„æ¯ä¸ªå…ƒç´ åº”ç”¨_nmså‡½æ•°ï¼Œè¿”å›å¤„ç†åçš„ç»“æœ

    @staticmethod
    def _nms(x, topk_all=100, iou_thres=0.45, conf_thres=0.25):
        """Performs agnostic non-maximum suppression (NMS) on detected objects, filtering based on IoU and confidence
        thresholds.
        """
        # å¯¹æ£€æµ‹åˆ°çš„å¯¹è±¡æ‰§è¡Œæ— å…³ç±»åˆ«çš„éæå¤§å€¼æŠ‘åˆ¶ï¼ŒåŸºäºIoUå’Œç½®ä¿¡åº¦é˜ˆå€¼è¿›è¡Œè¿‡æ»¤
        boxes, classes, scores = x  # è§£åŒ…è¾“å…¥æ•°æ®
        class_inds = tf.cast(tf.argmax(classes, axis=-1), tf.float32)  # è·å–ç±»åˆ«ç´¢å¼•
        scores_inp = tf.reduce_max(scores, -1)  # è·å–æ¯ä¸ªæ¡†çš„æœ€å¤§å¾—åˆ†
        selected_inds = tf.image.non_max_suppression(
            boxes, scores_inp, max_output_size=topk_all, iou_threshold=iou_thres, score_threshold=conf_thres
        )
        # ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶é€‰æ‹©æ¡†ï¼Œè¿”å›é€‰æ‹©çš„ç´¢å¼•
        selected_boxes = tf.gather(boxes, selected_inds)  # æ ¹æ®é€‰æ‹©çš„ç´¢å¼•è·å–æ¡†
        padded_boxes = tf.pad(
            selected_boxes,
            paddings=[[0, topk_all - tf.shape(selected_boxes)[0]], [0, 0]],
            mode="CONSTANT",
            constant_values=0.0,
        )
        # å¯¹é€‰æ‹©çš„æ¡†è¿›è¡Œå¡«å……ï¼Œç¡®ä¿è¾“å‡ºå¤§å°ä¸ºtopk_all
        selected_scores = tf.gather(scores_inp, selected_inds)  # æ ¹æ®é€‰æ‹©çš„ç´¢å¼•è·å–å¾—åˆ†
        padded_scores = tf.pad(
            selected_scores,
            paddings=[[0, topk_all - tf.shape(selected_boxes)[0]]],
            mode="CONSTANT",
            constant_values=-1.0,
        )
        # å¯¹é€‰æ‹©çš„å¾—åˆ†è¿›è¡Œå¡«å……ï¼Œç¡®ä¿è¾“å‡ºå¤§å°ä¸ºtopk_all
        selected_classes = tf.gather(class_inds, selected_inds)  # æ ¹æ®é€‰æ‹©çš„ç´¢å¼•è·å–ç±»åˆ«
        padded_classes = tf.pad(
            selected_classes,
            paddings=[[0, topk_all - tf.shape(selected_boxes)[0]]],
            mode="CONSTANT",
            constant_values=-1.0,
        )
        # å¯¹é€‰æ‹©çš„ç±»åˆ«è¿›è¡Œå¡«å……ï¼Œç¡®ä¿è¾“å‡ºå¤§å°ä¸ºtopk_all
        valid_detections = tf.shape(selected_inds)[0]  # è·å–æœ‰æ•ˆæ£€æµ‹çš„æ•°é‡
        return padded_boxes, padded_scores, padded_classes, valid_detections
        # è¿”å›å¡«å……åçš„æ¡†ã€å¾—åˆ†ã€ç±»åˆ«å’Œæœ‰æ•ˆæ£€æµ‹æ•°é‡


def activations(act=nn.SiLU):
    """Converts PyTorch activations to TensorFlow equivalents, supporting LeakyReLU, Hardswish, and SiLU/Swish."""
    # å°†PyTorchæ¿€æ´»å‡½æ•°è½¬æ¢ä¸ºTensorFlowç­‰æ•ˆå‡½æ•°ï¼Œæ”¯æŒLeakyReLUã€Hardswishå’ŒSiLU/Swish
    if isinstance(act, nn.LeakyReLU):
        return lambda x: keras.activations.relu(x, alpha=0.1)  # LeakyReLUè½¬æ¢
    elif isinstance(act, nn.Hardswish):
        return lambda x: x * tf.nn.relu6(x + 3) * 0.166666667  # Hardswishè½¬æ¢
    elif isinstance(act, (nn.SiLU, SiLU)):
        return lambda x: keras.activations.swish(x)  # SiLU/Swishè½¬æ¢
    else:
        raise Exception(f"no matching TensorFlow activation found for PyTorch activation {act}")
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„æ¿€æ´»å‡½æ•°ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸


def representative_dataset_gen(dataset, ncalib=100):
    """Generates a representative dataset for calibration by yielding transformed numpy arrays from the input
    dataset.
    """
    # é€šè¿‡ä»è¾“å…¥æ•°æ®é›†ä¸­ç”Ÿæˆè½¬æ¢åçš„numpyæ•°ç»„æ¥ç”Ÿæˆç”¨äºæ ¡å‡†çš„ä»£è¡¨æ€§æ•°æ®é›†
    for n, (path, img, im0s, vid_cap, string) in enumerate(dataset):
        im = np.transpose(img, [1, 2, 0])  # è½¬æ¢å›¾åƒç»´åº¦
        im = np.expand_dims(im, axis=0).astype(np.float32)  # æ‰©å±•ç»´åº¦å¹¶è½¬æ¢ä¸ºfloat32
        im /= 255  # å½’ä¸€åŒ–å›¾åƒ
        yield [im]  # ç”Ÿæˆå¤„ç†åçš„å›¾åƒ
        if n >= ncalib:
            break  # å¦‚æœè¾¾åˆ°æ ¡å‡†æ•°é‡ï¼Œåˆ™åœæ­¢ç”Ÿæˆ


def run(
    weights=ROOT / "yolov5s.pt",  # weights path
    # æƒé‡è·¯å¾„
    imgsz=(640, 640),  # inference size h,w
    # æ¨ç†æ—¶çš„å›¾åƒå°ºå¯¸ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰
    batch_size=1,  # batch size
    # æ‰¹å¤„ç†å¤§å°
    dynamic=False,  # dynamic batch size
    # æ˜¯å¦ä½¿ç”¨åŠ¨æ€æ‰¹å¤„ç†å¤§å°
):
    # PyTorch model
    # PyTorchæ¨¡å‹
    im = torch.zeros((batch_size, 3, *imgsz))  # BCHW image
    # åˆ›å»ºä¸€ä¸ªå…¨é›¶çš„å¼ é‡ï¼Œå½¢çŠ¶ä¸ºï¼ˆæ‰¹å¤§å°ï¼Œé€šé“æ•°ï¼Œå›¾åƒé«˜åº¦ï¼Œå›¾åƒå®½åº¦ï¼‰
    model = attempt_load(weights, device=torch.device("cpu"), inplace=True, fuse=False)
    # åŠ è½½PyTorchæ¨¡å‹
    _ = model(im)  # inference
    # å¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ¨ç†
    model.info()  # æ‰“å°æ¨¡å‹ä¿¡æ¯

    # TensorFlow model
    # TensorFlowæ¨¡å‹
    im = tf.zeros((batch_size, *imgsz, 3))  # BHWC image
    # åˆ›å»ºä¸€ä¸ªå…¨é›¶çš„å¼ é‡ï¼Œå½¢çŠ¶ä¸ºï¼ˆæ‰¹å¤§å°ï¼Œå›¾åƒé«˜åº¦ï¼Œå›¾åƒå®½åº¦ï¼Œé€šé“æ•°ï¼‰
    tf_model = TFModel(cfg=model.yaml, model=model, nc=model.nc, imgsz=imgsz)
    # åˆ›å»ºTensorFlowæ¨¡å‹å®ä¾‹
    _ = tf_model.predict(im)  # inference
    # å¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ¨ç†

    # Keras model
    # Kerasæ¨¡å‹
    im = keras.Input(shape=(*imgsz, 3), batch_size=None if dynamic else batch_size)
    # åˆ›å»ºKerasè¾“å…¥å±‚ï¼Œå½¢çŠ¶ä¸ºï¼ˆå›¾åƒé«˜åº¦ï¼Œå›¾åƒå®½åº¦ï¼Œé€šé“æ•°ï¼‰
    keras_model = keras.Model(inputs=im, outputs=tf_model.predict(im))
    # åˆ›å»ºKerasæ¨¡å‹å®ä¾‹
    keras_model.summary()  # æ‰“å°Kerasæ¨¡å‹æ‘˜è¦

    LOGGER.info("PyTorch, TensorFlow and Keras models successfully verified.\nUse export.py for TF model export.")
    # è®°å½•ä¿¡æ¯ï¼Œè¡¨æ˜PyTorchã€TensorFlowå’ŒKerasæ¨¡å‹å·²æˆåŠŸéªŒè¯ï¼Œä½¿ç”¨export.pyå¯¼å‡ºTensorFlowæ¨¡å‹


def parse_opt():
    """Parses and returns command-line options for model inference, including weights path, image size, batch size, and
    dynamic batching.
    """
    # è§£æå¹¶è¿”å›æ¨¡å‹æ¨ç†çš„å‘½ä»¤è¡Œé€‰é¡¹ï¼ŒåŒ…æ‹¬æƒé‡è·¯å¾„ã€å›¾åƒå¤§å°ã€æ‰¹å¤„ç†å¤§å°å’ŒåŠ¨æ€æ‰¹å¤„ç†
    parser = argparse.ArgumentParser()  # åˆ›å»ºè§£æå™¨
    parser.add_argument("--weights", type=str, default=ROOT / "yolov5s.pt", help="weights path")
    # æ·»åŠ æƒé‡è·¯å¾„å‚æ•°
    parser.add_argument("--imgsz", "--img", "--img-size", nargs="+", type=int, default=[640], help="inference size h,w")
    # æ·»åŠ å›¾åƒå¤§å°å‚æ•°
    parser.add_argument("--batch-size", type=int, default=1, help="batch size")
    # æ·»åŠ æ‰¹å¤„ç†å¤§å°å‚æ•°
    parser.add_argument("--dynamic", action="store_true", help="dynamic batch size")
    # æ·»åŠ åŠ¨æ€æ‰¹å¤„ç†å‚æ•°
    opt = parser.parse_args()  # è§£æå‚æ•°
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand
    # å¦‚æœåªæä¾›ä¸€ä¸ªå›¾åƒå°ºå¯¸ï¼Œåˆ™å°†å…¶æ‰©å±•ä¸ºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰
    print_args(vars(opt))  # æ‰“å°å‚æ•°
    return opt  # è¿”å›è§£æåçš„é€‰é¡¹


def main(opt):
    """Executes the YOLOv5 model run function with parsed command line options."""
    # ä½¿ç”¨è§£æåçš„å‘½ä»¤è¡Œé€‰é¡¹æ‰§è¡ŒYOLOv5æ¨¡å‹è¿è¡Œå‡½æ•°
    run(**vars(opt))  # è§£åŒ…é€‰é¡¹å¹¶ä¼ é€’ç»™runå‡½æ•°


if __name__ == "__main__":
    opt = parse_opt()  # è§£æå‘½ä»¤è¡Œé€‰é¡¹
    main(opt)  # æ‰§è¡Œä¸»å‡½æ•°