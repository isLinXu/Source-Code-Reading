# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""Module utils."""  # å·¥å…·æ¨¡å—

import copy  # å¯¼å…¥copyæ¨¡å—
import math  # å¯¼å…¥mathæ¨¡å—

import numpy as np  # å¯¼å…¥numpyåº“å¹¶å‘½åä¸ºnp
import torch  # å¯¼å…¥PyTorchåº“
import torch.nn as nn  # å¯¼å…¥PyTorchçš„ç¥ç»ç½‘ç»œæ¨¡å—
import torch.nn.functional as F  # å¯¼å…¥PyTorchçš„åŠŸèƒ½æ€§ç¥ç»ç½‘ç»œæ¨¡å—
from torch.nn.init import uniform_  # ä»PyTorchçš„nn.initæ¨¡å—å¯¼å…¥uniform_å‡½æ•°

__all__ = "multi_scale_deformable_attn_pytorch", "inverse_sigmoid"  # å®šä¹‰æ¨¡å—çš„å…¬å…±æ¥å£

def _get_clones(module, n):
    """Create a list of cloned modules from the given module."""  # æ ¹æ®ç»™å®šæ¨¡å—åˆ›å»ºä¸€ä¸ªå…‹éš†æ¨¡å—åˆ—è¡¨
    return nn.ModuleList([copy.deepcopy(module) for _ in range(n)])  # è¿”å›å…‹éš†çš„æ¨¡å—åˆ—è¡¨

def bias_init_with_prob(prior_prob=0.01):
    """Initialize conv/fc bias value according to a given probability value."""  # æ ¹æ®ç»™å®šçš„æ¦‚ç‡å€¼åˆå§‹åŒ–å·ç§¯/å…¨è¿æ¥å±‚çš„åç½®å€¼
    return float(-np.log((1 - prior_prob) / prior_prob))  # è¿”å›åç½®åˆå§‹åŒ–å€¼

def linear_init(module):
    """Initialize the weights and biases of a linear module."""  # åˆå§‹åŒ–çº¿æ€§æ¨¡å—çš„æƒé‡å’Œåç½®
    bound = 1 / math.sqrt(module.weight.shape[0])  # è®¡ç®—æƒé‡çš„è¾¹ç•Œ
    uniform_(module.weight, -bound, bound)  # ä½¿ç”¨å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡
    if hasattr(module, "bias") and module.bias is not None:  # æ£€æŸ¥æ¨¡å—æ˜¯å¦æœ‰åç½®
        uniform_(module.bias, -bound, bound)  # ä½¿ç”¨å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–åç½®

def inverse_sigmoid(x, eps=1e-5):
    """Calculate the inverse sigmoid function for a tensor."""  # è®¡ç®—å¼ é‡çš„åsigmoidå‡½æ•°
    x = x.clamp(min=0, max=1)  # å°†xé™åˆ¶åœ¨[0, 1]èŒƒå›´å†…
    x1 = x.clamp(min=eps)  # å°†x1é™åˆ¶åœ¨[eps, 1]èŒƒå›´å†…
    x2 = (1 - x).clamp(min=eps)  # å°†x2é™åˆ¶åœ¨[eps, 1]èŒƒå›´å†…
    return torch.log(x1 / x2)  # è¿”å›åsigmoidå€¼

def multi_scale_deformable_attn_pytorch(
    value: torch.Tensor,  # è¾“å…¥å€¼å¼ é‡
    value_spatial_shapes: torch.Tensor,  # è¾“å…¥å€¼çš„ç©ºé—´å½¢çŠ¶
    sampling_locations: torch.Tensor,  # é‡‡æ ·ä½ç½®
    attention_weights: torch.Tensor,  # æ³¨æ„åŠ›æƒé‡
) -> torch.Tensor:
    """
    Multiscale deformable attention.  # å¤šå°ºåº¦å¯å˜å½¢æ³¨æ„åŠ›

    https://github.com/IDEA-Research/detrex/blob/main/detrex/layers/multi_scale_deform_attn.py  # ç›¸å…³é“¾æ¥
    """
    bs, _, num_heads, embed_dims = value.shape  # è·å–æ‰¹æ¬¡å¤§å°ã€é€šé“æ•°ã€å¤´æ•°å’ŒåµŒå…¥ç»´åº¦
    _, num_queries, num_heads, num_levels, num_points, _ = sampling_locations.shape  # è·å–æŸ¥è¯¢æ•°é‡ã€å¤´æ•°ã€å±‚æ•°å’Œç‚¹æ•°
    value_list = value.split([H_ * W_ for H_, W_ in value_spatial_shapes], dim=1)  # å°†å€¼å¼ é‡æŒ‰ç©ºé—´å½¢çŠ¶åˆ†å‰²
    sampling_grids = 2 * sampling_locations - 1  # è®¡ç®—é‡‡æ ·ç½‘æ ¼
    sampling_value_list = []  # åˆå§‹åŒ–é‡‡æ ·å€¼åˆ—è¡¨
    for level, (H_, W_) in enumerate(value_spatial_shapes):  # éå†æ¯ä¸ªç©ºé—´å±‚
        # bs, H_*W_, num_heads, embed_dims ->
        # bs, H_*W_, num_heads*embed_dims ->
        # bs, num_heads*embed_dims, H_*W_ ->
        # bs*num_heads, embed_dims, H_, W_
        value_l_ = value_list[level].flatten(2).transpose(1, 2).reshape(bs * num_heads, embed_dims, H_, W_)  # å¤„ç†å€¼å¼ é‡
        # bs, num_queries, num_heads, num_points, 2 ->
        # bs, num_heads, num_queries, num_points, 2 ->
        # bs*num_heads, num_queries, num_points, 2
        sampling_grid_l_ = sampling_grids[:, :, :, level].transpose(1, 2).flatten(0, 1)  # å¤„ç†é‡‡æ ·ç½‘æ ¼
        # bs*num_heads, embed_dims, num_queries, num_points
        sampling_value_l_ = F.grid_sample(
            value_l_, sampling_grid_l_, mode="bilinear", padding_mode="zeros", align_corners=False
        )  # ä½¿ç”¨åŒçº¿æ€§æ’å€¼è¿›è¡Œç½‘æ ¼é‡‡æ ·
        sampling_value_list.append(sampling_value_l_)  # å°†é‡‡æ ·å€¼æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    # (bs, num_queries, num_heads, num_levels, num_points) ->
    # (bs, num_heads, num_queries, num_levels, num_points) ->
    # (bs, num_heads, 1, num_queries, num_levels*num_points)
    attention_weights = attention_weights.transpose(1, 2).reshape(
        bs * num_heads, 1, num_queries, num_levels * num_points
    )  # å¤„ç†æ³¨æ„åŠ›æƒé‡
    output = (
        (torch.stack(sampling_value_list, dim=-2).flatten(-2) * attention_weights)  # è®¡ç®—è¾“å‡º
        .sum(-1)  # å¯¹æœ€åä¸€ä¸ªç»´åº¦æ±‚å’Œ
        .view(bs, num_heads * embed_dims, num_queries)  # è°ƒæ•´è¾“å‡ºå½¢çŠ¶
    )
    return output.transpose(1, 2).contiguous()  # è¿”å›è¾“å‡ºå¹¶è°ƒæ•´ç»´åº¦