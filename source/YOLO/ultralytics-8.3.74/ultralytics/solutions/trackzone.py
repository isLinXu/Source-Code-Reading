# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import cv2
import numpy as np

from ultralytics.solutions.solutions import BaseSolution
from ultralytics.utils.plotting import Annotator, colors


class TrackZone(BaseSolution):
    """
    A class to manage region-based object tracking in a video stream.

    This class extends the BaseSolution class and provides functionality for tracking objects within a specific region
    defined by a polygonal area. Objects outside the region are excluded from tracking. It supports dynamic initialization
    of the region, allowing either a default region or a user-specified polygon.

    Attributes:
        region (ndarray): The polygonal region for tracking, represented as a convex hull.

    Methods:
        trackzone: Processes each frame of the video, applying region-based tracking.

    Examples:
        >>> tracker = TrackZone()
        >>> frame = cv2.imread("frame.jpg")
        >>> processed_frame = tracker.trackzone(frame)
        >>> cv2.imshow("Tracked Frame", processed_frame)
    """

    def __init__(self, **kwargs):
        """Initializes the TrackZone class for tracking objects within a defined region in video streams."""
        super().__init__(**kwargs)
        default_region = [(150, 150), (1130, 150), (1130, 570), (150, 570)]
        self.region = cv2.convexHull(np.array(self.region or default_region, dtype=np.int32))

    def trackzone(self, im0):
        """
        Processes the input frame to track objects within a defined region.

        This method initializes the annotator, creates a mask for the specified region, extracts tracks
        only from the masked area, and updates tracking information. Objects outside the region are ignored.

        Args:
            im0 (numpy.ndarray): The input image or frame to be processed.

        Returns:
            (numpy.ndarray): The processed image with tracking id and bounding boxes annotations.

        Examples:
            >>> tracker = TrackZone()
            >>> frame = cv2.imread("path/to/image.jpg")
            >>> tracker.trackzone(frame)
        """
        self.annotator = Annotator(im0, line_width=self.line_width)  # Initialize annotator
        # Create a mask for the region and extract tracks from the masked image
        masked_frame = cv2.bitwise_and(im0, im0, mask=cv2.fillPoly(np.zeros_like(im0[:, :, 0]), [self.region], 255))
        self.extract_tracks(masked_frame)

        cv2.polylines(im0, [self.region], isClosed=True, color=(255, 255, 255), thickness=self.line_width * 2)

        # Iterate over boxes, track ids, classes indexes list and draw bounding boxes
        for box, track_id, cls in zip(self.boxes, self.track_ids, self.clss):
            self.annotator.box_label(box, label=f"{self.names[cls]}:{track_id}", color=colors(track_id, True))

        self.display_output(im0)  # display output with base class function

        return im0  # return output image for more usage
# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import cv2  # å¯¼å…¥OpenCVåº“ä»¥å¤„ç†å›¾åƒ
import numpy as np  # å¯¼å…¥NumPyåº“ï¼Œç”¨äºæ•°ç»„å’Œæ•°å€¼è®¡ç®—

from ultralytics.solutions.solutions import BaseSolution  # ä»ultralytics.solutionsæ¨¡å—å¯¼å…¥BaseSolutionç±»
from ultralytics.utils.plotting import Annotator, colors  # ä»ultralytics.utils.plottingå¯¼å…¥Annotatorå’Œcolors

class TrackZone(BaseSolution):
    """
    A class to manage region-based object tracking in a video stream.
    ä¸€ä¸ªç±»ï¼Œç”¨äºç®¡ç†è§†é¢‘æµä¸­çš„åŸºäºåŒºåŸŸçš„å¯¹è±¡è·Ÿè¸ªã€‚

    This class extends the BaseSolution class and provides functionality for tracking objects within a specific region
    defined by a polygonal area. Objects outside the region are excluded from tracking. It supports dynamic initialization
    of the region, allowing either a default region or a user-specified polygon.
    è¯¥ç±»æ‰©å±•äº†BaseSolutionç±»ï¼Œæä¾›åœ¨å¤šè¾¹å½¢åŒºåŸŸå†…è·Ÿè¸ªå¯¹è±¡çš„åŠŸèƒ½ã€‚åŒºåŸŸå¤–çš„å¯¹è±¡å°†è¢«æ’é™¤åœ¨è·Ÿè¸ªä¹‹å¤–ã€‚å®ƒæ”¯æŒåŒºåŸŸçš„åŠ¨æ€åˆå§‹åŒ–ï¼Œå…è®¸ä½¿ç”¨é»˜è®¤åŒºåŸŸæˆ–ç”¨æˆ·æŒ‡å®šçš„å¤šè¾¹å½¢ã€‚

    Attributes:
        region (ndarray): The polygonal region for tracking, represented as a convex hull.
        region (ndarray): ç”¨äºè·Ÿè¸ªçš„å¤šè¾¹å½¢åŒºåŸŸï¼Œè¡¨ç¤ºä¸ºå‡¸åŒ…ã€‚

    Methods:
        trackzone: Processes each frame of the video, applying region-based tracking.
        trackzone: å¤„ç†è§†é¢‘çš„æ¯ä¸€å¸§ï¼Œåº”ç”¨åŸºäºåŒºåŸŸçš„è·Ÿè¸ªã€‚

    Examples:
        >>> tracker = TrackZone()
        >>> frame = cv2.imread("frame.jpg")
        >>> processed_frame = tracker.trackzone(frame)
        >>> cv2.imshow("Tracked Frame", processed_frame)
    """

    def __init__(self, **kwargs):
        """Initializes the TrackZone class for tracking objects within a defined region in video streams."""
        super().__init__(**kwargs)  # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
        default_region = [(150, 150), (1130, 150), (1130, 570), (150, 570)]  # å®šä¹‰é»˜è®¤åŒºåŸŸ
        self.region = cv2.convexHull(np.array(self.region or default_region, dtype=np.int32))  # å°†åŒºåŸŸè½¬æ¢ä¸ºå‡¸åŒ…

    def trackzone(self, im0):
        """
        Processes the input frame to track objects within a defined region.

        This method initializes the annotator, creates a mask for the specified region, extracts tracks
        only from the masked area, and updates tracking information. Objects outside the region are ignored.

        Args:
            im0 (numpy.ndarray): The input image or frame to be processed. è¾“å…¥å›¾åƒæˆ–å¸§ï¼Œç”¨äºå¤„ç†ã€‚

        Returns:
            (numpy.ndarray): The processed image with tracking id and bounding boxes annotations.
            (numpy.ndarray): å¤„ç†åçš„å›¾åƒï¼ŒåŒ…å«è·Ÿè¸ªIDå’Œè¾¹ç•Œæ¡†æ³¨é‡Šã€‚

        Examples:
            >>> tracker = TrackZone()
            >>> frame = cv2.imread("path/to/image.jpg")
            >>> tracker.trackzone(frame)
        """
        self.annotator = Annotator(im0, line_width=self.line_width)  # åˆå§‹åŒ–æ³¨é‡Šå™¨
        # Create a mask for the region and extract tracks from the masked image
        masked_frame = cv2.bitwise_and(im0, im0, mask=cv2.fillPoly(np.zeros_like(im0[:, :, 0]), [self.region], 255))  # åˆ›å»ºåŒºåŸŸæ©ç å¹¶æå–è½¨è¿¹
        self.extract_tracks(masked_frame)  # ä»æ©ç å›¾åƒä¸­æå–è½¨è¿¹

        cv2.polylines(im0, [self.region], isClosed=True, color=(255, 255, 255), thickness=self.line_width * 2)  # ç»˜åˆ¶åŒºåŸŸè¾¹ç•Œ

        # Iterate over boxes, track ids, classes indexes list and draw bounding boxes
        for box, track_id, cls in zip(self.boxes, self.track_ids, self.clss):  # éå†è¾¹ç•Œæ¡†ã€è½¨è¿¹IDå’Œç±»åˆ«
            self.annotator.box_label(box, label=f"{self.names[cls]}:{track_id}", color=colors(track_id, True))  # ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾

        self.display_output(im0)  # ä½¿ç”¨åŸºç±»å‡½æ•°æ˜¾ç¤ºè¾“å‡º

        return im0  # è¿”å›å¤„ç†åçš„å›¾åƒä»¥ä¾›è¿›ä¸€æ­¥ä½¿ç”¨