# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import os
import random
from pathlib import Path

import numpy as np
import torch
from PIL import Image
from torch.utils.data import dataloader, distributed

from ultralytics.data.dataset import GroundingDataset, YOLODataset, YOLOMultiModalDataset
from ultralytics.data.loaders import (
    LOADERS,
    LoadImagesAndVideos,
    LoadPilAndNumpy,
    LoadScreenshots,
    LoadStreams,
    LoadTensor,
    SourceTypes,
    autocast_list,
)
from ultralytics.data.utils import IMG_FORMATS, PIN_MEMORY, VID_FORMATS
from ultralytics.utils import RANK, colorstr
from ultralytics.utils.checks import check_file


class InfiniteDataLoader(dataloader.DataLoader):
    """
    Dataloader that reuses workers.
    é‡ç”¨å·¥ä½œçº¿ç¨‹çš„æ•°æ®åŠ è½½å™¨ã€‚

    Uses same syntax as vanilla DataLoader.
    ä½¿ç”¨ä¸æ™®é€šDataLoaderç›¸åŒçš„è¯­æ³•ã€‚
    """

    def __init__(self, *args, **kwargs):
        """Dataloader that infinitely recycles workers, inherits from DataLoader."""
        super().__init__(*args, **kwargs)  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        object.__setattr__(self, "batch_sampler", _RepeatSampler(self.batch_sampler))  # è®¾ç½®æ‰¹æ¬¡é‡‡æ ·å™¨ä¸ºé‡å¤é‡‡æ ·å™¨
        self.iterator = super().__iter__()  # åˆ›å»ºè¿­ä»£å™¨

    def __len__(self):
        """Returns the length of the batch sampler's sampler."""
        return len(self.batch_sampler.sampler)  # è¿”å›æ‰¹æ¬¡é‡‡æ ·å™¨çš„é•¿åº¦

    def __iter__(self):
        """Creates a sampler that repeats indefinitely."""
        for _ in range(len(self)):  # æ— é™å¾ªç¯
            yield next(self.iterator)  # è¿”å›ä¸‹ä¸€ä¸ªå…ƒç´ 

    def __del__(self):
        """Ensure that workers are terminated."""
        try:
            if not hasattr(self.iterator, "_workers"):  # æ£€æŸ¥è¿­ä»£å™¨æ˜¯å¦æœ‰_workerså±æ€§
                return
            for w in self.iterator._workers:  # force terminate å¼ºåˆ¶ç»ˆæ­¢
                if w.is_alive():  # å¦‚æœå·¥ä½œçº¿ç¨‹ä»åœ¨è¿è¡Œ
                    w.terminate()  # ç»ˆæ­¢å·¥ä½œçº¿ç¨‹
            self.iterator._shutdown_workers()  # æ¸…ç†å·¥ä½œçº¿ç¨‹
        except Exception:
            pass  # å¿½ç•¥å¼‚å¸¸

    def reset(self):
        """
        Reset iterator.
        é‡ç½®è¿­ä»£å™¨ã€‚

        This is useful when we want to modify settings of dataset while training.
        å½“æˆ‘ä»¬æƒ³åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿®æ”¹æ•°æ®é›†çš„è®¾ç½®æ—¶ï¼Œè¿™å¾ˆæœ‰ç”¨ã€‚
        """
        self.iterator = self._get_iterator()  # è·å–æ–°çš„è¿­ä»£å™¨


class _RepeatSampler:
    """
    Sampler that repeats forever.
    æ°¸ä¹…é‡å¤çš„é‡‡æ ·å™¨ã€‚

    Args:
        sampler (Dataset.sampler): The sampler to repeat.
    """

    def __init__(self, sampler):
        """Initializes an object that repeats a given sampler indefinitely."""
        self.sampler = sampler  # è®¾ç½®è¦é‡å¤çš„é‡‡æ ·å™¨

    def __iter__(self):
        """Iterates over the 'sampler' and yields its contents."""
        while True:  # æ— é™å¾ªç¯
            yield from iter(self.sampler)  # ä»é‡‡æ ·å™¨ä¸­è¿­ä»£å¹¶è¿”å›å†…å®¹


def seed_worker(worker_id):  # noqa
    """Set dataloader worker seed https://pytorch.org/docs/stable/notes/randomness.html#dataloader."""
    worker_seed = torch.initial_seed() % 2**32  # è®¾ç½®å·¥ä½œçº¿ç¨‹çš„ç§å­
    np.random.seed(worker_seed)  # è®¾ç½®numpyéšæœºæ•°ç§å­
    random.seed(worker_seed)  # è®¾ç½®Pythonéšæœºæ•°ç§å­


def build_yolo_dataset(cfg, img_path, batch, data, mode="train", rect=False, stride=32, multi_modal=False):
    """Build YOLO Dataset."""
    dataset = YOLOMultiModalDataset if multi_modal else YOLODataset  # æ ¹æ®æ˜¯å¦å¤šæ¨¡æ€é€‰æ‹©æ•°æ®é›†
    return dataset(
        img_path=img_path,  # å›¾åƒè·¯å¾„
        imgsz=cfg.imgsz,  # å›¾åƒå¤§å°
        batch_size=batch,  # æ‰¹æ¬¡å¤§å°
        augment=mode == "train",  # augmentation æ•°æ®å¢å¼º
        hyp=cfg,  # TODO: probably add a get_hyps_from_cfg function
        rect=cfg.rect or rect,  # rectangular batches çŸ©å½¢æ‰¹æ¬¡
        cache=cfg.cache or None,  # ç¼“å­˜è®¾ç½®
        single_cls=cfg.single_cls or False,  # å•ç±»è®­ç»ƒè®¾ç½®
        stride=int(stride),  # æ­¥å¹…
        pad=0.0 if mode == "train" else 0.5,  # å¡«å……è®¾ç½®
        prefix=colorstr(f"{mode}: "),  # æ—¥å¿—å‰ç¼€
        task=cfg.task,  # ä»»åŠ¡ç±»å‹
        classes=cfg.classes,  # ç±»åˆ«
        data=data,  # æ•°æ®
        fraction=cfg.fraction if mode == "train" else 1.0,  # ä½¿ç”¨çš„æ•°æ®é›†æ¯”ä¾‹
    )


def build_grounding(cfg, img_path, json_file, batch, mode="train", rect=False, stride=32):
    """Build YOLO Dataset."""
    return GroundingDataset(
        img_path=img_path,  # å›¾åƒè·¯å¾„
        json_file=json_file,  # JSONæ–‡ä»¶è·¯å¾„
        imgsz=cfg.imgsz,  # å›¾åƒå¤§å°
        batch_size=batch,  # æ‰¹æ¬¡å¤§å°
        augment=mode == "train",  # æ•°æ®å¢å¼º
        hyp=cfg,  # TODO: probably add a get_hyps_from_cfg function
        rect=cfg.rect or rect,  # çŸ©å½¢æ‰¹æ¬¡
        cache=cfg.cache or None,  # ç¼“å­˜è®¾ç½®
        single_cls=cfg.single_cls or False,  # å•ç±»è®­ç»ƒè®¾ç½®
        stride=int(stride),  # æ­¥å¹…
        pad=0.0 if mode == "train" else 0.5,  # å¡«å……è®¾ç½®
        prefix=colorstr(f"{mode}: "),  # æ—¥å¿—å‰ç¼€
        task=cfg.task,  # ä»»åŠ¡ç±»å‹
        classes=cfg.classes,  # ç±»åˆ«
        fraction=cfg.fraction if mode == "train" else 1.0,  # ä½¿ç”¨çš„æ•°æ®é›†æ¯”ä¾‹
    )


def build_dataloader(dataset, batch, workers, shuffle=True, rank=-1):
    """Return an InfiniteDataLoader or DataLoader for training or validation set."""
    batch = min(batch, len(dataset))  # è®¾ç½®æ‰¹æ¬¡å¤§å°
    nd = torch.cuda.device_count()  # number of CUDA devices è·å–CUDAè®¾å¤‡æ•°é‡
    nw = min(os.cpu_count() // max(nd, 1), workers)  # number of workers è·å–å·¥ä½œçº¿ç¨‹æ•°é‡
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)  # è®¾ç½®é‡‡æ ·å™¨
    generator = torch.Generator()  # åˆ›å»ºéšæœºæ•°ç”Ÿæˆå™¨
    generator.manual_seed(6148914691236517205 + RANK)  # è®¾ç½®ç”Ÿæˆå™¨ç§å­
    return InfiniteDataLoader(
        dataset=dataset,  # æ•°æ®é›†
        batch_size=batch,  # æ‰¹æ¬¡å¤§å°
        shuffle=shuffle and sampler is None,  # æ˜¯å¦æ‰“ä¹±æ•°æ®
        num_workers=nw,  # å·¥ä½œçº¿ç¨‹æ•°é‡
        sampler=sampler,  # é‡‡æ ·å™¨
        pin_memory=PIN_MEMORY,  # æ˜¯å¦å°†æ•°æ®å›ºå®šåœ¨å†…å­˜ä¸­
        collate_fn=getattr(dataset, "collate_fn", None),  # è·å–åˆå¹¶å‡½æ•°
        worker_init_fn=seed_worker,  # å·¥ä½œçº¿ç¨‹åˆå§‹åŒ–å‡½æ•°
        generator=generator,  # éšæœºæ•°ç”Ÿæˆå™¨
    )


def check_source(source):
    """Check source type and return corresponding flag values."""
    webcam, screenshot, from_img, in_memory, tensor = False, False, False, False, False  # åˆå§‹åŒ–æ ‡å¿—
    if isinstance(source, (str, int, Path)):  # int for local usb camera
        source = str(source)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        is_file = Path(source).suffix[1:] in (IMG_FORMATS | VID_FORMATS)  # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
        is_url = source.lower().startswith(("https://", "http://", "rtsp://", "rtmp://", "tcp://"))  # æ£€æŸ¥æ˜¯å¦ä¸ºURL
        webcam = source.isnumeric() or source.endswith(".streams") or (is_url and not is_file)  # æ£€æŸ¥æ˜¯å¦ä¸ºç½‘ç»œæ‘„åƒå¤´
        screenshot = source.lower() == "screen"  # æ£€æŸ¥æ˜¯å¦ä¸ºå±å¹•æˆªå›¾
        if is_url and is_file:
            source = check_file(source)  # download ä¸‹è½½æ–‡ä»¶
    elif isinstance(source, LOADERS):
        in_memory = True  # å¦‚æœæ˜¯LOADERSç±»å‹ï¼Œè®¾ç½®ä¸ºå†…å­˜åŠ è½½
    elif isinstance(source, (list, tuple)):
        source = autocast_list(source)  # convert all list elements to PIL or np arrays å°†åˆ—è¡¨ä¸­çš„æ‰€æœ‰å…ƒç´ è½¬æ¢ä¸ºPILæˆ–numpyæ•°ç»„
        from_img = True  # è®¾ç½®ä¸ºå›¾åƒæ¥æº
    elif isinstance(source, (Image.Image, np.ndarray)):
        from_img = True  # è®¾ç½®ä¸ºå›¾åƒæ¥æº
    elif isinstance(source, torch.Tensor):
        tensor = True  # è®¾ç½®ä¸ºå¼ é‡æ¥æº
    else:
        raise TypeError("Unsupported image type. For supported types see https://docs.ultralytics.com/modes/predict")  # æŠ›å‡ºä¸æ”¯æŒçš„ç±»å‹é”™è¯¯

    return source, webcam, screenshot, from_img, in_memory, tensor  # è¿”å›æºå’Œæ ‡å¿—


def load_inference_source(source=None, batch=1, vid_stride=1, buffer=False):
    """
    Loads an inference source for object detection and applies necessary transformations.
    åŠ è½½ç”¨äºç›®æ ‡æ£€æµ‹çš„æ¨ç†æºå¹¶åº”ç”¨å¿…è¦çš„å˜æ¢ã€‚

    Args:
        source (str, Path, Tensor, PIL.Image, np.ndarray): The input source for inference.
        source (str, Path, Tensor, PIL.Image, np.ndarray): ç”¨äºæ¨ç†çš„è¾“å…¥æºã€‚
        batch (int, optional): Batch size for dataloaders. Default is 1.
        batch (int, optional): æ•°æ®åŠ è½½å™¨çš„æ‰¹æ¬¡å¤§å°ã€‚é»˜è®¤ä¸º1ã€‚
        vid_stride (int, optional): The frame interval for video sources. Default is 1.
        vid_stride (int, optional): è§†é¢‘æºçš„å¸§é—´éš”ã€‚é»˜è®¤ä¸º1ã€‚
        buffer (bool, optional): Determined whether stream frames will be buffered. Default is False.
        buffer (bool, optional): ç¡®å®šæµå¸§æ˜¯å¦ä¼šè¢«ç¼“å†²ã€‚é»˜è®¤ä¸ºFalseã€‚

    Returns:
        dataset (Dataset): A dataset object for the specified input source.
        dataset (Dataset): æŒ‡å®šè¾“å…¥æºçš„æ•°æ®é›†å¯¹è±¡ã€‚
    """
    source, stream, screenshot, from_img, in_memory, tensor = check_source(source)  # æ£€æŸ¥æºç±»å‹
    source_type = source.source_type if in_memory else SourceTypes(stream, screenshot, from_img, tensor)  # è·å–æºç±»å‹

    # Dataloader
    if tensor:
        dataset = LoadTensor(source)  # å¦‚æœæ˜¯å¼ é‡ï¼ŒåŠ è½½å¼ é‡æ•°æ®é›†
    elif in_memory:
        dataset = source  # å¦‚æœåœ¨å†…å­˜ä¸­ï¼Œç›´æ¥ä½¿ç”¨æº
    elif stream:
        dataset = LoadStreams(source, vid_stride=vid_stride, buffer=buffer)  # åŠ è½½æµæ•°æ®é›†
    elif screenshot:
        dataset = LoadScreenshots(source)  # åŠ è½½å±å¹•æˆªå›¾æ•°æ®é›†
    elif from_img:
        dataset = LoadPilAndNumpy(source)  # åŠ è½½PILå’Œnumpyæ•°æ®é›†
    else:
        dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)  # åŠ è½½å›¾åƒå’Œè§†é¢‘æ•°æ®é›†

    # Attach source types to the dataset
    setattr(dataset, "source_type", source_type)  # å°†æºç±»å‹é™„åŠ åˆ°æ•°æ®é›†

    return dataset  # è¿”å›æ•°æ®é›†