# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from pathlib import Path  # ä» pathlib å¯¼å…¥ Path ç±»

from ultralytics import SAM, YOLO  # ä» ultralytics å¯¼å…¥ SAM å’Œ YOLO ç±»


def auto_annotate(  # å®šä¹‰ auto_annotate å‡½æ•°
    data,  # è¦æ³¨é‡Šçš„æ•°æ®
    det_model="yolo11x.pt",  # æ£€æµ‹æ¨¡å‹çš„è·¯å¾„æˆ–åç§°ï¼Œé»˜è®¤ä¸º yolo11x.pt
    sam_model="sam_b.pt",  # åˆ†å‰²æ¨¡å‹çš„è·¯å¾„æˆ–åç§°ï¼Œé»˜è®¤ä¸º sam_b.pt
    device="",  # è¿è¡Œæ¨¡å‹çš„è®¾å¤‡ï¼ˆä¾‹å¦‚ 'cpu', 'cuda', '0'ï¼‰
    conf=0.25,  # æ£€æµ‹æ¨¡å‹çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤ä¸º 0.25
    iou=0.45,  # IoU é˜ˆå€¼ï¼Œç”¨äºè¿‡æ»¤æ£€æµ‹ç»“æœä¸­çš„é‡å æ¡†ï¼Œé»˜è®¤ä¸º 0.45
    imgsz=640,  # è¾“å…¥å›¾åƒçš„è°ƒæ•´å°ºå¯¸ï¼Œé»˜è®¤ä¸º 640
    max_det=300,  # æ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°é‡
    classes=None,  # è¿‡æ»¤é¢„æµ‹åˆ°çš„ç±» IDï¼Œè¿”å›ç›¸å…³çš„æ£€æµ‹ç»“æœ
    output_dir=None,  # æ³¨é‡Šç»“æœä¿å­˜çš„ç›®å½•ï¼Œé»˜è®¤ä¸º None
):
    """
    Automatically annotates images using a YOLO object detection model and a SAM segmentation model.  # ä½¿ç”¨ YOLO ç›®æ ‡æ£€æµ‹æ¨¡å‹å’Œ SAM åˆ†å‰²æ¨¡å‹è‡ªåŠ¨æ³¨é‡Šå›¾åƒ

    This function processes images in a specified directory, detects objects using a YOLO model, and then generates  # è¯¥å‡½æ•°å¤„ç†æŒ‡å®šç›®å½•ä¸­çš„å›¾åƒï¼Œä½¿ç”¨ YOLO æ¨¡å‹æ£€æµ‹å¯¹è±¡ï¼Œç„¶åç”Ÿæˆ
    segmentation masks using a SAM model. The resulting annotations are saved as text files.  # ä½¿ç”¨ SAM æ¨¡å‹ç”Ÿæˆåˆ†å‰²æ©è†œï¼Œç»“æœæ³¨é‡Šä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶

    Args:  # å‚æ•°è¯´æ˜
        data (str): Path to a folder containing images to be annotated.  # åŒ…å«å¾…æ³¨é‡Šå›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„
        det_model (str): Path or name of the pre-trained YOLO detection model.  # é¢„è®­ç»ƒ YOLO æ£€æµ‹æ¨¡å‹çš„è·¯å¾„æˆ–åç§°
        sam_model (str): Path or name of the pre-trained SAM segmentation model.  # é¢„è®­ç»ƒ SAM åˆ†å‰²æ¨¡å‹çš„è·¯å¾„æˆ–åç§°
        device (str): Device to run the models on (e.g., 'cpu', 'cuda', '0').  # è¿è¡Œæ¨¡å‹çš„è®¾å¤‡ï¼ˆä¾‹å¦‚ 'cpu', 'cuda', '0'ï¼‰
        conf (float): Confidence threshold for detection model; default is 0.25.  # æ£€æµ‹æ¨¡å‹çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé»˜è®¤ä¸º 0.25
        iou (float): IoU threshold for filtering overlapping boxes in detection results; default is 0.45.  # æ£€æµ‹ç»“æœä¸­è¿‡æ»¤é‡å æ¡†çš„ IoU é˜ˆå€¼ï¼Œé»˜è®¤ä¸º 0.45
        imgsz (int): Input image resize dimension; default is 640.  # è¾“å…¥å›¾åƒçš„è°ƒæ•´å°ºå¯¸ï¼Œé»˜è®¤ä¸º 640
        max_det (int): Limits detections per image to control outputs in dense scenes.  # æ¯å¼ å›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°é‡
        classes (list): Filters predictions to specified class IDs, returning only relevant detections.  # è¿‡æ»¤é¢„æµ‹åˆ°çš„ç±» IDï¼Œè¿”å›ç›¸å…³çš„æ£€æµ‹ç»“æœ
        output_dir (str | None): Directory to save the annotated results. If None, a default directory is created.  # æ³¨é‡Šç»“æœä¿å­˜çš„ç›®å½•ï¼Œå¦‚æœä¸º Noneï¼Œåˆ™åˆ›å»ºé»˜è®¤ç›®å½•

    Examples:  # ç¤ºä¾‹
        >>> from ultralytics.data.annotator import auto_annotate  # ä» ultralytics.data.annotator å¯¼å…¥ auto_annotate
        >>> auto_annotate(data="ultralytics/assets", det_model="yolo11n.pt", sam_model="mobile_sam.pt")  # è°ƒç”¨ auto_annotate å‡½æ•°

    Notes:  # æ³¨æ„äº‹é¡¹
        - The function creates a new directory for output if not specified.  # å¦‚æœæœªæŒ‡å®šï¼Œåˆ™è¯¥å‡½æ•°ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„è¾“å‡ºç›®å½•
        - Annotation results are saved as text files with the same names as the input images.  # æ³¨é‡Šç»“æœä¿å­˜ä¸ºä¸è¾“å…¥å›¾åƒåŒåçš„æ–‡æœ¬æ–‡ä»¶
        - Each line in the output text file represents a detected object with its class ID and segmentation points.  # è¾“å‡ºæ–‡æœ¬æ–‡ä»¶ä¸­çš„æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ£€æµ‹åˆ°çš„å¯¹è±¡åŠå…¶ç±» ID å’Œåˆ†å‰²ç‚¹
    """
    det_model = YOLO(det_model)  # åˆå§‹åŒ– YOLO æ£€æµ‹æ¨¡å‹
    sam_model = SAM(sam_model)  # åˆå§‹åŒ– SAM åˆ†å‰²æ¨¡å‹

    data = Path(data)  # å°†æ•°æ®è·¯å¾„è½¬æ¢ä¸º Path å¯¹è±¡
    if not output_dir:  # å¦‚æœæœªæŒ‡å®šè¾“å‡ºç›®å½•
        output_dir = data.parent / f"{data.stem}_auto_annotate_labels"  # åˆ›å»ºé»˜è®¤è¾“å‡ºç›®å½•
    Path(output_dir).mkdir(exist_ok=True, parents=True)  # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰

    det_results = det_model(  # ä½¿ç”¨ YOLO æ¨¡å‹è¿›è¡Œæ£€æµ‹
        data, stream=True, device=device, conf=conf, iou=iou, imgsz=imgsz, max_det=max_det, classes=classes  # ä¼ é€’å‚æ•°è¿›è¡Œæ£€æµ‹
    )

    for result in det_results:  # éå†æ£€æµ‹ç»“æœ
        class_ids = result.boxes.cls.int().tolist()  # è·å–æ£€æµ‹åˆ°çš„ç±» ID
        if len(class_ids):  # å¦‚æœæœ‰æ£€æµ‹åˆ°çš„ç±»
            boxes = result.boxes.xyxy  # è·å–è¾¹ç•Œæ¡†
            sam_results = sam_model(result.orig_img, bboxes=boxes, verbose=False, save=False, device=device)  # ä½¿ç”¨ SAM æ¨¡å‹ç”Ÿæˆåˆ†å‰²ç»“æœ
            segments = sam_results[0].masks.xyn  # è·å–åˆ†å‰²æ©è†œ

            with open(f"{Path(output_dir) / Path(result.path).stem}.txt", "w") as f:  # æ‰“å¼€è¾“å‡ºæ–‡ä»¶
                for i in range(len(segments)):  # éå†åˆ†å‰²ç»“æœ
                    s = segments[i]  # è·å–åˆ†å‰²ç»“æœ
                    if len(s) == 0:  # å¦‚æœåˆ†å‰²ç»“æœä¸ºç©º
                        continue  # è·³è¿‡
                    segment = map(str, segments[i].reshape(-1).tolist())  # å°†åˆ†å‰²ç»“æœè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    f.write(f"{class_ids[i]} " + " ".join(segment) + "\n")  # å†™å…¥è¾“å‡ºæ–‡ä»¶