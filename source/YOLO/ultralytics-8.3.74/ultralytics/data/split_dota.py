# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import itertools  # å¯¼å…¥itertoolsåº“ï¼Œç”¨äºåˆ›å»ºè¿­ä»£å™¨
from glob import glob  # ä»globæ¨¡å—å¯¼å…¥globå‡½æ•°ï¼Œç”¨äºæ–‡ä»¶è·¯å¾„åŒ¹é…
from math import ceil  # ä»mathæ¨¡å—å¯¼å…¥ceilå‡½æ•°ï¼Œç”¨äºå‘ä¸Šå–æ•´
from pathlib import Path  # ä»pathlibæ¨¡å—å¯¼å…¥Pathç±»ï¼Œç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„

import cv2  # å¯¼å…¥OpenCVåº“ï¼Œç”¨äºå›¾åƒå¤„ç†
import numpy as np  # å¯¼å…¥Numpyåº“ï¼Œç”¨äºæ•°å€¼è®¡ç®—
from PIL import Image  # ä»PILåº“å¯¼å…¥Imageç±»ï¼Œç”¨äºå¤„ç†å›¾åƒ

from ultralytics.data.utils import exif_size, img2label_paths  # å¯¼å…¥è‡ªå®šä¹‰çš„å·¥å…·å‡½æ•°
from ultralytics.utils import TQDM  # å¯¼å…¥TQDMç±»ï¼Œç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡
from ultralytics.utils.checks import check_requirements  # å¯¼å…¥æ£€æŸ¥ä¾èµ–çš„å‡½æ•°


def bbox_iof(polygon1, bbox2, eps=1e-6):
    """
    Calculate Intersection over Foreground (IoF) between polygons and bounding boxes.
    è®¡ç®—å¤šè¾¹å½¢å’Œè¾¹ç•Œæ¡†ä¹‹é—´çš„å‰æ™¯äº¤é›†ï¼ˆIoFï¼‰ã€‚

    Args:
        polygon1 (np.ndarray): Polygon coordinates, shape (n, 8).
        polygon1 (np.ndarray): å¤šè¾¹å½¢åæ ‡ï¼Œå½¢çŠ¶ä¸º(n, 8)ã€‚
        bbox2 (np.ndarray): Bounding boxes, shape (n, 4).
        bbox2 (np.ndarray): è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º(n, 4)ã€‚
        eps (float, optional): Small value to prevent division by zero. Defaults to 1e-6.
        eps (float, å¯é€‰): é˜²æ­¢é™¤ä»¥é›¶çš„å°å€¼ã€‚é»˜è®¤ä¸º1e-6ã€‚

    Returns:
        (np.ndarray): IoF scores, shape (n, 1) or (n, m) if bbox2 is (m, 4).
        (np.ndarray): IoFå¾—åˆ†ï¼Œå½¢çŠ¶ä¸º(n, 1)æˆ–(n, m)å¦‚æœbbox2ä¸º(m, 4)ã€‚

    Note:
        Polygon format: [x1, y1, x2, y2, x3, y3, x4, y4].
        å¤šè¾¹å½¢æ ¼å¼: [x1, y1, x2, y2, x3, y3, x4, y4]ã€‚
        Bounding box format: [x_min, y_min, x_max, y_max].
        è¾¹ç•Œæ¡†æ ¼å¼: [x_min, y_min, x_max, y_max]ã€‚
    """
    check_requirements("shapely")  # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†shapelyåº“
    from shapely.geometry import Polygon  # ä»shapelyåº“å¯¼å…¥Polygonç±»

    polygon1 = polygon1.reshape(-1, 4, 2)  # å°†å¤šè¾¹å½¢åæ ‡é‡å¡‘ä¸º(n, 4, 2)çš„å½¢çŠ¶
    lt_point = np.min(polygon1, axis=-2)  # left-top  # è·å–å·¦ä¸Šè§’ç‚¹
    rb_point = np.max(polygon1, axis=-2)  # right-bottom  # è·å–å³ä¸‹è§’ç‚¹
    bbox1 = np.concatenate([lt_point, rb_point], axis=-1)  # åˆ›å»ºè¾¹ç•Œæ¡†

    lt = np.maximum(bbox1[:, None, :2], bbox2[..., :2])  # è®¡ç®—å·¦ä¸Šè§’çš„æœ€å¤§å€¼
    rb = np.minimum(bbox1[:, None, 2:], bbox2[..., 2:])  # è®¡ç®—å³ä¸‹è§’çš„æœ€å°å€¼
    wh = np.clip(rb - lt, 0, np.inf)  # è®¡ç®—å®½é«˜å¹¶é™åˆ¶åœ¨éè´ŸèŒƒå›´å†…
    h_overlaps = wh[..., 0] * wh[..., 1]  # è®¡ç®—é‡å é¢ç§¯

    left, top, right, bottom = (bbox2[..., i] for i in range(4))  # è·å–è¾¹ç•Œæ¡†çš„å››ä¸ªè¾¹
    polygon2 = np.stack([left, top, right, top, right, bottom, left, bottom], axis=-1).reshape(-1, 4, 2)  # åˆ›å»ºç¬¬äºŒä¸ªå¤šè¾¹å½¢

    sg_polys1 = [Polygon(p) for p in polygon1]  # å°†å¤šè¾¹å½¢1è½¬æ¢ä¸ºshapelyå¤šè¾¹å½¢å¯¹è±¡
    sg_polys2 = [Polygon(p) for p in polygon2]  # å°†å¤šè¾¹å½¢2è½¬æ¢ä¸ºshapelyå¤šè¾¹å½¢å¯¹è±¡
    overlaps = np.zeros(h_overlaps.shape)  # åˆå§‹åŒ–é‡å é¢ç§¯æ•°ç»„
    for p in zip(*np.nonzero(h_overlaps)):  # éå†é‡å é¢ç§¯ä¸ä¸ºé›¶çš„ç´¢å¼•
        overlaps[p] = sg_polys1[p[0]].intersection(sg_polys2[p[-1]]).area  # è®¡ç®—å¤šè¾¹å½¢çš„äº¤é›†é¢ç§¯
    unions = np.array([p.area for p in sg_polys1], dtype=np.float32)  # è®¡ç®—å¤šè¾¹å½¢çš„é¢ç§¯
    unions = unions[..., None]  # æ‰©å±•ç»´åº¦ä»¥ä¾¿äºå¹¿æ’­

    unions = np.clip(unions, eps, np.inf)  # é™åˆ¶é¢ç§¯åœ¨epså’Œæ— ç©·å¤§ä¹‹é—´
    outputs = overlaps / unions  # è®¡ç®—IoFå¾—åˆ†
    if outputs.ndim == 1:
        outputs = outputs[..., None]  # å¦‚æœè¾“å‡ºæ˜¯ä¸€ç»´ï¼Œåˆ™æ‰©å±•ç»´åº¦
    return outputs  # è¿”å›IoFå¾—åˆ†


def load_yolo_dota(data_root, split="train"):
    """
    Load DOTA dataset.
    åŠ è½½DOTAæ•°æ®é›†ã€‚

    Args:
        data_root (str): Data root.
        data_root (str): æ•°æ®æ ¹ç›®å½•ã€‚
        split (str): The split data set, could be `train` or `val`.
        split (str): æ•°æ®é›†çš„åˆ’åˆ†ï¼Œå¯ä»¥æ˜¯`train`æˆ–`val`ã€‚

    Notes:
        The directory structure assumed for the DOTA dataset:
            - data_root
                - images
                    - train
                    - val
                - labels
                    - train
                    - val
    """
    assert split in {"train", "val"}, f"Split must be 'train' or 'val', not {split}."  # ç¡®ä¿åˆ’åˆ†æ˜¯'train'æˆ–'val'
    im_dir = Path(data_root) / "images" / split  # æ„å»ºå›¾åƒç›®å½•è·¯å¾„
    assert im_dir.exists(), f"Can't find {im_dir}, please check your data root."  # ç¡®ä¿å›¾åƒç›®å½•å­˜åœ¨
    im_files = glob(str(Path(data_root) / "images" / split / "*"))  # è·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    lb_files = img2label_paths(im_files)  # è·å–æ ‡ç­¾æ–‡ä»¶è·¯å¾„
    annos = []  # åˆå§‹åŒ–æ³¨é‡Šåˆ—è¡¨
    for im_file, lb_file in zip(im_files, lb_files):  # éå†å›¾åƒå’Œæ ‡ç­¾æ–‡ä»¶
        w, h = exif_size(Image.open(im_file))  # è·å–å›¾åƒçš„åŸå§‹å°ºå¯¸
        with open(lb_file) as f:  # æ‰“å¼€æ ‡ç­¾æ–‡ä»¶
            lb = [x.split() for x in f.read().strip().splitlines() if len(x)]  # è¯»å–æ ‡ç­¾æ•°æ®
            lb = np.array(lb, dtype=np.float32)  # è½¬æ¢ä¸ºNumpyæ•°ç»„
        annos.append(dict(ori_size=(h, w), label=lb, filepath=im_file))  # å°†æ³¨é‡Šä¿¡æ¯æ·»åŠ åˆ°åˆ—è¡¨
    return annos  # è¿”å›æ³¨é‡Šåˆ—è¡¨


def get_windows(im_size, crop_sizes=(1024,), gaps=(200,), im_rate_thr=0.6, eps=0.01):
    """
    Get the coordinates of windows.
    è·å–çª—å£çš„åæ ‡ã€‚

    Args:
        im_size (tuple): Original image size, (h, w).
        im_size (tuple): åŸå§‹å›¾åƒå¤§å°ï¼Œ(h, w)ã€‚
        crop_sizes (List(int)): Crop size of windows.
        crop_sizes (List(int)): çª—å£çš„è£å‰ªå¤§å°ã€‚
        gaps (List(int)): Gap between crops.
        gaps (List(int)): è£å‰ªä¹‹é—´çš„é—´éš™ã€‚
        im_rate_thr (float): Threshold of windows areas divided by image areas.
        im_rate_thr (float): çª—å£é¢ç§¯ä¸å›¾åƒé¢ç§¯ä¹‹æ¯”çš„é˜ˆå€¼ã€‚
        eps (float): Epsilon value for math operations.
        eps (float): æ•°å­¦è¿ç®—çš„epsilonå€¼ã€‚
    """
    h, w = im_size  # è·å–å›¾åƒçš„é«˜åº¦å’Œå®½åº¦
    windows = []  # åˆå§‹åŒ–çª—å£åˆ—è¡¨
    for crop_size, gap in zip(crop_sizes, gaps):  # éå†è£å‰ªå¤§å°å’Œé—´éš™
        assert crop_size > gap, f"invalid crop_size gap pair [{crop_size} {gap}]"  # ç¡®ä¿è£å‰ªå¤§å°å¤§äºé—´éš™
        step = crop_size - gap  # è®¡ç®—æ­¥å¹…

        xn = 1 if w <= crop_size else ceil((w - crop_size) / step + 1)  # è®¡ç®—åœ¨å®½åº¦æ–¹å‘ä¸Šå¯ä»¥æ”¾ç½®çš„çª—å£æ•°é‡
        xs = [step * i for i in range(xn)]  # è®¡ç®—çª—å£çš„èµ·å§‹ä½ç½®
        if len(xs) > 1 and xs[-1] + crop_size > w:  # å¦‚æœæœ€åä¸€ä¸ªçª—å£è¶…å‡ºå›¾åƒå®½åº¦
            xs[-1] = w - crop_size  # è°ƒæ•´æœ€åä¸€ä¸ªçª—å£çš„èµ·å§‹ä½ç½®

        yn = 1 if h <= crop_size else ceil((h - crop_size) / step + 1)  # è®¡ç®—åœ¨é«˜åº¦æ–¹å‘ä¸Šå¯ä»¥æ”¾ç½®çš„çª—å£æ•°é‡
        ys = [step * i for i in range(yn)]  # è®¡ç®—çª—å£çš„èµ·å§‹ä½ç½®
        if len(ys) > 1 and ys[-1] + crop_size > h:  # å¦‚æœæœ€åä¸€ä¸ªçª—å£è¶…å‡ºå›¾åƒé«˜åº¦
            ys[-1] = h - crop_size  # è°ƒæ•´æœ€åä¸€ä¸ªçª—å£çš„èµ·å§‹ä½ç½®

        start = np.array(list(itertools.product(xs, ys)), dtype=np.int64)  # è®¡ç®—çª—å£çš„èµ·å§‹åæ ‡
        stop = start + crop_size  # è®¡ç®—çª—å£çš„ç»“æŸåæ ‡
        windows.append(np.concatenate([start, stop], axis=1))  # å°†èµ·å§‹å’Œç»“æŸåæ ‡åˆå¹¶å¹¶æ·»åŠ åˆ°çª—å£åˆ—è¡¨
    windows = np.concatenate(windows, axis=0)  # åˆå¹¶æ‰€æœ‰çª—å£åæ ‡

    im_in_wins = windows.copy()  # å¤åˆ¶çª—å£åæ ‡
    im_in_wins[:, 0::2] = np.clip(im_in_wins[:, 0::2], 0, w)  # é™åˆ¶çª—å£çš„å·¦è¾¹ç•Œåœ¨å›¾åƒå®½åº¦èŒƒå›´å†…
    im_in_wins[:, 1::2] = np.clip(im_in_wins[:, 1::2], 0, h)  # é™åˆ¶çª—å£çš„ä¸Šè¾¹ç•Œåœ¨å›¾åƒé«˜åº¦èŒƒå›´å†…
    im_areas = (im_in_wins[:, 2] - im_in_wins[:, 0]) * (im_in_wins[:, 3] - im_in_wins[:, 1])  # è®¡ç®—çª—å£é¢ç§¯
    win_areas = (windows[:, 2] - windows[:, 0]) * (windows[:, 3] - windows[:, 1])  # è®¡ç®—çª—å£çš„åŸå§‹é¢ç§¯
    im_rates = im_areas / win_areas  # è®¡ç®—å›¾åƒé¢ç§¯ä¸çª—å£é¢ç§¯ä¹‹æ¯”
    if not (im_rates > im_rate_thr).any():  # å¦‚æœæ²¡æœ‰çª—å£æ»¡è¶³é¢ç§¯æ¯”é˜ˆå€¼
        max_rate = im_rates.max()  # è·å–æœ€å¤§çš„é¢ç§¯æ¯”
        im_rates[abs(im_rates - max_rate) < eps] = 1  # å°†æ¥è¿‘æœ€å¤§æ¯”ç‡çš„çª—å£è®¾ç½®ä¸º1
    return windows[im_rates > im_rate_thr]  # è¿”å›æ»¡è¶³é¢ç§¯æ¯”é˜ˆå€¼çš„çª—å£


def get_window_obj(anno, windows, iof_thr=0.7):
    """Get objects for each window."""
    # è·å–æ¯ä¸ªçª—å£çš„å¯¹è±¡ã€‚
    h, w = anno["ori_size"]  # è·å–åŸå§‹å›¾åƒçš„é«˜åº¦å’Œå®½åº¦
    label = anno["label"]  # è·å–æ ‡ç­¾ä¿¡æ¯
    if len(label):  # å¦‚æœæœ‰æ ‡ç­¾
        label[:, 1::2] *= w  # å°†æ ‡ç­¾çš„xåæ ‡ä¹˜ä»¥å›¾åƒå®½åº¦
        label[:, 2::2] *= h  # å°†æ ‡ç­¾çš„yåæ ‡ä¹˜ä»¥å›¾åƒé«˜åº¦
        iofs = bbox_iof(label[:, 1:], windows)  # è®¡ç®—æ¯ä¸ªæ ‡ç­¾ä¸çª—å£çš„IoF
        # Unnormalized and misaligned coordinates
        return [(label[iofs[:, i] >= iof_thr]) for i in range(len(windows))]  # è¿”å›æ»¡è¶³IoFé˜ˆå€¼çš„çª—å£æ³¨é‡Š
    else:
        return [np.zeros((0, 9), dtype=np.float32) for _ in range(len(windows))]  # è¿”å›ç©ºçš„çª—å£æ³¨é‡Š


def crop_and_save(anno, windows, window_objs, im_dir, lb_dir, allow_background_images=True):
    """
    Crop images and save new labels.
    è£å‰ªå›¾åƒå¹¶ä¿å­˜æ–°æ ‡ç­¾ã€‚

    Args:
        anno (dict): Annotation dict, including `filepath`, `label`, `ori_size` as its keys.
        anno (dict): æ³¨é‡Šå­—å…¸ï¼ŒåŒ…æ‹¬`filepath`ã€`label`ã€`ori_size`ä½œä¸ºå…¶é”®ã€‚
        windows (list): A list of windows coordinates.
        windows (list): çª—å£åæ ‡çš„åˆ—è¡¨ã€‚
        window_objs (list): A list of labels inside each window.
        window_objs (list): æ¯ä¸ªçª—å£å†…æ ‡ç­¾çš„åˆ—è¡¨ã€‚
        im_dir (str): The output directory path of images.
        im_dir (str): å›¾åƒçš„è¾“å‡ºç›®å½•è·¯å¾„ã€‚
        lb_dir (str): The output directory path of labels.
        lb_dir (str): æ ‡ç­¾çš„è¾“å‡ºç›®å½•è·¯å¾„ã€‚
        allow_background_images (bool): Whether to include background images without labels.
        allow_background_images (bool): æ˜¯å¦åŒ…å«æ²¡æœ‰æ ‡ç­¾çš„èƒŒæ™¯å›¾åƒã€‚

    Notes:
        The directory structure assumed for the DOTA dataset:
            - data_root
                - images
                    - train
                    - val
                - labels
                    - train
                    - val
    """
    im = cv2.imread(anno["filepath"])  # è¯»å–åŸå§‹å›¾åƒ
    name = Path(anno["filepath"]).stem  # è·å–å›¾åƒæ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
    for i, window in enumerate(windows):  # éå†æ¯ä¸ªçª—å£
        x_start, y_start, x_stop, y_stop = window.tolist()  # è·å–çª—å£çš„åæ ‡
        new_name = f"{name}__{x_stop - x_start}__{x_start}___{y_start}"  # ç”Ÿæˆæ–°æ–‡ä»¶å
        patch_im = im[y_start:y_stop, x_start:x_stop]  # è£å‰ªå›¾åƒ
        ph, pw = patch_im.shape[:2]  # è·å–è£å‰ªå›¾åƒçš„é«˜åº¦å’Œå®½åº¦

        label = window_objs[i]  # è·å–å½“å‰çª—å£çš„æ ‡ç­¾
        if len(label) or allow_background_images:  # å¦‚æœæœ‰æ ‡ç­¾æˆ–å…è®¸èƒŒæ™¯å›¾åƒ
            cv2.imwrite(str(Path(im_dir) / f"{new_name}.jpg"), patch_im)  # ä¿å­˜è£å‰ªåçš„å›¾åƒ
        if len(label):  # å¦‚æœæœ‰æ ‡ç­¾
            label[:, 1::2] -= x_start  # å°†æ ‡ç­¾çš„xåæ ‡å‡å»çª—å£çš„å·¦åæ ‡
            label[:, 2::2] -= y_start  # å°†æ ‡ç­¾çš„yåæ ‡å‡å»çª—å£çš„ä¸Šåæ ‡
            label[:, 1::2] /= pw  # å°†æ ‡ç­¾çš„xåæ ‡å½’ä¸€åŒ–
            label[:, 2::2] /= ph  # å°†æ ‡ç­¾çš„yåæ ‡å½’ä¸€åŒ–

            with open(Path(lb_dir) / f"{new_name}.txt", "w") as f:  # æ‰“å¼€æ ‡ç­¾æ–‡ä»¶ä»¥å†™å…¥
                for lb in label:  # éå†æ ‡ç­¾
                    formatted_coords = [f"{coord:.6g}" for coord in lb[1:]]  # æ ¼å¼åŒ–åæ ‡
                    f.write(f"{int(lb[0])} {' '.join(formatted_coords)}\n")  # å†™å…¥æ ‡ç­¾ä¿¡æ¯


def split_images_and_labels(data_root, save_dir, split="train", crop_sizes=(1024,), gaps=(200,)):
    """
    Split both images and labels.
    åŒæ—¶æ‹†åˆ†å›¾åƒå’Œæ ‡ç­¾ã€‚

    Notes:
        The directory structure assumed for the DOTA dataset:
            - data_root
                - images
                    - split
                - labels
                    - split
        and the output directory structure is:
            - save_dir
                - images
                    - split
                - labels
                    - split
    """
    im_dir = Path(save_dir) / "images" / split  # æ„å»ºè¾“å‡ºå›¾åƒç›®å½•è·¯å¾„
    im_dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºå›¾åƒç›®å½•
    lb_dir = Path(save_dir) / "labels" / split  # æ„å»ºè¾“å‡ºæ ‡ç­¾ç›®å½•è·¯å¾„
    lb_dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºæ ‡ç­¾ç›®å½•

    annos = load_yolo_dota(data_root, split=split)  # åŠ è½½DOTAæ•°æ®é›†
    for anno in TQDM(annos, total=len(annos), desc=split):  # éå†æ³¨é‡Š
        windows = get_windows(anno["ori_size"], crop_sizes, gaps)  # è·å–çª—å£åæ ‡
        window_objs = get_window_obj(anno, windows)  # è·å–æ¯ä¸ªçª—å£çš„å¯¹è±¡
        crop_and_save(anno, windows, window_objs, str(im_dir), str(lb_dir))  # è£å‰ªå¹¶ä¿å­˜å›¾åƒå’Œæ ‡ç­¾


def split_trainval(data_root, save_dir, crop_size=1024, gap=200, rates=(1.0,)):
    """
    Split train and val set of DOTA.
    æ‹†åˆ†DOTAçš„è®­ç»ƒå’ŒéªŒè¯é›†ã€‚

    Notes:
        The directory structure assumed for the DOTA dataset:
            - data_root
                - images
                    - train
                    - val
                - labels
                    - train
                    - val
        and the output directory structure is:
            - save_dir
                - images
                    - train
                    - val
                - labels
                    - train
                    - val
    """
    crop_sizes, gaps = [], []  # åˆå§‹åŒ–è£å‰ªå¤§å°å’Œé—´éš™åˆ—è¡¨
    for r in rates:  # éå†æ¯”ä¾‹
        crop_sizes.append(int(crop_size / r))  # è®¡ç®—è£å‰ªå¤§å°
        gaps.append(int(gap / r))  # è®¡ç®—é—´éš™
    for split in ["train", "val"]:  # éå†è®­ç»ƒå’ŒéªŒè¯é›†
        split_images_and_labels(data_root, save_dir, split, crop_sizes, gaps)  # æ‹†åˆ†å›¾åƒå’Œæ ‡ç­¾


def split_test(data_root, save_dir, crop_size=1024, gap=200, rates=(1.0,)):
    """
    Split test set of DOTA, labels are not included within this set.
    æ‹†åˆ†DOTAçš„æµ‹è¯•é›†ï¼Œæ ‡ç­¾ä¸åŒ…å«åœ¨æ­¤é›†ä¸­ã€‚

    Notes:
        The directory structure assumed for the DOTA dataset:
            - data_root
                - images
                    - test
        and the output directory structure is:
            - save_dir
                - images
                    - test
    """
    crop_sizes, gaps = [], []  # åˆå§‹åŒ–è£å‰ªå¤§å°å’Œé—´éš™åˆ—è¡¨
    for r in rates:  # éå†æ¯”ä¾‹
        crop_sizes.append(int(crop_size / r))  # è®¡ç®—è£å‰ªå¤§å°
        gaps.append(int(gap / r))  # è®¡ç®—é—´éš™
    save_dir = Path(save_dir) / "images" / "test"  # æ„å»ºè¾“å‡ºæµ‹è¯•å›¾åƒç›®å½•è·¯å¾„
    save_dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºæµ‹è¯•å›¾åƒç›®å½•

    im_dir = Path(data_root) / "images" / "test"  # æ„å»ºè¾“å…¥æµ‹è¯•å›¾åƒç›®å½•è·¯å¾„
    assert im_dir.exists(), f"Can't find {im_dir}, please check your data root."  # ç¡®ä¿è¾“å…¥ç›®å½•å­˜åœ¨
    im_files = glob(str(im_dir / "*"))  # è·å–æµ‹è¯•å›¾åƒæ–‡ä»¶åˆ—è¡¨
    for im_file in TQDM(im_files, total=len(im_files), desc="test"):  # éå†æµ‹è¯•å›¾åƒ
        w, h = exif_size(Image.open(im_file))  # è·å–å›¾åƒçš„åŸå§‹å°ºå¯¸
        windows = get_windows((h, w), crop_sizes=crop_sizes, gaps=gaps)  # è·å–çª—å£åæ ‡
        im = cv2.imread(im_file)  # è¯»å–å›¾åƒ
        name = Path(im_file).stem  # è·å–å›¾åƒæ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
        for window in windows:  # éå†æ¯ä¸ªçª—å£
            x_start, y_start, x_stop, y_stop = window.tolist()  # è·å–çª—å£çš„åæ ‡
            new_name = f"{name}__{x_stop - x_start}__{x_start}___{y_start}"  # ç”Ÿæˆæ–°æ–‡ä»¶å
            patch_im = im[y_start:y_stop, x_start:x_stop]  # è£å‰ªå›¾åƒ
            cv2.imwrite(str(save_dir / f"{new_name}.jpg"), patch_im)  # ä¿å­˜è£å‰ªåçš„å›¾åƒ


if __name__ == "__main__":
    split_trainval(data_root="DOTAv2", save_dir="DOTAv2-split")  # æ‹†åˆ†è®­ç»ƒå’ŒéªŒè¯é›†
    split_test(data_root="DOTAv2", save_dir="DOTAv2-split")  # æ‹†åˆ†æµ‹è¯•é›†