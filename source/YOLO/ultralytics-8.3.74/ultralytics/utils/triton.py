# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from typing import List
from urllib.parse import urlsplit

import numpy as np


class TritonRemoteModel:  # å®šä¹‰ TritonRemoteModel ç±»
    """
    Client for interacting with a remote Triton Inference Server model.  # ä¸è¿œç¨‹ Triton æ¨ç†æœåŠ¡å™¨æ¨¡å‹äº¤äº’çš„å®¢æˆ·ç«¯

    Attributes:  # å±æ€§è¯´æ˜
        endpoint (str): The name of the model on the Triton server.  # æ¨¡å‹åœ¨ Triton æœåŠ¡å™¨ä¸Šçš„åç§°
        url (str): The URL of the Triton server.  # Triton æœåŠ¡å™¨çš„ URL
        triton_client: The Triton client (either HTTP or gRPC).  # Triton å®¢æˆ·ç«¯ï¼ˆHTTP æˆ– gRPCï¼‰
        InferInput: The input class for the Triton client.  # Triton å®¢æˆ·ç«¯çš„è¾“å…¥ç±»
        InferRequestedOutput: The output request class for the Triton client.  # Triton å®¢æˆ·ç«¯çš„è¾“å‡ºè¯·æ±‚ç±»
        input_formats (List[str]): The data types of the model inputs.  # æ¨¡å‹è¾“å…¥çš„æ•°æ®ç±»å‹
        np_input_formats (List[type]): The numpy data types of the model inputs.  # æ¨¡å‹è¾“å…¥çš„ numpy æ•°æ®ç±»å‹
        input_names (List[str]): The names of the model inputs.  # æ¨¡å‹è¾“å…¥çš„åç§°
        output_names (List[str]): The names of the model outputs.  # æ¨¡å‹è¾“å‡ºçš„åç§°
    """

    def __init__(self, url: str, endpoint: str = "", scheme: str = ""):  # åˆå§‹åŒ–æ–¹æ³•
        """
        Initialize the TritonRemoteModel.  # åˆå§‹åŒ– TritonRemoteModel

        Arguments may be provided individually or parsed from a collective 'url' argument of the form  # å‚æ•°å¯ä»¥å•ç‹¬æä¾›æˆ–ä»ä¸€ä¸ªé›†ä½“çš„ 'url' å‚æ•°è§£æ
            <scheme>://<netloc>/<endpoint>/<task_name>  # URL æ ¼å¼

        Args:  # å‚æ•°è¯´æ˜
            url (str): The URL of the Triton server.  # Triton æœåŠ¡å™¨çš„ URL
            endpoint (str): The name of the model on the Triton server.  # æ¨¡å‹åœ¨ Triton æœåŠ¡å™¨ä¸Šçš„åç§°
            scheme (str): The communication scheme ('http' or 'grpc').  # é€šä¿¡æ–¹æ¡ˆï¼ˆ'http' æˆ– 'grpc'ï¼‰
        """
        if not endpoint and not scheme:  # å¦‚æœæ²¡æœ‰æä¾› endpoint å’Œ schemeï¼Œåˆ™ä» URL å­—ç¬¦ä¸²è§£ææ‰€æœ‰å‚æ•°
            splits = urlsplit(url)  # è§£æ URL
            endpoint = splits.path.strip("/").split("/")[0]  # è·å– endpoint
            scheme = splits.scheme  # è·å– scheme
            url = splits.netloc  # è·å– URL çš„ç½‘ç»œä½ç½®

        self.endpoint = endpoint  # è®¾ç½®å®ä¾‹çš„ endpoint å±æ€§
        self.url = url  # è®¾ç½®å®ä¾‹çš„ url å±æ€§

        # Choose the Triton client based on the communication scheme  # æ ¹æ®é€šä¿¡æ–¹æ¡ˆé€‰æ‹© Triton å®¢æˆ·ç«¯
        if scheme == "http":  # å¦‚æœæ–¹æ¡ˆæ˜¯ HTTP
            import tritonclient.http as client  # noqa  # å¯¼å…¥ HTTP å®¢æˆ·ç«¯

            self.triton_client = client.InferenceServerClient(url=self.url, verbose=False, ssl=False)  # åˆ›å»º Triton å®¢æˆ·ç«¯å®ä¾‹
            config = self.triton_client.get_model_config(endpoint)  # è·å–æ¨¡å‹é…ç½®
        else:  # å¦‚æœæ–¹æ¡ˆä¸æ˜¯ HTTP
            import tritonclient.grpc as client  # noqa  # å¯¼å…¥ gRPC å®¢æˆ·ç«¯

            self.triton_client = client.InferenceServerClient(url=self.url, verbose=False, ssl=False)  # åˆ›å»º Triton å®¢æˆ·ç«¯å®ä¾‹
            config = self.triton_client.get_model_config(endpoint, as_json=True)["config"]  # è·å–æ¨¡å‹é…ç½®

        # Sort output names alphabetically, i.e. 'output0', 'output1', etc.  # æŒ‰å­—æ¯é¡ºåºæ’åºè¾“å‡ºåç§°ï¼Œä¾‹å¦‚ 'output0', 'output1' ç­‰
        config["output"] = sorted(config["output"], key=lambda x: x.get("name"))  # å¯¹è¾“å‡ºè¿›è¡Œæ’åº

        # Define model attributes  # å®šä¹‰æ¨¡å‹å±æ€§
        type_map = {"TYPE_FP32": np.float32, "TYPE_FP16": np.float16, "TYPE_UINT8": np.uint8}  # æ•°æ®ç±»å‹æ˜ å°„
        self.InferRequestedOutput = client.InferRequestedOutput  # è®¾ç½® InferRequestedOutput å±æ€§
        self.InferInput = client.InferInput  # è®¾ç½® InferInput å±æ€§
        self.input_formats = [x["data_type"] for x in config["input"]]  # è·å–è¾“å…¥æ ¼å¼
        self.np_input_formats = [type_map[x] for x in self.input_formats]  # è·å– numpy è¾“å…¥æ ¼å¼
        self.input_names = [x["name"] for x in config["input"]]  # è·å–è¾“å…¥åç§°
        self.output_names = [x["name"] for x in config["output"]]  # è·å–è¾“å‡ºåç§°
        self.metadata = eval(config.get("parameters", {}).get("metadata", {}).get("string_value", "None"))  # è·å–å…ƒæ•°æ®

    def __call__(self, *inputs: np.ndarray) -> List[np.ndarray]:  # å®šä¹‰è°ƒç”¨æ–¹æ³•
        """
        Call the model with the given inputs.  # ä½¿ç”¨ç»™å®šçš„è¾“å…¥è°ƒç”¨æ¨¡å‹

        Args:  # å‚æ•°è¯´æ˜
            *inputs (List[np.ndarray]): Input data to the model.  # è¾“å…¥æ•°æ®

        Returns:  # è¿”å›å€¼è¯´æ˜
            (List[np.ndarray]): Model outputs.  # æ¨¡å‹è¾“å‡º
        """
        infer_inputs = []  # åˆå§‹åŒ–æ¨ç†è¾“å…¥åˆ—è¡¨
        input_format = inputs[0].dtype  # è·å–è¾“å…¥æ•°æ®ç±»å‹
        for i, x in enumerate(inputs):  # éå†è¾“å…¥æ•°æ®
            if x.dtype != self.np_input_formats[i]:  # å¦‚æœæ•°æ®ç±»å‹ä¸åŒ¹é…
                x = x.astype(self.np_input_formats[i])  # è½¬æ¢æ•°æ®ç±»å‹
            infer_input = self.InferInput(self.input_names[i], [*x.shape], self.input_formats[i].replace("TYPE_", ""))  # åˆ›å»ºæ¨ç†è¾“å…¥
            infer_input.set_data_from_numpy(x)  # è®¾ç½®æ¨ç†è¾“å…¥æ•°æ®
            infer_inputs.append(infer_input)  # æ·»åŠ åˆ°æ¨ç†è¾“å…¥åˆ—è¡¨

        infer_outputs = [self.InferRequestedOutput(output_name) for output_name in self.output_names]  # åˆ›å»ºæ¨ç†è¾“å‡ºåˆ—è¡¨
        outputs = self.triton_client.infer(model_name=self.endpoint, inputs=infer_inputs, outputs=infer_outputs)  # æ‰§è¡Œæ¨ç†

        return [outputs.as_numpy(output_name).astype(input_format) for output_name in self.output_names]  # è¿”å›æ¨¡å‹è¾“å‡º