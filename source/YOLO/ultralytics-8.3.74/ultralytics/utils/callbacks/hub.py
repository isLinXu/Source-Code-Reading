# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license  # Ultralytics ğŸš€ AGPL-3.0 è®¸å¯è¯ - https://ultralytics.com/license

import json  # å¯¼å…¥ json æ¨¡å—
from time import time  # ä» time æ¨¡å—å¯¼å…¥ time å‡½æ•°

from ultralytics.hub import HUB_WEB_ROOT, PREFIX, HUBTrainingSession, events  # ä» ultralytics.hub å¯¼å…¥ç›¸å…³ç»„ä»¶
from ultralytics.utils import LOGGER, RANK, SETTINGS  # ä» ultralytics.utils å¯¼å…¥ LOGGERã€RANK å’Œ SETTINGS


def on_pretrain_routine_start(trainer):
    """Create a remote Ultralytics HUB session to log local model training.  # åˆ›å»ºä¸€ä¸ªè¿œç¨‹ Ultralytics HUB ä¼šè¯ä»¥è®°å½•æœ¬åœ°æ¨¡å‹è®­ç»ƒã€‚"""
    if RANK in {-1, 0} and SETTINGS["hub"] is True and SETTINGS["api_key"] and trainer.hub_session is None:  # å¦‚æœå½“å‰è¿›ç¨‹æ˜¯ä¸»è¿›ç¨‹ä¸”å¯ç”¨äº† HUB é›†æˆä¸”æœ‰ API å¯†é’¥ä¸”æ²¡æœ‰ç°æœ‰ä¼šè¯
        trainer.hub_session = HUBTrainingSession.create_session(trainer.args.model, trainer.args)  # åˆ›å»º HUBTrainingSession å®ä¾‹


def on_pretrain_routine_end(trainer):
    """Logs info before starting timer for upload rate limit.  # åœ¨å¼€å§‹ä¸Šä¼ é€Ÿç‡é™åˆ¶è®¡æ—¶å™¨ä¹‹å‰è®°å½•ä¿¡æ¯ã€‚"""
    if session := getattr(trainer, "hub_session", None):  # è·å–å½“å‰è®­ç»ƒä¼šè¯
        # Start timer for upload rate limit  # å¯åŠ¨ä¸Šä¼ é€Ÿç‡é™åˆ¶è®¡æ—¶å™¨
        session.timers = {"metrics": time(), "ckpt": time()}  # åœ¨ session.rate_limit ä¸Šå¯åŠ¨è®¡æ—¶å™¨


def on_fit_epoch_end(trainer):
    """Uploads training progress metrics at the end of each epoch.  # åœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶ä¸Šä¼ è®­ç»ƒè¿›åº¦æŒ‡æ ‡ã€‚"""
    if session := getattr(trainer, "hub_session", None):  # è·å–å½“å‰è®­ç»ƒä¼šè¯
        # Upload metrics after val end  # åœ¨éªŒè¯ç»“æŸåä¸Šä¼ æŒ‡æ ‡
        all_plots = {  # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
            **trainer.label_loss_items(trainer.tloss, prefix="train"),  # è·å–è®­ç»ƒæŸå¤±é¡¹
            **trainer.metrics,  # è·å–å…¶ä»–æŒ‡æ ‡
        }
        if trainer.epoch == 0:  # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªå‘¨æœŸ
            from ultralytics.utils.torch_utils import model_info_for_loggers  # ä» ultralytics.utils.torch_utils å¯¼å…¥ model_info_for_loggers

            all_plots = {**all_plots, **model_info_for_loggers(trainer)}  # æ·»åŠ æ¨¡å‹ä¿¡æ¯åˆ°æŒ‡æ ‡

        session.metrics_queue[trainer.epoch] = json.dumps(all_plots)  # å°†æŒ‡æ ‡è½¬æ¢ä¸º JSON æ ¼å¼å¹¶å­˜å…¥é˜Ÿåˆ—

        # If any metrics fail to upload, add them to the queue to attempt uploading again.  # å¦‚æœä»»ä½•æŒ‡æ ‡ä¸Šä¼ å¤±è´¥ï¼Œå°†å…¶æ·»åŠ åˆ°é˜Ÿåˆ—ä»¥å°è¯•å†æ¬¡ä¸Šä¼ ã€‚
        if session.metrics_upload_failed_queue:  # å¦‚æœæœ‰ä¸Šä¼ å¤±è´¥çš„æŒ‡æ ‡
            session.metrics_queue.update(session.metrics_upload_failed_queue)  # æ›´æ–°æŒ‡æ ‡é˜Ÿåˆ—

        if time() - session.timers["metrics"] > session.rate_limits["metrics"]:  # å¦‚æœè¶…è¿‡é€Ÿç‡é™åˆ¶
            session.upload_metrics()  # ä¸Šä¼ æŒ‡æ ‡
            session.timers["metrics"] = time()  # é‡ç½®è®¡æ—¶å™¨
            session.metrics_queue = {}  # é‡ç½®é˜Ÿåˆ—


def on_model_save(trainer):
    """Saves checkpoints to Ultralytics HUB with rate limiting.  # ä»¥é€Ÿç‡é™åˆ¶å°†æ£€æŸ¥ç‚¹ä¿å­˜åˆ° Ultralytics HUBã€‚"""
    if session := getattr(trainer, "hub_session", None):  # è·å–å½“å‰è®­ç»ƒä¼šè¯
        # Upload checkpoints with rate limiting  # ä»¥é€Ÿç‡é™åˆ¶ä¸Šä¼ æ£€æŸ¥ç‚¹
        is_best = trainer.best_fitness == trainer.fitness  # åˆ¤æ–­å½“å‰æ¨¡å‹æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        if time() - session.timers["ckpt"] > session.rate_limits["ckpt"]:  # å¦‚æœè¶…è¿‡é€Ÿç‡é™åˆ¶
            LOGGER.info(f"{PREFIX}Uploading checkpoint {HUB_WEB_ROOT}/models/{session.model.id}")  # è®°å½•ä¸Šä¼ ä¿¡æ¯
            session.upload_model(trainer.epoch, trainer.last, is_best)  # ä¸Šä¼ æ¨¡å‹
            session.timers["ckpt"] = time()  # é‡ç½®è®¡æ—¶å™¨


def on_train_end(trainer):
    """Upload final model and metrics to Ultralytics HUB at the end of training.  # åœ¨è®­ç»ƒç»“æŸæ—¶å°†æœ€ç»ˆæ¨¡å‹å’ŒæŒ‡æ ‡ä¸Šä¼ åˆ° Ultralytics HUBã€‚"""
    if session := getattr(trainer, "hub_session", None):  # è·å–å½“å‰è®­ç»ƒä¼šè¯
        # Upload final model and metrics with exponential standoff  # ä»¥æŒ‡æ•°é—´éš”ä¸Šä¼ æœ€ç»ˆæ¨¡å‹å’ŒæŒ‡æ ‡
        LOGGER.info(f"{PREFIX}Syncing final model...")  # è®°å½•åŒæ­¥ä¿¡æ¯
        session.upload_model(  # ä¸Šä¼ æœ€ç»ˆæ¨¡å‹
            trainer.epoch,
            trainer.best,
            map=trainer.metrics.get("metrics/mAP50-95(B)", 0),  # è·å– mAP æŒ‡æ ‡
            final=True,  # æ ‡è®°ä¸ºæœ€ç»ˆæ¨¡å‹
        )
        session.alive = False  # åœæ­¢å¿ƒè·³
        LOGGER.info(f"{PREFIX}Done âœ…\n{PREFIX}View model at {session.model_url} ğŸš€")  # è®°å½•å®Œæˆä¿¡æ¯


def on_train_start(trainer):
    """Run events on train start.  # åœ¨è®­ç»ƒå¼€å§‹æ—¶è¿è¡Œäº‹ä»¶ã€‚"""
    events(trainer.args)  # è§¦å‘äº‹ä»¶


def on_val_start(validator):
    """Runs events on validation start.  # åœ¨éªŒè¯å¼€å§‹æ—¶è¿è¡Œäº‹ä»¶ã€‚"""
    events(validator.args)  # è§¦å‘äº‹ä»¶


def on_predict_start(predictor):
    """Run events on predict start.  # åœ¨é¢„æµ‹å¼€å§‹æ—¶è¿è¡Œäº‹ä»¶ã€‚"""
    events(predictor.args)  # è§¦å‘äº‹ä»¶


def on_export_start(exporter):
    """Run events on export start.  # åœ¨å¯¼å‡ºå¼€å§‹æ—¶è¿è¡Œäº‹ä»¶ã€‚"""
    events(exporter.args)  # è§¦å‘äº‹ä»¶


callbacks = (  # å®šä¹‰å›è°ƒå‡½æ•°
    {
        "on_pretrain_routine_start": on_pretrain_routine_start,  # é¢„è®­ç»ƒä¾‹ç¨‹å¼€å§‹æ—¶çš„å›è°ƒ
        "on_pretrain_routine_end": on_pretrain_routine_end,  # é¢„è®­ç»ƒä¾‹ç¨‹ç»“æŸæ—¶çš„å›è°ƒ
        "on_fit_epoch_end": on_fit_epoch_end,  # æ‹Ÿåˆå‘¨æœŸç»“æŸæ—¶çš„å›è°ƒ
        "on_model_save": on_model_save,  # ä¿å­˜æ¨¡å‹æ—¶çš„å›è°ƒ
        "on_train_end": on_train_end,  # è®­ç»ƒç»“æŸæ—¶çš„å›è°ƒ
        "on_train_start": on_train_start,  # è®­ç»ƒå¼€å§‹æ—¶çš„å›è°ƒ
        "on_val_start": on_val_start,  # éªŒè¯å¼€å§‹æ—¶çš„å›è°ƒ
        "on_predict_start": on_predict_start,  # é¢„æµ‹å¼€å§‹æ—¶çš„å›è°ƒ
        "on_export_start": on_export_start,  # å¯¼å‡ºå¼€å§‹æ—¶çš„å›è°ƒ
    }
    if SETTINGS["hub"] is True  # å¦‚æœå¯ç”¨äº† hub è®¾ç½®
    else {}
)  # éªŒè¯å¯ç”¨