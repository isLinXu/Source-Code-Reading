# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license  # Ultralytics ğŸš€ AGPL-3.0 è®¸å¯è¯ - https://ultralytics.com/license

from ultralytics.utils import LOGGER, RANK, SETTINGS, TESTS_RUNNING, ops  # ä» ultralytics.utils å¯¼å…¥ LOGGERã€RANKã€SETTINGSã€TESTS_RUNNING å’Œ ops
from ultralytics.utils.metrics import ClassifyMetrics, DetMetrics, OBBMetrics, PoseMetrics, SegmentMetrics  # ä» ultralytics.utils.metrics å¯¼å…¥å¤šç§æŒ‡æ ‡ç±»

try:
    assert not TESTS_RUNNING  # do not log pytest  # ç¡®ä¿ä¸åœ¨ pytest ä¸­è®°å½•
    assert SETTINGS["comet"] is True  # verify integration is enabled  # éªŒè¯é›†æˆæ˜¯å¦å¯ç”¨
    import comet_ml  # å¯¼å…¥ comet_ml åº“

    assert hasattr(comet_ml, "__version__")  # verify package is not directory  # éªŒè¯åŒ…ä¸æ˜¯ç›®å½•

    import os  # å¯¼å…¥ os æ¨¡å—
    from pathlib import Path  # ä» pathlib å¯¼å…¥ Path ç±»

    # Ensures certain logging functions only run for supported tasks  # ç¡®ä¿æŸäº›æ—¥å¿—è®°å½•åŠŸèƒ½ä»…åœ¨æ”¯æŒçš„ä»»åŠ¡ä¸­è¿è¡Œ
    COMET_SUPPORTED_TASKS = ["detect"]  # æ”¯æŒçš„ä»»åŠ¡åˆ—è¡¨

    # Names of plots created by Ultralytics that are logged to Comet  # Ultralytics åˆ›å»ºçš„å›¾è¡¨åç§°ï¼Œå°†è®°å½•åˆ° Comet
    CONFUSION_MATRIX_PLOT_NAMES = "confusion_matrix", "confusion_matrix_normalized"  # æ··æ·†çŸ©é˜µå›¾åç§°
    EVALUATION_PLOT_NAMES = "F1_curve", "P_curve", "R_curve", "PR_curve"  # è¯„ä¼°å›¾åç§°
    LABEL_PLOT_NAMES = "labels", "labels_correlogram"  # æ ‡ç­¾å›¾åç§°
    SEGMENT_METRICS_PLOT_PREFIX = "Box", "Mask"  # åˆ†å‰²æŒ‡æ ‡å›¾å‰ç¼€
    POSE_METRICS_PLOT_PREFIX = "Box", "Pose"  # å§¿æ€æŒ‡æ ‡å›¾å‰ç¼€

    _comet_image_prediction_count = 0  # åˆå§‹åŒ–å›¾åƒé¢„æµ‹è®¡æ•°

except (ImportError, AssertionError):  # æ•è·å¯¼å…¥é”™è¯¯æˆ–æ–­è¨€é”™è¯¯
    comet_ml = None  # å¦‚æœå¯¼å…¥å¤±è´¥æˆ–æ–­è¨€å¤±è´¥ï¼Œåˆ™å°† comet_ml è®¾ç½®ä¸º None


def _get_comet_mode():
    """Returns the mode of comet set in the environment variables, defaults to 'online' if not set.  # è¿”å›ç¯å¢ƒå˜é‡ä¸­è®¾ç½®çš„ comet æ¨¡å¼ï¼Œå¦‚æœæœªè®¾ç½®åˆ™é»˜è®¤ä¸º 'online'ã€‚"""
    return os.getenv("COMET_MODE", "online")  # è·å– COMET_MODE ç¯å¢ƒå˜é‡çš„å€¼


def _get_comet_model_name():
    """Returns the model name for Comet from the environment variable COMET_MODEL_NAME or defaults to 'Ultralytics'.  # ä»ç¯å¢ƒå˜é‡ COMET_MODEL_NAME è¿”å› Comet çš„æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º 'Ultralytics'ã€‚"""
    return os.getenv("COMET_MODEL_NAME", "Ultralytics")  # è·å– COMET_MODEL_NAME ç¯å¢ƒå˜é‡çš„å€¼


def _get_eval_batch_logging_interval():
    """Get the evaluation batch logging interval from environment variable or use default value 1.  # ä»ç¯å¢ƒå˜é‡è·å–è¯„ä¼°æ‰¹æ¬¡æ—¥å¿—è®°å½•é—´éš”ï¼Œé»˜è®¤ä¸º 1ã€‚"""
    return int(os.getenv("COMET_EVAL_BATCH_LOGGING_INTERVAL", 1))  # è·å– COMET_EVAL_BATCH_LOGGING_INTERVAL ç¯å¢ƒå˜é‡çš„å€¼


def _get_max_image_predictions_to_log():
    """Get the maximum number of image predictions to log from the environment variables.  # ä»ç¯å¢ƒå˜é‡è·å–è¦è®°å½•çš„æœ€å¤§å›¾åƒé¢„æµ‹æ•°é‡ã€‚"""
    return int(os.getenv("COMET_MAX_IMAGE_PREDICTIONS", 100))  # è·å– COMET_MAX_IMAGE_PREDICTIONS ç¯å¢ƒå˜é‡çš„å€¼


def _scale_confidence_score(score):
    """Scales the given confidence score by a factor specified in an environment variable.  # æ ¹æ®ç¯å¢ƒå˜é‡ä¸­æŒ‡å®šçš„å› å­ç¼©æ”¾ç»™å®šçš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚"""
    scale = float(os.getenv("COMET_MAX_CONFIDENCE_SCORE", 100.0))  # è·å– COMET_MAX_CONFIDENCE_SCORE ç¯å¢ƒå˜é‡çš„å€¼
    return score * scale  # è¿”å›ç¼©æ”¾åçš„ç½®ä¿¡åº¦åˆ†æ•°


def _should_log_confusion_matrix():
    """Determines if the confusion matrix should be logged based on the environment variable settings.  # æ ¹æ®ç¯å¢ƒå˜é‡è®¾ç½®ç¡®å®šæ˜¯å¦åº”è®°å½•æ··æ·†çŸ©é˜µã€‚"""
    return os.getenv("COMET_EVAL_LOG_CONFUSION_MATRIX", "false").lower() == "true"  # æ£€æŸ¥ç¯å¢ƒå˜é‡


def _should_log_image_predictions():
    """Determines whether to log image predictions based on a specified environment variable.  # æ ¹æ®æŒ‡å®šçš„ç¯å¢ƒå˜é‡ç¡®å®šæ˜¯å¦è®°å½•å›¾åƒé¢„æµ‹ã€‚"""
    return os.getenv("COMET_EVAL_LOG_IMAGE_PREDICTIONS", "true").lower() == "true"  # æ£€æŸ¥ç¯å¢ƒå˜é‡


def _get_experiment_type(mode, project_name):
    """Return an experiment based on mode and project name.  # æ ¹æ®æ¨¡å¼å’Œé¡¹ç›®åç§°è¿”å›å®éªŒã€‚"""
    if mode == "offline":  # å¦‚æœæ¨¡å¼ä¸ºç¦»çº¿
        return comet_ml.OfflineExperiment(project_name=project_name)  # è¿”å›ç¦»çº¿å®éªŒ

    return comet_ml.Experiment(project_name=project_name)  # è¿”å›åœ¨çº¿å®éªŒ


def _create_experiment(args):
    """Ensures that the experiment object is only created in a single process during distributed training.  # ç¡®ä¿åœ¨åˆ†å¸ƒå¼è®­ç»ƒæœŸé—´ä»…åœ¨å•ä¸ªè¿›ç¨‹ä¸­åˆ›å»ºå®éªŒå¯¹è±¡ã€‚"""
    if RANK not in {-1, 0}:  # å¦‚æœå½“å‰è¿›ç¨‹ä¸æ˜¯ä¸»è¿›ç¨‹
        return  # é€€å‡ºå‡½æ•°
    try:
        comet_mode = _get_comet_mode()  # è·å–å½“å‰çš„ comet æ¨¡å¼
        _project_name = os.getenv("COMET_PROJECT_NAME", args.project)  # è·å–é¡¹ç›®åç§°
        experiment = _get_experiment_type(comet_mode, _project_name)  # åˆ›å»ºå®éªŒå¯¹è±¡
        experiment.log_parameters(vars(args))  # è®°å½•å‚æ•°
        experiment.log_others(  # è®°å½•å…¶ä»–ä¿¡æ¯
            {
                "eval_batch_logging_interval": _get_eval_batch_logging_interval(),  # è®°å½•è¯„ä¼°æ‰¹æ¬¡æ—¥å¿—è®°å½•é—´éš”
                "log_confusion_matrix_on_eval": _should_log_confusion_matrix(),  # è®°å½•è¯„ä¼°æ—¶çš„æ··æ·†çŸ©é˜µ
                "log_image_predictions": _should_log_image_predictions(),  # è®°å½•å›¾åƒé¢„æµ‹
                "max_image_predictions": _get_max_image_predictions_to_log(),  # è®°å½•æœ€å¤§å›¾åƒé¢„æµ‹æ•°é‡
            }
        )
        experiment.log_other("Created from", "ultralytics")  # è®°å½•æ¥æº

    except Exception as e:  # æ•è·å¼‚å¸¸
        LOGGER.warning(f"WARNING âš ï¸ Comet installed but not initialized correctly, not logging this run. {e}")  # è®°å½•è­¦å‘Šä¿¡æ¯


def _fetch_trainer_metadata(trainer):
    """Returns metadata for YOLO training including epoch and asset saving status.  # è¿”å› YOLO è®­ç»ƒçš„å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬å‘¨æœŸå’Œèµ„äº§ä¿å­˜çŠ¶æ€ã€‚"""
    curr_epoch = trainer.epoch + 1  # å½“å‰å‘¨æœŸ

    train_num_steps_per_epoch = len(trainer.train_loader.dataset) // trainer.batch_size  # æ¯ä¸ªå‘¨æœŸçš„è®­ç»ƒæ­¥æ•°
    curr_step = curr_epoch * train_num_steps_per_epoch  # å½“å‰æ­¥æ•°
    final_epoch = curr_epoch == trainer.epochs  # æ˜¯å¦ä¸ºæœ€åä¸€ä¸ªå‘¨æœŸ

    save = trainer.args.save  # ä¿å­˜å‚æ•°
    save_period = trainer.args.save_period  # ä¿å­˜å‘¨æœŸ
    save_interval = curr_epoch % save_period == 0  # æ˜¯å¦åœ¨ä¿å­˜å‘¨æœŸå†…
    save_assets = save and save_period > 0 and save_interval and not final_epoch  # æ˜¯å¦ä¿å­˜èµ„äº§

    return dict(curr_epoch=curr_epoch, curr_step=curr_step, save_assets=save_assets, final_epoch=final_epoch)  # è¿”å›å…ƒæ•°æ®å­—å…¸


def _scale_bounding_box_to_original_image_shape(box, resized_image_shape, original_image_shape, ratio_pad):
    """
    YOLO resizes images during training and the label values are normalized based on this resized shape.  # YOLO åœ¨è®­ç»ƒæœŸé—´è°ƒæ•´å›¾åƒå¤§å°ï¼Œæ ‡ç­¾å€¼åŸºäºæ­¤è°ƒæ•´åçš„å½¢çŠ¶è¿›è¡Œå½’ä¸€åŒ–ã€‚

    This function rescales the bounding box labels to the original image shape.  # æ­¤å‡½æ•°å°†è¾¹ç•Œæ¡†æ ‡ç­¾é‡æ–°ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå½¢çŠ¶ã€‚
    """
    resized_image_height, resized_image_width = resized_image_shape  # è·å–è°ƒæ•´åå›¾åƒçš„é«˜åº¦å’Œå®½åº¦

    # Convert normalized xywh format predictions to xyxy in resized scale format  # å°†å½’ä¸€åŒ–çš„ xywh æ ¼å¼é¢„æµ‹è½¬æ¢ä¸ºè°ƒæ•´åæ¯”ä¾‹çš„ xyxy æ ¼å¼
    box = ops.xywhn2xyxy(box, h=resized_image_height, w=resized_image_width)  # è½¬æ¢è¾¹ç•Œæ¡†æ ¼å¼
    # Scale box predictions from resized image scale back to original image scale  # å°†è¾¹ç•Œæ¡†é¢„æµ‹ä»è°ƒæ•´åå›¾åƒæ¯”ä¾‹ç¼©æ”¾å›åŸå§‹å›¾åƒæ¯”ä¾‹
    box = ops.scale_boxes(resized_image_shape, box, original_image_shape, ratio_pad)  # ç¼©æ”¾è¾¹ç•Œæ¡†
    # Convert bounding box format from xyxy to xywh for Comet logging  # å°†è¾¹ç•Œæ¡†æ ¼å¼ä» xyxy è½¬æ¢ä¸º xywh ä»¥ä¾¿è®°å½•åˆ° Comet
    box = ops.xyxy2xywh(box)  # è½¬æ¢æ ¼å¼
    # Adjust xy center to correspond top-left corner  # è°ƒæ•´ xy ä¸­å¿ƒä»¥å¯¹åº”å·¦ä¸Šè§’
    box[:2] -= box[2:] / 2  # è°ƒæ•´ä¸­å¿ƒç‚¹
    box = box.tolist()  # è½¬æ¢ä¸ºåˆ—è¡¨

    return box  # è¿”å›è¾¹ç•Œæ¡†


def _format_ground_truth_annotations_for_detection(img_idx, image_path, batch, class_name_map=None):
    """Format ground truth annotations for detection.  # æ ¼å¼åŒ–ç”¨äºæ£€æµ‹çš„çœŸå®æ ‡ç­¾æ³¨é‡Šã€‚"""
    indices = batch["batch_idx"] == img_idx  # è·å–å½“å‰å›¾åƒçš„ç´¢å¼•
    bboxes = batch["bboxes"][indices]  # è·å–å½“å‰å›¾åƒçš„è¾¹ç•Œæ¡†
    if len(bboxes) == 0:  # å¦‚æœæ²¡æœ‰è¾¹ç•Œæ¡†
        LOGGER.debug(f"COMET WARNING: Image: {image_path} has no bounding boxes labels")  # è®°å½•è­¦å‘Šä¿¡æ¯
        return None  # è¿”å› None

    cls_labels = batch["cls"][indices].squeeze(1).tolist()  # è·å–ç±»åˆ«æ ‡ç­¾
    if class_name_map:  # å¦‚æœæœ‰ç±»åˆ«åç§°æ˜ å°„
        cls_labels = [str(class_name_map[label]) for label in cls_labels]  # å°†æ ‡ç­¾æ˜ å°„ä¸ºåç§°

    original_image_shape = batch["ori_shape"][img_idx]  # è·å–åŸå§‹å›¾åƒå½¢çŠ¶
    resized_image_shape = batch["resized_shape"][img_idx]  # è·å–è°ƒæ•´åå›¾åƒå½¢çŠ¶
    ratio_pad = batch["ratio_pad"][img_idx]  # è·å–å¡«å……æ¯”ä¾‹

    data = []  # åˆå§‹åŒ–æ•°æ®åˆ—è¡¨
    for box, label in zip(bboxes, cls_labels):  # éå†è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
        box = _scale_bounding_box_to_original_image_shape(box, resized_image_shape, original_image_shape, ratio_pad)  # ç¼©æ”¾è¾¹ç•Œæ¡†
        data.append(  # æ·»åŠ åˆ°æ•°æ®åˆ—è¡¨
            {
                "boxes": [box],  # è¾¹ç•Œæ¡†
                "label": f"gt_{label}",  # æ ‡ç­¾
                "score": _scale_confidence_score(1.0),  # ç½®ä¿¡åº¦åˆ†æ•°
            }
        )

    return {"name": "ground_truth", "data": data}  # è¿”å›æ ¼å¼åŒ–çš„çœŸå®æ ‡ç­¾


def _format_prediction_annotations_for_detection(image_path, metadata, class_label_map=None):
    """Format YOLO predictions for object detection visualization.  # æ ¼å¼åŒ– YOLO é¢„æµ‹ä»¥ä¾¿äºå¯¹è±¡æ£€æµ‹å¯è§†åŒ–ã€‚"""
    stem = image_path.stem  # è·å–å›¾åƒæ–‡ä»¶å
    image_id = int(stem) if stem.isnumeric() else stem  # å¦‚æœæ–‡ä»¶åæ˜¯æ•°å­—ï¼Œåˆ™è½¬æ¢ä¸ºæ•´æ•°

    predictions = metadata.get(image_id)  # è·å–å½“å‰å›¾åƒçš„é¢„æµ‹
    if not predictions:  # å¦‚æœæ²¡æœ‰é¢„æµ‹
        LOGGER.debug(f"COMET WARNING: Image: {image_path} has no bounding boxes predictions")  # è®°å½•è­¦å‘Šä¿¡æ¯
        return None  # è¿”å› None

    data = []  # åˆå§‹åŒ–æ•°æ®åˆ—è¡¨
    for prediction in predictions:  # éå†é¢„æµ‹
        boxes = prediction["bbox"]  # è·å–è¾¹ç•Œæ¡†
        score = _scale_confidence_score(prediction["score"])  # ç¼©æ”¾ç½®ä¿¡åº¦åˆ†æ•°
        cls_label = prediction["category_id"]  # è·å–ç±»åˆ«æ ‡ç­¾
        if class_label_map:  # å¦‚æœæœ‰ç±»åˆ«æ ‡ç­¾æ˜ å°„
            cls_label = str(class_label_map[cls_label])  # å°†æ ‡ç­¾æ˜ å°„ä¸ºåç§°

        data.append({"boxes": [boxes], "label": cls_label, "score": score})  # æ·»åŠ åˆ°æ•°æ®åˆ—è¡¨

    return {"name": "prediction", "data": data}  # è¿”å›æ ¼å¼åŒ–çš„é¢„æµ‹


def _fetch_annotations(img_idx, image_path, batch, prediction_metadata_map, class_label_map):
    """Join the ground truth and prediction annotations if they exist.  # å¦‚æœå­˜åœ¨ï¼Œåˆ™åˆå¹¶çœŸå®æ ‡ç­¾å’Œé¢„æµ‹æ³¨é‡Šã€‚"""
    ground_truth_annotations = _format_ground_truth_annotations_for_detection(  # æ ¼å¼åŒ–çœŸå®æ ‡ç­¾
        img_idx, image_path, batch, class_label_map
    )
    prediction_annotations = _format_prediction_annotations_for_detection(  # æ ¼å¼åŒ–é¢„æµ‹
        image_path, prediction_metadata_map, class_label_map
    )

    annotations = [  # åˆå¹¶æ³¨é‡Š
        annotation for annotation in [ground_truth_annotations, prediction_annotations] if annotation is not None
    ]
    return [annotations] if annotations else None  # è¿”å›æ³¨é‡Š


def _create_prediction_metadata_map(model_predictions):
    """Create metadata map for model predictions by groupings them based on image ID.  # æ ¹æ®å›¾åƒ ID åˆ›å»ºæ¨¡å‹é¢„æµ‹çš„å…ƒæ•°æ®æ˜ å°„ã€‚"""
    pred_metadata_map = {}  # åˆå§‹åŒ–é¢„æµ‹å…ƒæ•°æ®æ˜ å°„
    for prediction in model_predictions:  # éå†æ¨¡å‹é¢„æµ‹
        pred_metadata_map.setdefault(prediction["image_id"], [])  # åˆå§‹åŒ–å›¾åƒ ID çš„åˆ—è¡¨
        pred_metadata_map[prediction["image_id"]].append(prediction)  # æ·»åŠ é¢„æµ‹åˆ°åˆ—è¡¨

    return pred_metadata_map  # è¿”å›é¢„æµ‹å…ƒæ•°æ®æ˜ å°„


def _log_confusion_matrix(experiment, trainer, curr_step, curr_epoch):
    """Log the confusion matrix to Comet experiment.  # å°†æ··æ·†çŸ©é˜µè®°å½•åˆ° Comet å®éªŒä¸­ã€‚"""
    conf_mat = trainer.validator.confusion_matrix.matrix  # è·å–æ··æ·†çŸ©é˜µ
    names = list(trainer.data["names"].values()) + ["background"]  # è·å–ç±»åˆ«åç§°
    experiment.log_confusion_matrix(  # è®°å½•æ··æ·†çŸ©é˜µ
        matrix=conf_mat, labels=names, max_categories=len(names), epoch=curr_epoch, step=curr_step
    )


def _log_images(experiment, image_paths, curr_step, annotations=None):
    """Logs images to the experiment with optional annotations.  # å°†å›¾åƒè®°å½•åˆ°å®éªŒä¸­ï¼Œå¹¶å¯é€‰åœ°æ·»åŠ æ³¨é‡Šã€‚"""
    if annotations:  # å¦‚æœæœ‰æ³¨é‡Š
        for image_path, annotation in zip(image_paths, annotations):  # éå†å›¾åƒè·¯å¾„å’Œæ³¨é‡Š
            experiment.log_image(image_path, name=image_path.stem, step=curr_step, annotations=annotation)  # è®°å½•å›¾åƒ

    else:  # å¦‚æœæ²¡æœ‰æ³¨é‡Š
        for image_path in image_paths:  # éå†å›¾åƒè·¯å¾„
            experiment.log_image(image_path, name=image_path.stem, step=curr_step)  # è®°å½•å›¾åƒ


def _log_image_predictions(experiment, validator, curr_step):
    """Logs predicted boxes for a single image during training.  # åœ¨è®­ç»ƒæœŸé—´è®°å½•å•ä¸ªå›¾åƒçš„é¢„æµ‹è¾¹ç•Œæ¡†ã€‚"""
    global _comet_image_prediction_count  # å£°æ˜å…¨å±€å˜é‡

    task = validator.args.task  # è·å–ä»»åŠ¡
    if task not in COMET_SUPPORTED_TASKS:  # å¦‚æœä»»åŠ¡ä¸åœ¨æ”¯æŒçš„ä»»åŠ¡åˆ—è¡¨ä¸­
        return  # é€€å‡ºå‡½æ•°

    jdict = validator.jdict  # è·å–éªŒè¯å™¨çš„å­—å…¸
    if not jdict:  # å¦‚æœå­—å…¸ä¸ºç©º
        return  # é€€å‡ºå‡½æ•°

    predictions_metadata_map = _create_prediction_metadata_map(jdict)  # åˆ›å»ºé¢„æµ‹å…ƒæ•°æ®æ˜ å°„
    dataloader = validator.dataloader  # è·å–æ•°æ®åŠ è½½å™¨
    class_label_map = validator.names  # è·å–ç±»åˆ«æ ‡ç­¾æ˜ å°„

    batch_logging_interval = _get_eval_batch_logging_interval()  # è·å–æ‰¹æ¬¡æ—¥å¿—è®°å½•é—´éš”
    max_image_predictions = _get_max_image_predictions_to_log()  # è·å–æœ€å¤§å›¾åƒé¢„æµ‹æ•°é‡

    for batch_idx, batch in enumerate(dataloader):  # éå†æ•°æ®åŠ è½½å™¨
        if (batch_idx + 1) % batch_logging_interval != 0:  # å¦‚æœå½“å‰æ‰¹æ¬¡ä¸æ˜¯è®°å½•æ‰¹æ¬¡
            continue  # è·³è¿‡å½“å‰æ‰¹æ¬¡

        image_paths = batch["im_file"]  # è·å–å›¾åƒè·¯å¾„
        for img_idx, image_path in enumerate(image_paths):  # éå†å›¾åƒè·¯å¾„
            if _comet_image_prediction_count >= max_image_predictions:  # å¦‚æœè¾¾åˆ°æœ€å¤§é¢„æµ‹æ•°é‡
                return  # é€€å‡ºå‡½æ•°

            image_path = Path(image_path)  # è½¬æ¢ä¸º Path å¯¹è±¡
            annotations = _fetch_annotations(  # è·å–æ³¨é‡Š
                img_idx,
                image_path,
                batch,
                predictions_metadata_map,
                class_label_map,
            )
            _log_images(  # è®°å½•å›¾åƒ
                experiment,
                [image_path],
                curr_step,
                annotations=annotations,
            )
            _comet_image_prediction_count += 1  # å¢åŠ é¢„æµ‹è®¡æ•°


def _log_plots(experiment, trainer):
    """Logs evaluation plots and label plots for the experiment.  # è®°å½•è¯„ä¼°å›¾å’Œæ ‡ç­¾å›¾åˆ°å®éªŒä¸­ã€‚"""
    plot_filenames = None  # åˆå§‹åŒ–å›¾åƒæ–‡ä»¶å
    if isinstance(trainer.validator.metrics, SegmentMetrics) and trainer.validator.metrics.task == "segment":  # å¦‚æœæ˜¯åˆ†å‰²ä»»åŠ¡
        plot_filenames = [
            trainer.save_dir / f"{prefix}{plots}.png"  # è·å–å›¾åƒæ–‡ä»¶å
            for plots in EVALUATION_PLOT_NAMES  # éå†è¯„ä¼°å›¾åç§°
            for prefix in SEGMENT_METRICS_PLOT_PREFIX  # éå†åˆ†å‰²æŒ‡æ ‡å‰ç¼€
        ]
    elif isinstance(trainer.validator.metrics, PoseMetrics):  # å¦‚æœæ˜¯å§¿æ€ä»»åŠ¡
        plot_filenames = [
            trainer.save_dir / f"{prefix}{plots}.png"  # è·å–å›¾åƒæ–‡ä»¶å
            for plots in EVALUATION_PLOT_NAMES  # éå†è¯„ä¼°å›¾åç§°
            for prefix in POSE_METRICS_PLOT_PREFIX  # éå†å§¿æ€æŒ‡æ ‡å‰ç¼€
        ]
    elif isinstance(trainer.validator.metrics, (DetMetrics, OBBMetrics)):  # å¦‚æœæ˜¯æ£€æµ‹ä»»åŠ¡
        plot_filenames = [trainer.save_dir / f"{plots}.png" for plots in EVALUATION_PLOT_NAMES]  # è·å–å›¾åƒæ–‡ä»¶å

    if plot_filenames is not None:  # å¦‚æœæœ‰å›¾åƒæ–‡ä»¶å
        _log_images(experiment, plot_filenames, None)  # è®°å½•å›¾åƒ

    confusion_matrix_filenames = [trainer.save_dir / f"{plots}.png" for plots in CONFUSION_MATRIX_PLOT_NAMES]  # è·å–æ··æ·†çŸ©é˜µå›¾åƒæ–‡ä»¶å
    _log_images(experiment, confusion_matrix_filenames, None)  # è®°å½•æ··æ·†çŸ©é˜µå›¾åƒ

    if not isinstance(trainer.validator.metrics, ClassifyMetrics):  # å¦‚æœä¸æ˜¯åˆ†ç±»ä»»åŠ¡
        label_plot_filenames = [trainer.save_dir / f"{labels}.jpg" for labels in LABEL_PLOT_NAMES]  # è·å–æ ‡ç­¾å›¾åƒæ–‡ä»¶å
        _log_images(experiment, label_plot_filenames, None)  # è®°å½•æ ‡ç­¾å›¾åƒ


def _log_model(experiment, trainer):
    """Log the best-trained model to Comet.ml.  # å°†æœ€ä½³è®­ç»ƒæ¨¡å‹è®°å½•åˆ° Comet.mlã€‚"""
    model_name = _get_comet_model_name()  # è·å–æ¨¡å‹åç§°
    experiment.log_model(model_name, file_or_folder=str(trainer.best), file_name="best.pt", overwrite=True)  # è®°å½•æ¨¡å‹


def on_pretrain_routine_start(trainer):
    """Creates or resumes a CometML experiment at the start of a YOLO pre-training routine.  # åœ¨ YOLO é¢„è®­ç»ƒä¾‹ç¨‹å¼€å§‹æ—¶åˆ›å»ºæˆ–æ¢å¤ CometML å®éªŒã€‚"""
    experiment = comet_ml.get_global_experiment()  # è·å–å…¨å±€å®éªŒ
    is_alive = getattr(experiment, "alive", False)  # æ£€æŸ¥å®éªŒæ˜¯å¦å­˜æ´»
    if not experiment or not is_alive:  # å¦‚æœå®éªŒä¸å­˜åœ¨æˆ–æœªå­˜æ´»
        _create_experiment(trainer.args)  # åˆ›å»ºå®éªŒ


def on_train_epoch_end(trainer):
    """Log metrics and save batch images at the end of training epochs.  # åœ¨è®­ç»ƒå‘¨æœŸç»“æŸæ—¶è®°å½•æŒ‡æ ‡å’Œä¿å­˜æ‰¹æ¬¡å›¾åƒã€‚"""
    experiment = comet_ml.get_global_experiment()  # è·å–å…¨å±€å®éªŒ
    if not experiment:  # å¦‚æœå®éªŒä¸å­˜åœ¨
        return  # é€€å‡ºå‡½æ•°

    metadata = _fetch_trainer_metadata(trainer)  # è·å–è®­ç»ƒå…ƒæ•°æ®
    curr_epoch = metadata["curr_epoch"]  # å½“å‰å‘¨æœŸ
    curr_step = metadata["curr_step"]  # å½“å‰æ­¥æ•°

    experiment.log_metrics(trainer.label_loss_items(trainer.tloss, prefix="train"), step=curr_step, epoch=curr_epoch)  # è®°å½•è®­ç»ƒæŸå¤±


def on_fit_epoch_end(trainer):
    """Logs model assets at the end of each epoch.  # åœ¨æ¯ä¸ªå‘¨æœŸç»“æŸæ—¶è®°å½•æ¨¡å‹èµ„äº§ã€‚"""
    experiment = comet_ml.get_global_experiment()  # è·å–å…¨å±€å®éªŒ
    if not experiment:  # å¦‚æœå®éªŒä¸å­˜åœ¨
        return  # é€€å‡ºå‡½æ•°

    metadata = _fetch_trainer_metadata(trainer)  # è·å–è®­ç»ƒå…ƒæ•°æ®
    curr_epoch = metadata["curr_epoch"]  # å½“å‰å‘¨æœŸ
    curr_step = metadata["curr_step"]  # å½“å‰æ­¥æ•°
    save_assets = metadata["save_assets"]  # æ˜¯å¦ä¿å­˜èµ„äº§

    experiment.log_metrics(trainer.metrics, step=curr_step, epoch=curr_epoch)  # è®°å½•æŒ‡æ ‡
    experiment.log_metrics(trainer.lr, step=curr_step, epoch=curr_epoch)  # è®°å½•å­¦ä¹ ç‡
    if curr_epoch == 1:  # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªå‘¨æœŸ
        from ultralytics.utils.torch_utils import model_info_for_loggers  # ä» ultralytics.utils.torch_utils å¯¼å…¥ model_info_for_loggers

        experiment.log_metrics(model_info_for_loggers(trainer), step=curr_step, epoch=curr_epoch)  # è®°å½•æ¨¡å‹ä¿¡æ¯

    if not save_assets:  # å¦‚æœä¸ä¿å­˜èµ„äº§
        return  # é€€å‡ºå‡½æ•°

    _log_model(experiment, trainer)  # è®°å½•æ¨¡å‹
    if _should_log_confusion_matrix():  # å¦‚æœåº”è®°å½•æ··æ·†çŸ©é˜µ
        _log_confusion_matrix(experiment, trainer, curr_step, curr_epoch)  # è®°å½•æ··æ·†çŸ©é˜µ
    if _should_log_image_predictions():  # å¦‚æœåº”è®°å½•å›¾åƒé¢„æµ‹
        _log_image_predictions(experiment, trainer.validator, curr_step)  # è®°å½•å›¾åƒé¢„æµ‹


def on_train_end(trainer):
    """Perform operations at the end of training.  # åœ¨è®­ç»ƒç»“æŸæ—¶æ‰§è¡Œæ“ä½œã€‚"""
    experiment = comet_ml.get_global_experiment()  # è·å–å…¨å±€å®éªŒ
    if not experiment:  # å¦‚æœå®éªŒä¸å­˜åœ¨
        return  # é€€å‡ºå‡½æ•°

    metadata = _fetch_trainer_metadata(trainer)  # è·å–è®­ç»ƒå…ƒæ•°æ®
    curr_epoch = metadata["curr_epoch"]  # å½“å‰å‘¨æœŸ
    curr_step = metadata["curr_step"]  # å½“å‰æ­¥æ•°
    plots = trainer.args.plots  # è·å–ç»˜å›¾å‚æ•°

    _log_model(experiment, trainer)  # è®°å½•æ¨¡å‹
    if plots:  # å¦‚æœæœ‰ç»˜å›¾å‚æ•°
        _log_plots(experiment, trainer)  # è®°å½•ç»˜å›¾

    _log_confusion_matrix(experiment, trainer, curr_step, curr_epoch)  # è®°å½•æ··æ·†çŸ©é˜µ
    _log_image_predictions(experiment, trainer.validator, curr_step)  # è®°å½•å›¾åƒé¢„æµ‹
    _log_images(experiment, trainer.save_dir.glob("train_batch*.jpg"), curr_step)  # è®°å½•è®­ç»ƒæ‰¹æ¬¡å›¾åƒ
    _log_images(experiment, trainer.save_dir.glob("val_batch*.jpg"), curr_step)  # è®°å½•éªŒè¯æ‰¹æ¬¡å›¾åƒ
    experiment.end()  # ç»“æŸå®éªŒ

    global _comet_image_prediction_count  # å£°æ˜å…¨å±€å˜é‡
    _comet_image_prediction_count = 0  # é‡ç½®å›¾åƒé¢„æµ‹è®¡æ•°


callbacks = (  # å®šä¹‰å›è°ƒå‡½æ•°
    {
        "on_pretrain_routine_start": on_pretrain_routine_start,  # é¢„è®­ç»ƒä¾‹ç¨‹å¼€å§‹æ—¶çš„å›è°ƒ
        "on_train_epoch_end": on_train_epoch_end,  # è®­ç»ƒå‘¨æœŸç»“æŸæ—¶çš„å›è°ƒ
        "on_fit_epoch_end": on_fit_epoch_end,  # æ‹Ÿåˆå‘¨æœŸç»“æŸæ—¶çš„å›è°ƒ
        "on_train_end": on_train_end,  # è®­ç»ƒç»“æŸæ—¶çš„å›è°ƒ
    }
    if comet_ml  # å¦‚æœ comet_ml å¯ç”¨
    else {}  # å¦åˆ™ä¸ºç©ºå­—å…¸
)