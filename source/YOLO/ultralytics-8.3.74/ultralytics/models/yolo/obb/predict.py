# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import torch

from ultralytics.engine.results import Results
from ultralytics.models.yolo.detect.predict import DetectionPredictor
from ultralytics.utils import DEFAULT_CFG, ops


class OBBPredictor(DetectionPredictor):
    """
    A class extending the DetectionPredictor class for prediction based on an Oriented Bounding Box (OBB) model.
    ä¸€ä¸ªç»§æ‰¿è‡ªDetectionPredictorç±»çš„é¢„æµ‹å™¨ï¼Œä¸“é—¨ç”¨äºåŸºäºå¸¦æ–¹å‘è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰æ¨¡å‹çš„é¢„æµ‹ã€‚

    Example:
        ```python
        from ultralytics.utils import ASSETS
        from ultralytics.models.yolo.obb import OBBPredictor

        args = dict(model="yolo11n-obb.pt", source=ASSETS)
        predictor = OBBPredictor(overrides=args)
        predictor.predict_cli()
        ```
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """Initializes OBBPredictor with optional model and data configuration overrides."""
        # ä½¿ç”¨å¯é€‰çš„æ¨¡å‹å’Œæ•°æ®é…ç½®è¦†ç›–å‚æ•°åˆå§‹åŒ–OBBPredictor
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        super().__init__(cfg, overrides, _callbacks)
        
        # å¼ºåˆ¶è®¾ç½®ä»»åŠ¡ä¸º"obb"ï¼ˆå¸¦æ–¹å‘è¾¹ç•Œæ¡†ï¼‰
        self.args.task = "obb"

    def construct_result(self, pred, img, orig_img, img_path):
        """
        Constructs the result object from the prediction.
        ä»é¢„æµ‹ç»“æœæ„å»ºç»“æœå¯¹è±¡ã€‚

        Args:
            pred (torch.Tensor): The predicted bounding boxes, scores, and rotation angles.
                                 é¢„æµ‹çš„è¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦å’Œæ—‹è½¬è§’åº¦
            img (torch.Tensor): The image after preprocessing.
                                é¢„å¤„ç†åçš„å›¾åƒ
            orig_img (np.ndarray): The original image before preprocessing.
                                   é¢„å¤„ç†å‰çš„åŸå§‹å›¾åƒ
            img_path (str): The path to the original image.
                            åŸå§‹å›¾åƒçš„è·¯å¾„

        Returns:
            (Results): The result object containing the original image, image path, class names, and oriented bounding boxes.
                       åŒ…å«åŸå§‹å›¾åƒã€å›¾åƒè·¯å¾„ã€ç±»åˆ«åç§°å’Œå¸¦æ–¹å‘è¾¹ç•Œæ¡†çš„ç»“æœå¯¹è±¡
        """
        # è§„èŒƒåŒ–æ—‹è½¬è¾¹ç•Œæ¡†
        # 1. ä»é¢„æµ‹ç»“æœä¸­æå–è¾¹ç•Œæ¡†åæ ‡ï¼ˆå‰4åˆ—ï¼‰å’Œæ—‹è½¬è§’åº¦ï¼ˆæœ€åä¸€åˆ—ï¼‰
        # 2. ä½¿ç”¨regularize_rboxeså‡½æ•°æ ‡å‡†åŒ–è¾¹ç•Œæ¡†
        rboxes = ops.regularize_rboxes(torch.cat([pred[:, :4], pred[:, -1:]], dim=-1))
        
        # ç¼©æ”¾è¾¹ç•Œæ¡†åˆ°åŸå§‹å›¾åƒå°ºå¯¸
        # - img.shape[2:]: é¢„å¤„ç†åå›¾åƒçš„é«˜åº¦å’Œå®½åº¦
        # - rboxes[:, :4]: è§„èŒƒåŒ–åçš„è¾¹ç•Œæ¡†åæ ‡
        # - orig_img.shape: åŸå§‹å›¾åƒå°ºå¯¸
        # - xywh=True: ä½¿ç”¨XYWHï¼ˆä¸­å¿ƒxã€ä¸­å¿ƒyã€å®½åº¦ã€é«˜åº¦ï¼‰æ ¼å¼
        rboxes[:, :4] = ops.scale_boxes(img.shape[2:], rboxes[:, :4], orig_img.shape, xywh=True)
        
        # ç»„åˆæ—‹è½¬è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦ã€ç±»åˆ«ä¿¡æ¯
        # - rboxes: ç¼©æ”¾åçš„è¾¹ç•Œæ¡†
        # - pred[:, 4:6]: ç½®ä¿¡åº¦å’Œç±»åˆ«ä¿¡æ¯
        # ä½¿ç”¨torch.catåœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šæ‹¼æ¥å¼ é‡
        obb = torch.cat([rboxes, pred[:, 4:6]], dim=-1)
        
        # åˆ›å»ºå¹¶è¿”å›Resultså¯¹è±¡
        # - orig_img: åŸå§‹å›¾åƒ
        # - path: å›¾åƒè·¯å¾„
        # - names: ç±»åˆ«åç§°
        # - obb: å¸¦æ–¹å‘çš„è¾¹ç•Œæ¡†ç»“æœ
        return Results(orig_img, path=img_path, names=self.model.names, obb=obb)
