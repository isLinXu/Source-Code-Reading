# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from ultralytics.engine.results import Results
from ultralytics.models.yolo.detect.predict import DetectionPredictor
from ultralytics.utils import DEFAULT_CFG, ops


class SegmentationPredictor(DetectionPredictor):
    """
    A class extending the DetectionPredictor class for prediction based on a segmentation model.
    ä¸€ä¸ªæ‰©å±•äº† DetectionPredictor ç±»çš„ç±»ï¼Œç”¨äºåŸºäºåˆ†å‰²æ¨¡å‹çš„é¢„æµ‹ã€‚

    Example:
        ```python
        from ultralytics.utils import ASSETS
        from ultralytics.models.yolo.segment import SegmentationPredictor

        args = dict(model="yolo11n-seg.pt", source=ASSETS)
        predictor = SegmentationPredictor(overrides=args)
        predictor.predict_cli()
        ```
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """Initializes the SegmentationPredictor with the provided configuration, overrides, and callbacks.
        ä½¿ç”¨æä¾›çš„é…ç½®ã€è¦†ç›–å’Œå›è°ƒåˆå§‹åŒ– SegmentationPredictorã€‚"""
        super().__init__(cfg, overrides, _callbacks)  # è°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–æ–¹æ³•
        self.args.task = "segment"  # è®¾ç½®ä»»åŠ¡ç±»å‹ä¸ºåˆ†å‰²

    def postprocess(self, preds, img, orig_imgs):
        """Applies non-max suppression and processes detections for each image in an input batch.
        å¯¹è¾“å…¥æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªå›¾åƒåº”ç”¨éæå¤§å€¼æŠ‘åˆ¶å¹¶å¤„ç†æ£€æµ‹ç»“æœã€‚"""
        # tuple if PyTorch model or array if exported
        protos = preds[1][-1] if isinstance(preds[1], tuple) else preds[1]  # æ ¹æ® preds çš„ç±»å‹è·å–åŸå‹
        return super().postprocess(preds[0], img, orig_imgs, protos=protos)  # è°ƒç”¨çˆ¶ç±»çš„åå¤„ç†æ–¹æ³•

    def construct_results(self, preds, img, orig_imgs, protos):
        """
        Constructs a list of result objects from the predictions.
        ä»é¢„æµ‹ç»“æœæ„å»ºç»“æœå¯¹è±¡çš„åˆ—è¡¨ã€‚

        Args:
            preds (List[torch.Tensor]): List of predicted bounding boxes, scores, and masks.
            predsï¼ˆList[torch.Tensor]ï¼‰ï¼šé¢„æµ‹çš„è¾¹ç•Œæ¡†ã€åˆ†æ•°å’Œæ©ç çš„åˆ—è¡¨ã€‚
            img (torch.Tensor): The image after preprocessing.
            imgï¼ˆtorch.Tensorï¼‰ï¼šç»è¿‡é¢„å¤„ç†çš„å›¾åƒã€‚
            orig_imgs (List[np.ndarray]): List of original images before preprocessing.
            orig_imgsï¼ˆList[np.ndarray]ï¼‰ï¼šé¢„å¤„ç†å‰çš„åŸå§‹å›¾åƒåˆ—è¡¨ã€‚
            protos (List[torch.Tensor]): List of prototype masks.
            protosï¼ˆList[torch.Tensor]ï¼‰ï¼šåŸå‹æ©ç çš„åˆ—è¡¨ã€‚

        Returns:
            (list): List of result objects containing the original images, image paths, class names, bounding boxes, and masks.
            (list)ï¼šåŒ…å«åŸå§‹å›¾åƒã€å›¾åƒè·¯å¾„ã€ç±»åã€è¾¹ç•Œæ¡†å’Œæ©ç çš„ç»“æœå¯¹è±¡åˆ—è¡¨ã€‚
        """
        return [
            self.construct_result(pred, img, orig_img, img_path, proto)  # æ„å»ºæ¯ä¸ªç»“æœå¯¹è±¡
            for pred, orig_img, img_path, proto in zip(preds, orig_imgs, self.batch[0], protos)  # éå†æ‰€æœ‰é¢„æµ‹ç»“æœ
        ]

    def construct_result(self, pred, img, orig_img, img_path, proto):
        """
        Constructs the result object from the prediction.
        ä»é¢„æµ‹æ„å»ºç»“æœå¯¹è±¡ã€‚

        Args:
            pred (np.ndarray): The predicted bounding boxes, scores, and masks.
            predï¼ˆnp.ndarrayï¼‰ï¼šé¢„æµ‹çš„è¾¹ç•Œæ¡†ã€åˆ†æ•°å’Œæ©ç ã€‚
            img (torch.Tensor): The image after preprocessing.
            imgï¼ˆtorch.Tensorï¼‰ï¼šç»è¿‡é¢„å¤„ç†çš„å›¾åƒã€‚
            orig_img (np.ndarray): The original image before preprocessing.
            orig_imgï¼ˆnp.ndarrayï¼‰ï¼šé¢„å¤„ç†å‰çš„åŸå§‹å›¾åƒã€‚
            img_path (str): The path to the original image.
            img_pathï¼ˆstrï¼‰ï¼šåŸå§‹å›¾åƒçš„è·¯å¾„ã€‚
            proto (torch.Tensor): The prototype masks.
            protoï¼ˆtorch.Tensorï¼‰ï¼šåŸå‹æ©ç ã€‚

        Returns:
            (Results): The result object containing the original image, image path, class names, bounding boxes, and masks.
            (Results)ï¼šåŒ…å«åŸå§‹å›¾åƒã€å›¾åƒè·¯å¾„ã€ç±»åã€è¾¹ç•Œæ¡†å’Œæ©ç çš„ç»“æœå¯¹è±¡ã€‚
        """
        if not len(pred):  # save empty boxes
            masks = None  # å¦‚æœæ²¡æœ‰é¢„æµ‹ç»“æœï¼Œæ©ç è®¾ç½®ä¸º None
        elif self.args.retina_masks:
            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)  # ç¼©æ”¾è¾¹ç•Œæ¡†
            masks = ops.process_mask_native(proto, pred[:, 6:], pred[:, :4], orig_img.shape[:2])  # HWC
        else:
            masks = ops.process_mask(proto, pred[:, 6:], pred[:, :4], img.shape[2:], upsample=True)  # HWC
            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape)  # ç¼©æ”¾è¾¹ç•Œæ¡†
        return Results(orig_img, path=img_path, names=self.model.names, boxes=pred[:, :6], masks=masks)  # è¿”å›ç»“æœå¯¹è±¡