# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from copy import copy

import torch

from ultralytics.data import ClassificationDataset, build_dataloader
from ultralytics.engine.trainer import BaseTrainer
from ultralytics.models import yolo
from ultralytics.nn.tasks import ClassificationModel
from ultralytics.utils import DEFAULT_CFG, LOGGER, RANK
from ultralytics.utils.plotting import plot_images, plot_results
from ultralytics.utils.torch_utils import is_parallel, strip_optimizer, torch_distributed_zero_first


class ClassificationTrainer(BaseTrainer):
    """
    A class extending the BaseTrainer class for training based on a classification model.

    Notes:
        - Torchvision classification models can also be passed to the 'model' argument, i.e. model='resnet18'.

    Example:
        ```python
        from ultralytics.models.yolo.classify import ClassificationTrainer

        args = dict(model="yolo11n-cls.pt", data="imagenet10", epochs=3)
        trainer = ClassificationTrainer(overrides=args)
        trainer.train()
        ```
    """
    # ç»§æ‰¿è‡ªBaseTrainerçš„åˆ†ç±»æ¨¡å‹è®­ç»ƒå™¨ç±»
    # æ”¯æŒYOLOå’ŒTorchvisionçš„åˆ†ç±»æ¨¡å‹è®­ç»ƒ

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """Initialize a ClassificationTrainer object with optional configuration overrides and callbacks."""
        # åˆå§‹åŒ–åˆ†ç±»è®­ç»ƒå™¨ï¼Œè®¾ç½®é»˜è®¤é…ç½®å’Œå›è°ƒå‡½æ•°
        
        # å¦‚æœæœªæä¾›è¦†ç›–é…ç½®ï¼Œåˆ›å»ºç©ºå­—å…¸
        if overrides is None:
            overrides = {}
        
        # å¼ºåˆ¶è®¾ç½®ä»»åŠ¡ç±»å‹ä¸ºåˆ†ç±»
        overrides["task"] = "classify"
        
        # å¦‚æœæœªæŒ‡å®šå›¾åƒå¤§å°ï¼Œé»˜è®¤è®¾ç½®ä¸º224x224
        if overrides.get("imgsz") is None:
            overrides["imgsz"] = 224
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•ï¼Œä¼ å…¥é…ç½®ã€è¦†ç›–å‚æ•°å’Œå›è°ƒå‡½æ•°
        super().__init__(cfg, overrides, _callbacks)

    def set_model_attributes(self):
        """Set the YOLO model's class names from the loaded dataset."""
        # ä»åŠ è½½çš„æ•°æ®é›†ä¸­è®¾ç½®æ¨¡å‹çš„ç±»åˆ«åç§°
        self.model.names = self.data["names"]

    def get_model(self, cfg=None, weights=None, verbose=True):
        """Returns a modified PyTorch model configured for training YOLO."""
        # åˆ›å»ºå¹¶é…ç½®ç”¨äºè®­ç»ƒçš„åˆ†ç±»æ¨¡å‹
        
        # ä½¿ç”¨ClassificationModelåˆ›å»ºæ¨¡å‹ï¼Œä¼ å…¥é…ç½®å’Œç±»åˆ«æ•°é‡
        # verboseå‚æ•°æ§åˆ¶æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼ˆä»…åœ¨ä¸»è¿›ç¨‹æ—¶ï¼‰
        model = ClassificationModel(cfg, nc=self.data["nc"], verbose=verbose and RANK == -1)
        
        # å¦‚æœæä¾›äº†æƒé‡ï¼ŒåŠ è½½é¢„è®­ç»ƒæƒé‡
        if weights:
            model.load(weights)

        # éå†æ¨¡å‹çš„æ‰€æœ‰æ¨¡å—è¿›è¡Œé…ç½®
        for m in model.modules():
            # å¦‚æœä¸æ˜¯é¢„è®­ç»ƒæ¨¡å‹ï¼Œé‡ç½®æ¨¡å—å‚æ•°
            if not self.args.pretrained and hasattr(m, "reset_parameters"):
                m.reset_parameters()
            
            # å¦‚æœæ¨¡å—æ˜¯Dropoutä¸”é…ç½®äº†dropoutç‡ï¼Œè®¾ç½®dropoutæ¦‚ç‡
            if isinstance(m, torch.nn.Dropout) and self.args.dropout:
                m.p = self.args.dropout  # set dropout
        
        # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½å¯ä»¥è¿›è¡Œæ¢¯åº¦æ›´æ–°ï¼ˆè®­ç»ƒæ¨¡å¼ï¼‰
        for p in model.parameters():
            p.requires_grad = True  # for training
        
        # è¿”å›é…ç½®å¥½çš„æ¨¡å‹
        return model


    def setup_model(self):
        """Load, create or download model for any task."""
        # åŠ è½½ã€åˆ›å»ºæˆ–ä¸‹è½½æ¨¡å‹çš„æ–¹æ³•
        import torchvision  # scope for faster 'import ultralytics'
        # å¯¼å…¥torchvisionï¼Œä¼˜åŒ–å¯¼å…¥ultralyticsçš„æ€§èƒ½

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ˜¯torchvisionå†…ç½®æ¨¡å‹
        if str(self.model) in torchvision.models.__dict__:
            # å¦‚æœæ˜¯torchvisionæ¨¡å‹ï¼Œæ ¹æ®æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡åŠ è½½
            self.model = torchvision.models.__dict__[self.model](
                weights="IMAGENET1K_V1" if self.args.pretrained else None
            )
            ckpt = None  # ä¸éœ€è¦æ£€æŸ¥ç‚¹
        else:
            # å¦‚æœä¸æ˜¯torchvisionæ¨¡å‹ï¼Œè°ƒç”¨çˆ¶ç±»çš„æ¨¡å‹è®¾ç½®æ–¹æ³•
            ckpt = super().setup_model()
        
        # æ ¹æ®æ•°æ®é›†çš„ç±»åˆ«æ•°é‡æ–°è°ƒæ•´æ¨¡å‹è¾“å‡ºå±‚
        ClassificationModel.reshape_outputs(self.model, self.data["nc"])
        return ckpt

    def build_dataset(self, img_path, mode="train", batch=None):
        """Creates a ClassificationDataset instance given an image path, and mode (train/test etc.)."""
        # æ ¹æ®å›¾åƒè·¯å¾„å’Œæ¨¡å¼åˆ›å»ºåˆ†ç±»æ•°æ®é›†å®ä¾‹
        # modeå†³å®šæ˜¯å¦å¯ç”¨æ•°æ®å¢å¼ºï¼ˆè®­ç»ƒæ¨¡å¼ä¸‹å¯ç”¨ï¼‰
        return ClassificationDataset(root=img_path, args=self.args, augment=mode == "train", prefix=mode)

    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):
        """Returns PyTorch DataLoader with transforms to preprocess images for inference."""
        # åˆ›å»ºå¹¶è¿”å›å¸¦æœ‰å›¾åƒé¢„å¤„ç†å˜æ¢çš„PyTorchæ•°æ®åŠ è½½å™¨
        
        # ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒçš„é›¶å·è¿›ç¨‹é¦–å…ˆåˆå§‹åŒ–æ•°æ®é›†ç¼“å­˜
        with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP
            dataset = self.build_dataset(dataset_path, mode)

        # æ„å»ºæ•°æ®åŠ è½½å™¨ï¼Œæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ
        loader = build_dataloader(dataset, batch_size, self.args.workers, rank=rank)
        
        # ä¸ºæ¨ç†æ¨¡å¼é™„åŠ å›¾åƒå˜æ¢
        if mode != "train":
            # å¤„ç†å¹¶è¡Œæ¨¡å‹å’Œå•ä¸€æ¨¡å‹çš„æƒ…å†µ
            if is_parallel(self.model):
                self.model.module.transforms = loader.dataset.torch_transforms
            else:
                self.model.transforms = loader.dataset.torch_transforms
        
        return loader

    def preprocess_batch(self, batch):
        """Preprocesses a batch of images and classes."""
        # é¢„å¤„ç†ä¸€æ‰¹å›¾åƒå’Œç±»åˆ«æ ‡ç­¾
        # å°†å›¾åƒå’Œç±»åˆ«æ ‡ç­¾ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPUï¼‰
        batch["img"] = batch["img"].to(self.device)
        batch["cls"] = batch["cls"].to(self.device)
        return batch

    def progress_string(self):
        """Returns a formatted string showing training progress."""
        # è¿”å›æ ¼å¼åŒ–çš„è®­ç»ƒè¿›åº¦å­—ç¬¦ä¸²
        # åŒ…æ‹¬è½®æ¬¡ã€GPUå†…å­˜ã€æŸå¤±åç§°ã€å®ä¾‹æ•°å’Œå›¾åƒå¤§å°
        return ("\n" + "%11s" * (4 + len(self.loss_names))) % (
            "Epoch",       # è®­ç»ƒè½®æ¬¡
            "GPU_mem",     # GPUå†…å­˜ä½¿ç”¨
            *self.loss_names,  # æŸå¤±å‡½æ•°åç§°
            "Instances",   # è®­ç»ƒå®ä¾‹æ•°
            "Size",        # å›¾åƒå¤§å°
        )
        
    def get_validator(self):
        """Returns an instance of ClassificationValidator for validation."""
        # è¿”å›åˆ†ç±»éªŒè¯å™¨å®ä¾‹
        # è®¾ç½®æŸå¤±åç§°ä¸º"loss"
        self.loss_names = ["loss"]
        
        # åˆ›å»ºå¹¶è¿”å›ClassificationValidatorå®ä¾‹
        # ä½¿ç”¨æµ‹è¯•åŠ è½½å™¨ã€ä¿å­˜ç›®å½•ã€å‚æ•°å‰¯æœ¬å’Œå›è°ƒå‡½æ•°
        return yolo.classify.ClassificationValidator(
            self.test_loader, self.save_dir, args=copy(self.args), _callbacks=self.callbacks
        )
    
    def label_loss_items(self, loss_items=None, prefix="train"):
        """
        Returns a loss dict with labelled training loss items tensor.
    
        Not needed for classification but necessary for segmentation & detection
        """
        # è¿”å›å¸¦æ ‡ç­¾çš„è®­ç»ƒæŸå¤±é¡¹å­—å…¸
        # å¯¹äºåˆ†ç±»ä»»åŠ¡ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å¯¹äºåˆ†å‰²å’Œæ£€æµ‹ä»»åŠ¡å¾ˆé‡è¦
        
        # ä¸ºæŸå¤±åç§°æ·»åŠ å‰ç¼€ï¼ˆé»˜è®¤ä¸º"train"ï¼‰
        keys = [f"{prefix}/{x}" for x in self.loss_names]
        
        # å¦‚æœæ²¡æœ‰æä¾›æŸå¤±é¡¹ï¼Œè¿”å›é”®åˆ—è¡¨
        if loss_items is None:
            return keys
        
        # å°†æŸå¤±é¡¹è½¬æ¢ä¸ºå››èˆäº”å…¥çš„æµ®ç‚¹æ•°
        loss_items = [round(float(loss_items), 5)]
        
        # ä½¿ç”¨é”®å’ŒæŸå¤±é¡¹åˆ›å»ºå­—å…¸
        return dict(zip(keys, loss_items))
    
    def plot_metrics(self):
        """Plots metrics from a CSV file."""
        # ä»CSVæ–‡ä»¶ç»˜åˆ¶æŒ‡æ ‡
        # ä½¿ç”¨plot_resultså‡½æ•°ï¼Œç‰¹åˆ«é’ˆå¯¹åˆ†ç±»ä»»åŠ¡
        plot_results(file=self.csv, classify=True, on_plot=self.on_plot)  # save results.png
    
    def final_eval(self):
        """Evaluate trained model and save validation results."""
        # è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶ä¿å­˜éªŒè¯ç»“æœ
        
        # éå†æœ€åä¸€ä¸ªå’Œæœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹
        for f in self.last, self.best:
            # å¦‚æœæ£€æŸ¥ç‚¹æ–‡ä»¶å­˜åœ¨
            if f.exists():
                # å‰¥ç¦»ä¼˜åŒ–å™¨çŠ¶æ€
                strip_optimizer(f)  # strip optimizers
                
                # å¯¹æœ€ä½³æ¨¡å‹è¿›è¡Œé¢å¤–å¤„ç†
                if f is self.best:
                    # è®°å½•æ—¥å¿—
                    LOGGER.info(f"\nValidating {f}...")
                    
                    # è®¾ç½®éªŒè¯å™¨å‚æ•°
                    self.validator.args.data = self.args.data
                    self.validator.args.plots = self.args.plots
                    
                    # ä½¿ç”¨æ¨¡å‹æ–‡ä»¶è¿›è¡ŒéªŒè¯
                    self.metrics = self.validator(model=f)
                    
                    # ç§»é™¤é€‚åº”åº¦æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    self.metrics.pop("fitness", None)
                    
                    # è¿è¡Œå›è°ƒå‡½æ•°
                    self.run_callbacks("on_fit_epoch_end")
    
    def plot_training_samples(self, batch, ni):
        """Plots training samples with their annotations."""
        # ç»˜åˆ¶å¸¦æ³¨é‡Šçš„è®­ç»ƒæ ·æœ¬
        plot_images(
            images=batch["img"],  # è¾“å…¥å›¾åƒæ‰¹æ¬¡
            batch_idx=torch.arange(len(batch["img"])),  # æ‰¹æ¬¡ç´¢å¼•
            cls=batch["cls"].view(-1),  # ç±»åˆ«æ ‡ç­¾
            # è­¦å‘Šï¼šå¯¹äºåˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨.view()è€Œä¸æ˜¯.squeeze()
            fname=self.save_dir / f"train_batch{ni}.jpg",  # ä¿å­˜æ–‡ä»¶å
            on_plot=self.on_plot,  # ç»˜å›¾å›è°ƒå‡½æ•°
        )
