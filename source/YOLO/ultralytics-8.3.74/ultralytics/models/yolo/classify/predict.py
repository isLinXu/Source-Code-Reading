# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import cv2
import torch
from PIL import Image

from ultralytics.engine.predictor import BasePredictor
from ultralytics.engine.results import Results
from ultralytics.utils import DEFAULT_CFG, ops


class ClassificationPredictor(BasePredictor):
    """
    A class extending the BasePredictor class for prediction based on a classification model.

    Notes:
        - Torchvision classification models can also be passed to the 'model' argument, i.e. model='resnet18'.

    Example:
        ```python
        from ultralytics.utils import ASSETS
        from ultralytics.models.yolo.classify import ClassificationPredictor

        args = dict(model="yolo11n-cls.pt", source=ASSETS)
        predictor = ClassificationPredictor(overrides=args)
        predictor.predict_cli()
        ```
    """
    # ç»§æ‰¿è‡ªBasePredictorçš„åˆ†ç±»æ¨¡å‹é¢„æµ‹å™¨ç±»
    # æ”¯æŒYOLOå’ŒTorchvisionçš„åˆ†ç±»æ¨¡å‹é¢„æµ‹

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """Initializes ClassificationPredictor setting the task to 'classify'."""
        # åˆå§‹åŒ–åˆ†ç±»é¢„æµ‹å™¨
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–æ–¹æ³•
        super().__init__(cfg, overrides, _callbacks)
        
        # å¼ºåˆ¶è®¾ç½®ä»»åŠ¡ç±»å‹ä¸ºåˆ†ç±»
        self.args.task = "classify"
        
        # è®¾ç½®é—ç•™è½¬æ¢åç§°ï¼ˆç”¨äºå…¼å®¹æ—§ç‰ˆæœ¬çš„å›¾åƒè½¬æ¢ï¼‰
        self._legacy_transform_name = "ultralytics.yolo.data.augment.ToTensor"

    def preprocess(self, img):
        """Converts input image to model-compatible data type."""
        # å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºæ¨¡å‹å…¼å®¹çš„æ•°æ®ç±»å‹
        
        # å¦‚æœè¾“å…¥ä¸æ˜¯å¼ é‡ï¼Œéœ€è¦è¿›è¡Œé¢„å¤„ç†
        if not isinstance(img, torch.Tensor):
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨é—ç•™çš„å›¾åƒè½¬æ¢æ–¹æ³•
            is_legacy_transform = any(
                self._legacy_transform_name in str(transform) for transform in self.transforms.transforms
            )
            
            if is_legacy_transform:  # å¤„ç†é—ç•™è½¬æ¢
                # ç›´æ¥åº”ç”¨transformsåˆ°è¾“å…¥å›¾åƒ
                img = torch.stack([self.transforms(im) for im in img], dim=0)
            else:
                # å°†å›¾åƒä»BGRè½¬æ¢åˆ°RGBï¼Œç„¶ååº”ç”¨transforms
                img = torch.stack(
                    [self.transforms(Image.fromarray(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))) for im in img], dim=0
                )
        
        # ç¡®ä¿å›¾åƒæ˜¯å¼ é‡å¹¶ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
        img = (img if isinstance(img, torch.Tensor) else torch.from_numpy(img)).to(self.model.device)
        
        # æ ¹æ®æ¨¡å‹æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°è¿›è¡Œç±»å‹è½¬æ¢
        return img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32

    def postprocess(self, preds, img, orig_imgs):
        """Post-processes predictions to return Results objects."""
        # åå¤„ç†é¢„æµ‹ç»“æœï¼Œè¿”å›Resultså¯¹è±¡
        
        # å¦‚æœåŸå§‹å›¾åƒä¸æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºNumPyæ‰¹æ¬¡
        if not isinstance(orig_imgs, list):  # input images are a torch.Tensor, not a list
            orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)

        # å¤„ç†é¢„æµ‹ç»“æœï¼ˆç¡®ä¿æ˜¯å•ä¸ªå¼ é‡ï¼‰
        preds = preds[0] if isinstance(preds, (list, tuple)) else preds
        
        # ä¸ºæ¯ä¸ªå›¾åƒåˆ›å»ºResultså¯¹è±¡
        return [
            Results(
                orig_img,               # åŸå§‹å›¾åƒ
                path=img_path,          # å›¾åƒè·¯å¾„
                names=self.model.names,  # ç±»åˆ«åç§°
                probs=pred              # é¢„æµ‹æ¦‚ç‡
            )
            for pred, orig_img, img_path in zip(preds, orig_imgs, self.batch[0])
        ]
