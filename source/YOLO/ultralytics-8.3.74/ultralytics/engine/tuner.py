# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
Module provides functionalities for hyperparameter tuning of the Ultralytics YOLO models for object detection, instance
segmentation, image classification, pose estimation, and multi-object tracking.

Hyperparameter tuning is the process of systematically searching for the optimal set of hyperparameters
that yield the best model performance. This is particularly crucial in deep learning models like YOLO,
where small changes in hyperparameters can lead to significant differences in model accuracy and efficiency.

Example:
    Tune hyperparameters for YOLO11n on COCO8 at imgsz=640 and epochs=30 for 300 tuning iterations.
    ```python
    from ultralytics import YOLO

    model = YOLO("yolo11n.pt")
    model.tune(data="coco8.yaml", epochs=10, iterations=300, optimizer="AdamW", plots=False, save=False, val=False)
    ```
"""

import random  # å¯¼å…¥éšæœºæ•°ç”Ÿæˆæ¨¡å—
import shutil  # å¯¼å…¥æ–‡ä»¶æ“ä½œæ¨¡å—
import subprocess  # å¯¼å…¥å­è¿›ç¨‹æ¨¡å—
import time  # å¯¼å…¥æ—¶é—´æ¨¡å—

import numpy as np  # å¯¼å…¥NumPyåº“
import torch  # å¯¼å…¥PyTorchåº“

from ultralytics.cfg import get_cfg, get_save_dir  # å¯¼å…¥é…ç½®ç›¸å…³å‡½æ•°
from ultralytics.utils import DEFAULT_CFG, LOGGER, callbacks, colorstr, remove_colorstr, yaml_print, yaml_save  # å¯¼å…¥å·¥å…·å‡½æ•°
from ultralytics.utils.plotting import plot_tune_results  # å¯¼å…¥ç»˜å›¾å‡½æ•°

class Tuner:
    """
    Class responsible for hyperparameter tuning of YOLO models.

    The class evolves YOLO model hyperparameters over a given number of iterations
    by mutating them according to the search space and retraining the model to evaluate their performance.

    Attributes:
        space (dict): Hyperparameter search space containing bounds and scaling factors for mutation.
        tune_dir (Path): Directory where evolution logs and results will be saved.
        tune_csv (Path): Path to the CSV file where evolution logs are saved.

    Methods:
        _mutate(hyp: dict) -> dict:
            Mutates the given hyperparameters within the bounds specified in `self.space`.

        __call__():
            Executes the hyperparameter evolution across multiple iterations.

    Example:
        Tune hyperparameters for YOLO11n on COCO8 at imgsz=640 and epochs=30 for 300 tuning iterations.
        ```python
        from ultralytics import YOLO

        model = YOLO("yolo11n.pt")
        model.tune(data="coco8.yaml", epochs=10, iterations=300, optimizer="AdamW", plots=False, save=False, val=False)
        ```

        Tune with custom search space.
        ```python
        from ultralytics import YOLO

        model = YOLO("yolo11n.pt")
        model.tune(space={key1: val1, key2: val2})  # custom search space dictionary
        ```
    """

    def __init__(self, args=DEFAULT_CFG, _callbacks=None):
        """
        Initialize the Tuner with configurations.

        Args:
            args (dict, optional): Configuration for hyperparameter evolution.
        """
        # ä½¿ç”¨é…ç½®åˆå§‹åŒ–è°ƒä¼˜å™¨ã€‚
        self.space = args.pop("space", None) or {  # key: (min, max, gain(optional))
            # 'optimizer': tune.choice(['SGD', 'Adam', 'AdamW', 'NAdam', 'RAdam', 'RMSProp']),
            "lr0": (1e-5, 1e-1),  # åˆå§‹å­¦ä¹ ç‡ï¼ˆä¾‹å¦‚SGD=1E-2ï¼ŒAdam=1E-3ï¼‰
            "lrf": (0.0001, 0.1),  # æœ€ç»ˆOneCycleLRå­¦ä¹ ç‡ï¼ˆlr0 * lrfï¼‰
            "momentum": (0.7, 0.98, 0.3),  # SGDåŠ¨é‡/Adam beta1
            "weight_decay": (0.0, 0.001),  # ä¼˜åŒ–å™¨æƒé‡è¡°å‡5e-4
            "warmup_epochs": (0.0, 5.0),  # é¢„çƒ­epochï¼ˆå…è®¸å°æ•°ï¼‰
            "warmup_momentum": (0.0, 0.95),  # é¢„çƒ­åˆå§‹åŠ¨é‡
            "box": (1.0, 20.0),  # boxæŸå¤±å¢ç›Š
            "cls": (0.2, 4.0),  # clsæŸå¤±å¢ç›Šï¼ˆä¸åƒç´ ç¼©æ”¾ï¼‰
            "dfl": (0.4, 6.0),  # dflæŸå¤±å¢ç›Š
            "hsv_h": (0.0, 0.1),  # å›¾åƒHSV-Hueå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
            "hsv_s": (0.0, 0.9),  # å›¾åƒHSV-Saturationå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
            "hsv_v": (0.0, 0.9),  # å›¾åƒHSV-Valueå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
            "degrees": (0.0, 45.0),  # å›¾åƒæ—‹è½¬ï¼ˆ+/-åº¦ï¼‰
            "translate": (0.0, 0.9),  # å›¾åƒå¹³ç§»ï¼ˆ+/-æ¯”ä¾‹ï¼‰
            "scale": (0.0, 0.95),  # å›¾åƒç¼©æ”¾ï¼ˆ+/-å¢ç›Šï¼‰
            "shear": (0.0, 10.0),  # å›¾åƒå‰ªåˆ‡ï¼ˆ+/-åº¦ï¼‰
            "perspective": (0.0, 0.001),  # å›¾åƒé€è§†ï¼ˆ+/-æ¯”ä¾‹ï¼‰ï¼ŒèŒƒå›´0-0.001
            "flipud": (0.0, 1.0),  # å›¾åƒä¸Šä¸‹ç¿»è½¬ï¼ˆæ¦‚ç‡ï¼‰
            "fliplr": (0.0, 1.0),  # å›¾åƒå·¦å³ç¿»è½¬ï¼ˆæ¦‚ç‡ï¼‰
            "bgr": (0.0, 1.0),  # å›¾åƒé€šé“bgrï¼ˆæ¦‚ç‡ï¼‰
            "mosaic": (0.0, 1.0),  # å›¾åƒæ··åˆï¼ˆæ¦‚ç‡ï¼‰
            "mixup": (0.0, 1.0),  # å›¾åƒæ··åˆï¼ˆæ¦‚ç‡ï¼‰
            "copy_paste": (0.0, 1.0),  # ç‰‡æ®µå¤åˆ¶ç²˜è´´ï¼ˆæ¦‚ç‡ï¼‰
        }
        self.args = get_cfg(overrides=args)  # è·å–é…ç½®
        self.tune_dir = get_save_dir(self.args, name=self.args.name or "tune")  # è·å–ä¿å­˜ç›®å½•
        self.args.name = None  # é‡ç½®ä»¥ä¸å½±å“è®­ç»ƒç›®å½•
        self.tune_csv = self.tune_dir / "tune_results.csv"  # è®¾ç½®CSVæ–‡ä»¶è·¯å¾„
        self.callbacks = _callbacks or callbacks.get_default_callbacks()  # è·å–å›è°ƒå‡½æ•°
        self.prefix = colorstr("Tuner: ")  # è®¾ç½®å‰ç¼€
        callbacks.add_integration_callbacks(self)  # æ·»åŠ é›†æˆå›è°ƒ
        LOGGER.info(
            f"{self.prefix}Initialized Tuner instance with 'tune_dir={self.tune_dir}'\n"
            f"{self.prefix}ğŸ’¡ Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning"
        )  # è®°å½•åˆå§‹åŒ–ä¿¡æ¯

    def _mutate(self, parent="single", n=5, mutation=0.8, sigma=0.2):
        """
        Mutates the hyperparameters based on bounds and scaling factors specified in `self.space`.

        Args:
            parent (str): Parent selection method: 'single' or 'weighted'.
            n (int): Number of parents to consider.
            mutation (float): Probability of a parameter mutation in any given iteration.
            sigma (float): Standard deviation for Gaussian random number generator.

        Returns:
            (dict): A dictionary containing mutated hyperparameters.
        """
        # æ ¹æ®æŒ‡å®šçš„è¾¹ç•Œå’Œç¼©æ”¾å› å­çªå˜è¶…å‚æ•°ã€‚
        if self.tune_csv.exists():  # å¦‚æœCSVæ–‡ä»¶å­˜åœ¨ï¼šé€‰æ‹©æœ€ä½³è¶…å‚æ•°å¹¶çªå˜
            # Select parent(s)
            x = np.loadtxt(self.tune_csv, ndmin=2, delimiter=",", skiprows=1)  # ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®
            fitness = x[:, 0]  # ç¬¬ä¸€åˆ—ä¸ºé€‚åº”åº¦
            n = min(n, len(x))  # è€ƒè™‘çš„å†å²ç»“æœæ•°é‡
            x = x[np.argsort(-fitness)][:n]  # é€‰æ‹©é€‚åº”åº¦æœ€é«˜çš„nä¸ªç»“æœ
            w = x[:, 0] - x[:, 0].min() + 1e-6  # æƒé‡ï¼ˆç¡®ä¿å’Œå¤§äº0ï¼‰
            if parent == "single" or len(x) == 1:
                # x = x[random.randint(0, n - 1)]  # éšæœºé€‰æ‹©
                x = x[random.choices(range(n), weights=w)[0]]  # åŠ æƒé€‰æ‹©
            elif parent == "weighted":
                x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # åŠ æƒç»„åˆ

            # Mutate
            r = np.random  # éšæœºæ•°æ–¹æ³•
            r.seed(int(time.time()))  # è®¾ç½®éšæœºç§å­
            g = np.array([v[2] if len(v) == 3 else 1.0 for v in self.space.values()])  # è·å–å¢ç›Š
            ng = len(self.space)  # è¶…å‚æ•°æ•°é‡
            v = np.ones(ng)  # åˆå§‹åŒ–å¢ç›Š
            while all(v == 1):  # çªå˜ç›´åˆ°å‘ç”Ÿå˜åŒ–ï¼ˆé˜²æ­¢é‡å¤ï¼‰
                v = (g * (r.random(ng) < mutation) * r.randn(ng) * r.random() * sigma + 1).clip(0.3, 3.0)  # åº”ç”¨çªå˜
            hyp = {k: float(x[i + 1] * v[i]) for i, k in enumerate(self.space.keys())}  # ç”Ÿæˆçªå˜åçš„è¶…å‚æ•°
        else:
            hyp = {k: getattr(self.args, k) for k in self.space.keys()}  # å¦‚æœCSVæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤è¶…å‚æ•°

        # Constrain to limits
        for k, v in self.space.items():
            hyp[k] = max(hyp[k], v[0])  # ä¸‹é™çº¦æŸ
            hyp[k] = min(hyp[k], v[1])  # ä¸Šé™çº¦æŸ
            hyp[k] = round(hyp[k], 5)  # ä¿ç•™5ä½æœ‰æ•ˆæ•°å­—

        return hyp  # è¿”å›çªå˜åçš„è¶…å‚æ•°

    def __call__(self, model=None, iterations=10, cleanup=True):
        """
        Executes the hyperparameter evolution process when the Tuner instance is called.

        This method iterates through the number of iterations, performing the following steps in each iteration:
        1. Load the existing hyperparameters or initialize new ones.
        2. Mutate the hyperparameters using the `mutate` method.
        3. Train a YOLO model with the mutated hyperparameters.
        4. Log the fitness score and mutated hyperparameters to a CSV file.

        Args:
           model (Model): A pre-initialized YOLO model to be used for training.
           iterations (int): The number of generations to run the evolution for.
           cleanup (bool): Whether to delete iteration weights to reduce storage space used during tuning.

        Note:
           The method utilizes the `self.tune_csv` Path object to read and log hyperparameters and fitness scores.
           Ensure this path is set correctly in the Tuner instance.
        """
        # å½“è°ƒç”¨Tunerå®ä¾‹æ—¶æ‰§è¡Œè¶…å‚æ•°è¿›åŒ–è¿‡ç¨‹ã€‚
        t0 = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        best_save_dir, best_metrics = None, None  # åˆå§‹åŒ–æœ€ä½³ä¿å­˜ç›®å½•å’ŒæŒ‡æ ‡
        (self.tune_dir / "weights").mkdir(parents=True, exist_ok=True)  # åˆ›å»ºæƒé‡ä¿å­˜ç›®å½•
        for i in range(iterations):  # è¿­ä»£æŒ‡å®šæ¬¡æ•°
            # Mutate hyperparameters
            mutated_hyp = self._mutate()  # çªå˜è¶…å‚æ•°
            LOGGER.info(f"{self.prefix}Starting iteration {i + 1}/{iterations} with hyperparameters: {mutated_hyp}")  # è®°å½•å½“å‰è¿­ä»£ä¿¡æ¯

            metrics = {}  # åˆå§‹åŒ–æŒ‡æ ‡
            train_args = {**vars(self.args), **mutated_hyp}  # åˆå¹¶å‚æ•°
            save_dir = get_save_dir(get_cfg(train_args))  # è·å–ä¿å­˜ç›®å½•
            weights_dir = save_dir / "weights"  # æƒé‡ä¿å­˜ç›®å½•
            try:
                # Train YOLO model with mutated hyperparameters (run in subprocess to avoid dataloader hang)
                # ä½¿ç”¨çªå˜åçš„è¶…å‚æ•°è®­ç»ƒYOLOæ¨¡å‹ï¼ˆåœ¨å­è¿›ç¨‹ä¸­è¿è¡Œä»¥é¿å…æ•°æ®åŠ è½½å™¨æŒ‚èµ·ï¼‰
                cmd = ["yolo", "train", *(f"{k}={v}" for k, v in train_args.items())]  # æ„å»ºå‘½ä»¤
                return_code = subprocess.run(" ".join(cmd), check=True, shell=True).returncode  # æ‰§è¡Œå‘½ä»¤
                ckpt_file = weights_dir / ("best.pt" if (weights_dir / "best.pt").exists() else "last.pt")  # è·å–æ£€æŸ¥ç‚¹æ–‡ä»¶
                metrics = torch.load(ckpt_file)["train_metrics"]  # åŠ è½½è®­ç»ƒæŒ‡æ ‡
                assert return_code == 0, "training failed"  # æ£€æŸ¥è®­ç»ƒæ˜¯å¦æˆåŠŸ

            except Exception as e:
                LOGGER.warning(f"WARNING âŒï¸ training failure for hyperparameter tuning iteration {i + 1}\n{e}")  # è®°å½•è®­ç»ƒå¤±è´¥çš„è­¦å‘Š

            # Save results and mutated_hyp to CSV
            fitness = metrics.get("fitness", 0.0)  # è·å–é€‚åº”åº¦
            log_row = [round(fitness, 5)] + [mutated_hyp[k] for k in self.space.keys()]  # è®°å½•æ—¥å¿—è¡Œ
            headers = "" if self.tune_csv.exists() else (",".join(["fitness"] + list(self.space.keys())) + "\n")  # è¡¨å¤´
            with open(self.tune_csv, "a") as f:
                f.write(headers + ",".join(map(str, log_row)) + "\n")  # å†™å…¥CSVæ–‡ä»¶

            # Get best results
            x = np.loadtxt(self.tune_csv, ndmin=2, delimiter=",", skiprows=1)  # ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®
            fitness = x[:, 0]  # ç¬¬ä¸€åˆ—ä¸ºé€‚åº”åº¦
            best_idx = fitness.argmax()  # è·å–æœ€ä½³é€‚åº”åº¦çš„ç´¢å¼•
            best_is_current = best_idx == i  # åˆ¤æ–­å½“å‰æ˜¯å¦ä¸ºæœ€ä½³ç»“æœ
            if best_is_current:
                best_save_dir = save_dir  # æ›´æ–°æœ€ä½³ä¿å­˜ç›®å½•
                best_metrics = {k: round(v, 5) for k, v in metrics.items()}  # æ›´æ–°æœ€ä½³æŒ‡æ ‡
                for ckpt in weights_dir.glob("*.pt"):  # éå†æƒé‡ç›®å½•ä¸­çš„æ£€æŸ¥ç‚¹æ–‡ä»¶
                    shutil.copy2(ckpt, self.tune_dir / "weights")  # å¤åˆ¶æ£€æŸ¥ç‚¹åˆ°ä¿å­˜ç›®å½•
            elif cleanup:
                shutil.rmtree(weights_dir, ignore_errors=True)  # åˆ é™¤è¿­ä»£æƒé‡ç›®å½•ä»¥å‡å°‘å­˜å‚¨ç©ºé—´

            # Plot tune results
            plot_tune_results(self.tune_csv)  # ç»˜åˆ¶è°ƒä¼˜ç»“æœ

            # Save and print tune results
            header = (
                f"{self.prefix}{i + 1}/{iterations} iterations complete âœ… ({time.time() - t0:.2f}s)\n"
                f"{self.prefix}Results saved to {colorstr('bold', self.tune_dir)}\n"
                f"{self.prefix}Best fitness={fitness[best_idx]} observed at iteration {best_idx + 1}\n"
                f"{self.prefix}Best fitness metrics are {best_metrics}\n"
                f"{self.prefix}Best fitness model is {best_save_dir}\n"
                f"{self.prefix}Best fitness hyperparameters are printed below.\n"
            )
            LOGGER.info("\n" + header)  # è®°å½•è°ƒä¼˜ç»“æœ
            data = {k: float(x[best_idx, i + 1]) for i, k in enumerate(self.space.keys())}  # è·å–æœ€ä½³è¶…å‚æ•°
            yaml_save(
                self.tune_dir / "best_hyperparameters.yaml",
                data=data,
                header=remove_colorstr(header.replace(self.prefix, "# ")) + "\n",
            )  # ä¿å­˜æœ€ä½³è¶…å‚æ•°åˆ°YAMLæ–‡ä»¶
            yaml_print(self.tune_dir / "best_hyperparameters.yaml")  # æ‰“å°æœ€ä½³è¶…å‚æ•°