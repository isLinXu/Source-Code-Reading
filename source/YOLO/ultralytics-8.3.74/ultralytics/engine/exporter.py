# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
Export a YOLO PyTorch model to other formats. TensorFlow exports authored by https://github.com/zldrobit.

Format                  | `format=argument`         | Model
---                     | ---                       | ---
PyTorch                 | -                         | yolo11n.pt
TorchScript             | `torchscript`             | yolo11n.torchscript
ONNX                    | `onnx`                    | yolo11n.onnx
OpenVINO                | `openvino`                | yolo11n_openvino_model/
TensorRT                | `engine`                  | yolo11n.engine
CoreML                  | `coreml`                  | yolo11n.mlpackage
TensorFlow SavedModel   | `saved_model`             | yolo11n_saved_model/
TensorFlow GraphDef     | `pb`                      | yolo11n.pb
TensorFlow Lite         | `tflite`                  | yolo11n.tflite
TensorFlow Edge TPU     | `edgetpu`                 | yolo11n_edgetpu.tflite
TensorFlow.js           | `tfjs`                    | yolo11n_web_model/
PaddlePaddle            | `paddle`                  | yolo11n_paddle_model/
MNN                     | `mnn`                     | yolo11n.mnn
NCNN                    | `ncnn`                    | yolo11n_ncnn_model/
IMX                     | `imx`                     | yolo11n_imx_model/
RKNN                    | `rknn`                    | yolo11n_rknn_model/

Requirements:
    $ pip install "ultralytics[export]"

Python:
    from ultralytics import YOLO
    model = YOLO('yolo11n.pt')
    results = model.export(format='onnx')

CLI:
    $ yolo mode=export model=yolo11n.pt format=onnx

Inference:
    $ yolo predict model=yolo11n.pt                 # PyTorch
                         yolo11n.torchscript        # TorchScript
                         yolo11n.onnx               # ONNX Runtime or OpenCV DNN with dnn=True
                         yolo11n_openvino_model     # OpenVINO
                         yolo11n.engine             # TensorRT
                         yolo11n.mlpackage          # CoreML (macOS-only)
                         yolo11n_saved_model        # TensorFlow SavedModel
                         yolo11n.pb                 # TensorFlow GraphDef
                         yolo11n.tflite             # TensorFlow Lite
                         yolo11n_edgetpu.tflite     # TensorFlow Edge TPU
                         yolo11n_paddle_model       # PaddlePaddle
                         yolo11n.mnn                # MNN
                         yolo11n_ncnn_model         # NCNN
                         yolo11n_imx_model          # IMX

TensorFlow.js:
    $ cd .. && git clone https://github.com/zldrobit/tfjs-yolov5-example.git && cd tfjs-yolov5-example
    $ npm install
    $ ln -s ../../yolo11n_web_model public/yolo11n_web_model
    $ npm start
"""

import gc  # å¯¼å…¥gcæ¨¡å—ï¼Œç”¨äºåƒåœ¾å›æ”¶
import json  # å¯¼å…¥jsonæ¨¡å—ï¼Œç”¨äºå¤„ç†JSONæ•°æ®
import os  # å¯¼å…¥osæ¨¡å—ï¼Œç”¨äºæ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½
import shutil  # å¯¼å…¥shutilæ¨¡å—ï¼Œç”¨äºæ–‡ä»¶å’Œç›®å½•çš„é«˜çº§æ“ä½œ
import subprocess  # å¯¼å…¥subprocessæ¨¡å—ï¼Œç”¨äºæ‰§è¡Œå¤–éƒ¨å‘½ä»¤
import time  # å¯¼å…¥timeæ¨¡å—ï¼Œç”¨äºæ—¶é—´ç›¸å…³æ“ä½œ
import warnings  # å¯¼å…¥warningsæ¨¡å—ï¼Œç”¨äºå‘å‡ºè­¦å‘Š
from copy import deepcopy  # ä»copyæ¨¡å—å¯¼å…¥deepcopyå‡½æ•°ï¼Œç”¨äºæ·±æ‹·è´
from datetime import datetime  # ä»datetimeæ¨¡å—å¯¼å…¥datetimeç±»ï¼Œç”¨äºå¤„ç†æ—¥æœŸå’Œæ—¶é—´
from pathlib import Path  # ä»pathlibæ¨¡å—å¯¼å…¥Pathç±»ï¼Œç”¨äºå¤„ç†è·¯å¾„

import numpy as np  # å¯¼å…¥numpyåº“ï¼Œç”¨äºæ•°å€¼è®¡ç®—
import torch  # å¯¼å…¥PyTorchåº“ï¼Œç”¨äºæ·±åº¦å­¦ä¹ 

from ultralytics.cfg import TASK2DATA, get_cfg  # ä»ultralytics.cfgæ¨¡å—å¯¼å…¥TASK2DATAå’Œget_cfgå‡½æ•°
from ultralytics.data import build_dataloader  # ä»ultralytics.dataæ¨¡å—å¯¼å…¥build_dataloaderå‡½æ•°
from ultralytics.data.dataset import YOLODataset  # ä»ultralytics.data.datasetæ¨¡å—å¯¼å…¥YOLODatasetç±»
from ultralytics.data.utils import check_cls_dataset, check_det_dataset  # ä»ultralytics.data.utilsæ¨¡å—å¯¼å…¥æ•°æ®é›†æ£€æŸ¥å‡½æ•°
from ultralytics.nn.autobackend import check_class_names, default_class_names  # ä»ultralytics.nn.autobackendæ¨¡å—å¯¼å…¥æ£€æŸ¥ç±»åå’Œé»˜è®¤ç±»åçš„å‡½æ•°
from ultralytics.nn.modules import C2f, Classify, Detect, RTDETRDecoder  # ä»ultralytics.nn.modulesæ¨¡å—å¯¼å…¥æ¨¡å‹æ¨¡å—
from ultralytics.nn.tasks import ClassificationModel, DetectionModel, SegmentationModel, WorldModel  # ä»ultralytics.nn.tasksæ¨¡å—å¯¼å…¥ä¸åŒä»»åŠ¡çš„æ¨¡å‹ç±»
from ultralytics.utils import (  # ä»ultralytics.utilsæ¨¡å—å¯¼å…¥å·¥å…·å‡½æ•°å’Œå¸¸é‡
    ARM64,
    DEFAULT_CFG,
    IS_COLAB,
    IS_JETSON,
    LINUX,
    LOGGER,
    MACOS,
    PYTHON_VERSION,
    RKNN_CHIPS,
    ROOT,
    WINDOWS,
    __version__,
    callbacks,
    colorstr,
    get_default_args,
    yaml_save,
)
from ultralytics.utils.checks import (  # ä»ultralytics.utils.checksæ¨¡å—å¯¼å…¥æ£€æŸ¥å‡½æ•°
    check_imgsz,
    check_is_path_safe,
    check_requirements,
    check_version,
    is_sudo_available,
)
from ultralytics.utils.downloads import attempt_download_asset, get_github_assets, safe_download  # ä»ultralytics.utils.downloadsæ¨¡å—å¯¼å…¥ä¸‹è½½ç›¸å…³å‡½æ•°
from ultralytics.utils.files import file_size, spaces_in_path  # ä»ultralytics.utils.filesæ¨¡å—å¯¼å…¥æ–‡ä»¶å¤§å°å’Œè·¯å¾„ç©ºæ ¼æ£€æŸ¥å‡½æ•°
from ultralytics.utils.ops import Profile, nms_rotated, xywh2xyxy  # ä»ultralytics.utils.opsæ¨¡å—å¯¼å…¥æ“ä½œç›¸å…³å‡½æ•°
from ultralytics.utils.torch_utils import TORCH_1_13, get_latest_opset, select_device  # ä»ultralytics.utils.torch_utilsæ¨¡å—å¯¼å…¥PyTorchç›¸å…³å·¥å…·å‡½æ•°


def export_formats():
    """Ultralytics YOLO export formats.
    Ultralytics YOLOå¯¼å‡ºæ ¼å¼ã€‚"""
    x = [  # å®šä¹‰å¯¼å‡ºæ ¼å¼çš„åˆ—è¡¨
        ["PyTorch", "-", ".pt", True, True, []],  # PyTorchæ ¼å¼
        ["TorchScript", "torchscript", ".torchscript", True, True, ["batch", "optimize", "nms"]],  # TorchScriptæ ¼å¼
        ["ONNX", "onnx", ".onnx", True, True, ["batch", "dynamic", "half", "opset", "simplify", "nms"]],  # ONNXæ ¼å¼
        ["OpenVINO", "openvino", "_openvino_model", True, False, ["batch", "dynamic", "half", "int8", "nms"]],  # OpenVINOæ ¼å¼
        ["TensorRT", "engine", ".engine", False, True, ["batch", "dynamic", "half", "int8", "simplify", "nms"]],  # TensorRTæ ¼å¼
        ["CoreML", "coreml", ".mlpackage", True, False, ["batch", "half", "int8", "nms"]],  # CoreMLæ ¼å¼
        ["TensorFlow SavedModel", "saved_model", "_saved_model", True, True, ["batch", "int8", "keras", "nms"]],  # TensorFlow SavedModelæ ¼å¼
        ["TensorFlow GraphDef", "pb", ".pb", True, True, ["batch"]],  # TensorFlow GraphDefæ ¼å¼
        ["TensorFlow Lite", "tflite", ".tflite", True, False, ["batch", "half", "int8", "nms"]],  # TensorFlow Liteæ ¼å¼
        ["TensorFlow Edge TPU", "edgetpu", "_edgetpu.tflite", True, False, []],  # TensorFlow Edge TPUæ ¼å¼
        ["TensorFlow.js", "tfjs", "_web_model", True, False, ["batch", "half", "int8", "nms"]],  # TensorFlow.jsæ ¼å¼
        ["PaddlePaddle", "paddle", "_paddle_model", True, True, ["batch"]],  # PaddlePaddleæ ¼å¼
        ["MNN", "mnn", ".mnn", True, True, ["batch", "half", "int8"]],  # MNNæ ¼å¼
        ["NCNN", "ncnn", "_ncnn_model", True, True, ["batch", "half"]],  # NCNNæ ¼å¼
        ["IMX", "imx", "_imx_model", True, True, ["int8"]],  # IMXæ ¼å¼
        ["RKNN", "rknn", "_rknn_model", False, False, ["batch", "name"]],  # RKNNæ ¼å¼
    ]
    return dict(zip(["Format", "Argument", "Suffix", "CPU", "GPU", "Arguments"], zip(*x)))  # è¿”å›æ ¼å¼å­—å…¸


def validate_args(format, passed_args, valid_args):
    """
    Validates arguments based on format.
    æ ¹æ®æ ¼å¼éªŒè¯å‚æ•°ã€‚

    Args:
        format (str): The export format.
        passed_args (Namespace): The arguments used during export.
        valid_args (dict): List of valid arguments for the format.

    Raises:
        AssertionError: If an argument that's not supported by the export format is used, or if format doesn't have the supported arguments listed.
    """
    # Only check valid usage of these args
    export_args = ["half", "int8", "dynamic", "keras", "nms", "batch"]  # å®šä¹‰æœ‰æ•ˆå‚æ•°åˆ—è¡¨

    assert valid_args is not None, f"ERROR âŒï¸ valid arguments for '{format}' not listed."  # æ£€æŸ¥æœ‰æ•ˆå‚æ•°æ˜¯å¦å­˜åœ¨
    custom = {"batch": 1, "data": None, "device": None}  # exporteré»˜è®¤å‚æ•°
    default_args = get_cfg(DEFAULT_CFG, custom)  # è·å–é»˜è®¤é…ç½®
    for arg in export_args:  # éå†æœ‰æ•ˆå‚æ•°
        not_default = getattr(passed_args, arg, None) != getattr(default_args, arg, None)  # æ£€æŸ¥å‚æ•°æ˜¯å¦ä¸ºé»˜è®¤å€¼
        if not_default:  # å¦‚æœå‚æ•°ä¸æ˜¯é»˜è®¤å€¼
            assert arg in valid_args, f"ERROR âŒï¸ argument '{arg}' is not supported for format='{format}'"  # æŠ›å‡ºä¸æ”¯æŒå‚æ•°çš„é”™è¯¯


def gd_outputs(gd):
    """TensorFlow GraphDef model output node names.
    TensorFlow GraphDefæ¨¡å‹è¾“å‡ºèŠ‚ç‚¹åç§°ã€‚"""
    name_list, input_list = [], []  # åˆå§‹åŒ–åç§°å’Œè¾“å…¥åˆ—è¡¨
    for node in gd.node:  # éå†èŠ‚ç‚¹
        name_list.append(node.name)  # æ·»åŠ èŠ‚ç‚¹åç§°
        input_list.extend(node.input)  # æ·»åŠ èŠ‚ç‚¹è¾“å…¥
    return sorted(f"{x}:0" for x in list(set(name_list) - set(input_list)) if not x.startswith("NoOp"))  # è¿”å›è¾“å‡ºèŠ‚ç‚¹åç§°


def try_export(inner_func):
    """YOLO export decorator, i.e. @try_export.
    YOLOå¯¼å‡ºè£…é¥°å™¨ï¼Œå³@try_exportã€‚"""
    inner_args = get_default_args(inner_func)  # è·å–å†…éƒ¨å‡½æ•°çš„é»˜è®¤å‚æ•°

    def outer_func(*args, **kwargs):
        """Export a model.
        å¯¼å‡ºæ¨¡å‹ã€‚"""
        prefix = inner_args["prefix"]  # è·å–å‰ç¼€
        try:
            with Profile() as dt:  # è®°å½•æ—¶é—´
                f, model = inner_func(*args, **kwargs)  # è°ƒç”¨å†…éƒ¨å‡½æ•°
            LOGGER.info(f"{prefix} export success âœ… {dt.t:.1f}s, saved as '{f}' ({file_size(f):.1f} MB)")  # æ—¥å¿—è®°å½•å¯¼å‡ºæˆåŠŸ
            return f, model  # è¿”å›æ–‡ä»¶å’Œæ¨¡å‹
        except Exception as e:
            LOGGER.error(f"{prefix} export failure âŒ {dt.t:.1f}s: {e}")  # æ—¥å¿—è®°å½•å¯¼å‡ºå¤±è´¥
            raise e  # æŠ›å‡ºå¼‚å¸¸

    return outer_func  # è¿”å›å¤–éƒ¨å‡½æ•°

class Exporter:
    """
    A class for exporting a model.
    ç”¨äºå¯¼å‡ºæ¨¡å‹çš„ç±»ã€‚

    Attributes:
        args (SimpleNamespace): Configuration for the exporter.
        callbacks (list, optional): List of callback functions. Defaults to None.
        # å±æ€§ï¼š
        #     args (SimpleNamespace): å¯¼å‡ºçš„é…ç½®ã€‚
        #     callbacks (list, optional): å›è°ƒå‡½æ•°åˆ—è¡¨ã€‚é»˜è®¤ä¸ºNoneã€‚
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """
        Initializes the Exporter class.
        åˆå§‹åŒ–Exporterç±»ã€‚

        Args:
            cfg (str, optional): Path to a configuration file. Defaults to DEFAULT_CFG.
            # å‚æ•°ï¼š
            #     cfg (str, optional): é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤ä¸ºDEFAULT_CFGã€‚
            overrides (dict, optional): Configuration overrides. Defaults to None.
            #     overrides (dict, optional): é…ç½®è¦†ç›–ã€‚é»˜è®¤ä¸ºNoneã€‚
            _callbacks (dict, optional): Dictionary of callback functions. Defaults to None.
            #     _callbacks (dict, optional): å›è°ƒå‡½æ•°å­—å…¸ã€‚é»˜è®¤ä¸ºNoneã€‚
        """
        self.args = get_cfg(cfg, overrides)  # è·å–é…ç½®

        if self.args.format.lower() in {"coreml", "mlmodel"}:  # fix attempt for protobuf<3.20.x errors
            os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"  # å¿…é¡»åœ¨TensorBoardå›è°ƒä¹‹å‰è¿è¡Œ

        self.callbacks = _callbacks or callbacks.get_default_callbacks()  # è®¾ç½®å›è°ƒå‡½æ•°
        callbacks.add_integration_callbacks(self)  # æ·»åŠ é›†æˆå›è°ƒ

    def __call__(self, model=None) -> str:
        """Returns list of exported files/dirs after running callbacks.
        åœ¨è¿è¡Œå›è°ƒåè¿”å›å¯¼å‡ºæ–‡ä»¶/ç›®å½•çš„åˆ—è¡¨ã€‚"""
        self.run_callbacks("on_export_start")  # è¿è¡Œå¯¼å‡ºå¼€å§‹çš„å›è°ƒ
        t = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
        fmt = self.args.format.lower()  # å°†æ ¼å¼è½¬æ¢ä¸ºå°å†™
        if fmt in {"tensorrt", "trt"}:  # 'engine' åˆ«å
            fmt = "engine"
        if fmt in {"mlmodel", "mlpackage", "mlprogram", "apple", "ios", "coreml"}:  # 'coreml' åˆ«å
            fmt = "coreml"
        fmts_dict = export_formats()  # è·å–å¯¼å‡ºæ ¼å¼å­—å…¸
        fmts = tuple(fmts_dict["Argument"][1:])  # å¯ç”¨çš„å¯¼å‡ºæ ¼å¼
        if fmt not in fmts:  # å¦‚æœæ ¼å¼æ— æ•ˆ
            import difflib  # å¯¼å…¥difflibæ¨¡å—ç”¨äºæŸ¥æ‰¾ç›¸ä¼¼é¡¹

            # Get the closest match if format is invalid
            matches = difflib.get_close_matches(fmt, fmts, n=1, cutoff=0.6)  # 60%ç›¸ä¼¼åº¦æ‰èƒ½åŒ¹é…
            if not matches:  # å¦‚æœæ²¡æœ‰åŒ¹é…é¡¹
                raise ValueError(f"Invalid export format='{fmt}'. Valid formats are {fmts}")  # æŠ›å‡ºæ— æ•ˆæ ¼å¼é”™è¯¯
            LOGGER.warning(f"WARNING âš ï¸ Invalid export format='{fmt}', updating to format='{matches[0]}'")  # æ—¥å¿—è®°å½•æ— æ•ˆæ ¼å¼è­¦å‘Š
            fmt = matches[0]  # æ›´æ–°æ ¼å¼ä¸ºåŒ¹é…çš„æ ¼å¼
        flags = [x == fmt for x in fmts]  # åˆ›å»ºæ ¼å¼æ ‡å¿—
        if sum(flags) != 1:  # å¦‚æœæ ¼å¼æ ‡å¿—ä¸å”¯ä¸€
            raise ValueError(f"Invalid export format='{fmt}'. Valid formats are {fmts}")  # æŠ›å‡ºæ— æ•ˆæ ¼å¼é”™è¯¯
        (jit, onnx, xml, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, paddle, mnn, ncnn, imx, rknn) = (
            flags  # å¯¼å‡ºå¸ƒå°”å€¼
        )

        is_tf_format = any((saved_model, pb, tflite, edgetpu, tfjs))  # æ£€æŸ¥æ˜¯å¦ä¸ºTensorFlowæ ¼å¼

        # Device
        dla = None  # åˆå§‹åŒ–DLAä¸ºNone
        if fmt == "engine" and self.args.device is None:  # å¦‚æœæ ¼å¼ä¸ºengineä¸”æœªæŒ‡å®šè®¾å¤‡
            LOGGER.warning("WARNING âš ï¸ TensorRT requires GPU export, automatically assigning device=0")  # æ—¥å¿—è®°å½•è­¦å‘Š
            self.args.device = "0"  # è‡ªåŠ¨åˆ†é…è®¾å¤‡ä¸º0
        if fmt == "engine" and "dla" in str(self.args.device):  # å¦‚æœè®¾å¤‡ä¸ºDLA
            dla = self.args.device.split(":")[-1]  # è·å–DLAè®¾å¤‡ç¼–å·
            self.args.device = "0"  # æ›´æ–°è®¾å¤‡ä¸º"0"
            assert dla in {"0", "1"}, f"Expected self.args.device='dla:0' or 'dla:1, but got {self.args.device}."  # æ£€æŸ¥DLAè®¾å¤‡ç¼–å·
        self.device = select_device("cpu" if self.args.device is None else self.args.device)  # é€‰æ‹©è®¾å¤‡

        # Argument compatibility checks
        fmt_keys = fmts_dict["Arguments"][flags.index(True) + 1]  # è·å–æ ¼å¼å¯¹åº”çš„å‚æ•°
        validate_args(fmt, self.args, fmt_keys)  # éªŒè¯å‚æ•°å…¼å®¹æ€§
        if imx and not self.args.int8:  # å¦‚æœæ ¼å¼ä¸ºIMXä¸”æœªè®¾ç½®int8
            LOGGER.warning("WARNING âš ï¸ IMX only supports int8 export, setting int8=True.")  # æ—¥å¿—è®°å½•è­¦å‘Š
            self.args.int8 = True  # è®¾ç½®int8ä¸ºTrue
        if not hasattr(model, "names"):  # å¦‚æœæ¨¡å‹æ²¡æœ‰nameså±æ€§
            model.names = default_class_names()  # è®¾ç½®é»˜è®¤ç±»å
        model.names = check_class_names(model.names)  # æ£€æŸ¥ç±»å
        if self.args.half and self.args.int8:  # å¦‚æœåŒæ—¶è®¾ç½®äº†halfå’Œint8
            LOGGER.warning("WARNING âš ï¸ half=True and int8=True are mutually exclusive, setting half=False.")  # æ—¥å¿—è®°å½•è­¦å‘Š
            self.args.half = False  # è®¾ç½®halfä¸ºFalse
        if self.args.half and onnx and self.device.type == "cpu":  # å¦‚æœåœ¨CPUä¸Šä½¿ç”¨halfå’Œonnx
            LOGGER.warning("WARNING âš ï¸ half=True only compatible with GPU export, i.e. use device=0")  # æ—¥å¿—è®°å½•è­¦å‘Š
            self.args.half = False  # è®¾ç½®halfä¸ºFalse
            assert not self.args.dynamic, "half=True not compatible with dynamic=True, i.e. use only one."  # æ£€æŸ¥åŠ¨æ€å‚æ•°
        self.imgsz = check_imgsz(self.args.imgsz, stride=model.stride, min_dim=2)  # æ£€æŸ¥å›¾åƒå¤§å°
        if self.args.int8 and engine:  # å¦‚æœæ ¼å¼ä¸ºengineä¸”è®¾ç½®äº†int8
            self.args.dynamic = True  # å¼ºåˆ¶åŠ¨æ€å¯¼å‡ºTensorRT INT8
        if self.args.optimize:  # å¦‚æœè®¾ç½®äº†ä¼˜åŒ–
            assert not ncnn, "optimize=True not compatible with format='ncnn', i.e. use optimize=False"  # æ£€æŸ¥ncnnå…¼å®¹æ€§
            assert self.device.type == "cpu", "optimize=True not compatible with cuda devices, i.e. use device='cpu'"  # æ£€æŸ¥CUDAè®¾å¤‡å…¼å®¹æ€§
        if rknn:  # å¦‚æœæ ¼å¼ä¸ºRKNN
            if not self.args.name:  # å¦‚æœæœªè®¾ç½®åç§°
                LOGGER.warning(
                    "WARNING âš ï¸ Rockchip RKNN export requires a missing 'name' arg for processor type. Using default name='rk3588'."  # æ—¥å¿—è®°å½•è­¦å‘Š
                )
                self.args.name = "rk3588"  # è®¾ç½®é»˜è®¤åç§°
            self.args.name = self.args.name.lower()  # å°†åç§°è½¬æ¢ä¸ºå°å†™
            assert self.args.name in RKNN_CHIPS, (
                f"Invalid processor name '{self.args.name}' for Rockchip RKNN export. Valid names are {RKNN_CHIPS}."  # æ£€æŸ¥RKNNå¤„ç†å™¨åç§°
            )
        if self.args.int8 and tflite:  # å¦‚æœè®¾ç½®äº†int8ä¸”æ ¼å¼ä¸ºtflite
            assert not getattr(model, "end2end", False), "TFLite INT8 export not supported for end2end models."  # æ£€æŸ¥end2endæ¨¡å‹å…¼å®¹æ€§
        if self.args.nms:  # å¦‚æœè®¾ç½®äº†éæå¤§å€¼æŠ‘åˆ¶
            assert not isinstance(model, ClassificationModel), "'nms=True' is not valid for classification models."  # æ£€æŸ¥åˆ†ç±»æ¨¡å‹å…¼å®¹æ€§
            if getattr(model, "end2end", False):  # å¦‚æœæ˜¯end2endæ¨¡å‹
                LOGGER.warning("WARNING âš ï¸ 'nms=True' is not available for end2end models. Forcing 'nms=False'.")  # æ—¥å¿—è®°å½•è­¦å‘Š
                self.args.nms = False  # å¼ºåˆ¶nmsä¸ºFalse
            self.args.conf = self.args.conf or 0.25  # è®¾ç½®nmså¯¼å‡ºçš„é»˜è®¤ç½®ä¿¡åº¦
        if edgetpu:  # å¦‚æœæ ¼å¼ä¸ºEdge TPU
            if not LINUX:  # æ£€æŸ¥æ“ä½œç³»ç»Ÿ
                raise SystemError("Edge TPU export only supported on Linux. See https://coral.ai/docs/edgetpu/compiler")  # æŠ›å‡ºç³»ç»Ÿé”™è¯¯
            elif self.args.batch != 1:  # æ£€æŸ¥æ‰¹æ¬¡å¤§å°
                LOGGER.warning("WARNING âš ï¸ Edge TPU export requires batch size 1, setting batch=1.")  # æ—¥å¿—è®°å½•è­¦å‘Š
                self.args.batch = 1  # è®¾ç½®æ‰¹æ¬¡å¤§å°ä¸º1
        if isinstance(model, WorldModel):  # å¦‚æœæ¨¡å‹æ˜¯WorldModel
            LOGGER.warning(
                "WARNING âš ï¸ YOLOWorld (original version) export is not supported to any format.\n"
                "WARNING âš ï¸ YOLOWorldv2 models (i.e. 'yolov8s-worldv2.pt') only support export to "
                "(torchscript, onnx, openvino, engine, coreml) formats. "
                "See https://docs.ultralytics.com/models/yolo-world for details."  # æ—¥å¿—è®°å½•è­¦å‘Š
            )
            model.clip_model = None  # openvino int8å¯¼å‡ºé”™è¯¯
        if self.args.int8 and not self.args.data:  # å¦‚æœè®¾ç½®äº†int8ä¸”æœªæŒ‡å®šæ•°æ®
            self.args.data = DEFAULT_CFG.data or TASK2DATA[getattr(model, "task", "detect")]  # è®¾ç½®é»˜è®¤æ•°æ®
            LOGGER.warning(
                "WARNING âš ï¸ INT8 export requires a missing 'data' arg for calibration. "
                f"Using default 'data={self.args.data}'."  # æ—¥å¿—è®°å½•è­¦å‘Š
            )

        # Input
        im = torch.zeros(self.args.batch, 3, *self.imgsz).to(self.device)  # åˆ›å»ºè¾“å…¥å¼ é‡
        file = Path(
            getattr(model, "pt_path", None) or getattr(model, "yaml_file", None) or model.yaml.get("yaml_file", "")
        )  # è·å–æ¨¡å‹æ–‡ä»¶è·¯å¾„
        if file.suffix in {".yaml", ".yml"}:  # å¦‚æœæ–‡ä»¶æ˜¯yamlæ ¼å¼
            file = Path(file.name)  # è·å–æ–‡ä»¶å

        # Update model
        model = deepcopy(model).to(self.device)  # æ·±æ‹·è´æ¨¡å‹å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        for p in model.parameters():  # éå†æ¨¡å‹å‚æ•°
            p.requires_grad = False  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
        model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        model.float()  # è½¬æ¢æ¨¡å‹ä¸ºæµ®ç‚¹æ¨¡å¼
        model = model.fuse()  # èåˆæ¨¡å‹å±‚

        if imx:  # å¦‚æœæ ¼å¼ä¸ºIMX
            from ultralytics.utils.torch_utils import FXModel  # å¯¼å…¥FXModel

            model = FXModel(model)  # å°†æ¨¡å‹è½¬æ¢ä¸ºFXModel
        for m in model.modules():  # éå†æ¨¡å‹æ¨¡å—
            if isinstance(m, Classify):  # å¦‚æœæ¨¡å—æ˜¯Classify
                m.export = True  # è®¾ç½®å¯¼å‡ºæ ‡å¿—
            if isinstance(m, (Detect, RTDETRDecoder)):  # å¦‚æœæ¨¡å—æ˜¯Detectæˆ–RTDETRDecoder
                m.dynamic = self.args.dynamic  # è®¾ç½®åŠ¨æ€æ ‡å¿—
                m.export = True  # è®¾ç½®å¯¼å‡ºæ ‡å¿—
                m.format = self.args.format  # è®¾ç½®æ ¼å¼
                m.max_det = self.args.max_det  # è®¾ç½®æœ€å¤§æ£€æµ‹æ•°
            elif isinstance(m, C2f) and not is_tf_format:  # å¦‚æœæ¨¡å—æ˜¯C2fä¸”ä¸æ˜¯TensorFlowæ ¼å¼
                # EdgeTPU does not support FlexSplitV while split provides cleaner ONNX graph
                m.forward = m.forward_split  # ä½¿ç”¨åˆ†å‰²çš„å‰å‘ä¼ æ’­
            if isinstance(m, Detect) and imx:  # å¦‚æœæ¨¡å—æ˜¯Detectä¸”æ ¼å¼ä¸ºIMX
                from ultralytics.utils.tal import make_anchors  # å¯¼å…¥make_anchorså‡½æ•°

                m.anchors, m.strides = (
                    x.transpose(0, 1)  # è½¬ç½®é”šç‚¹å’Œæ­¥å¹…
                    for x in make_anchors(
                        torch.cat([s / m.stride.unsqueeze(-1) for s in self.imgsz], dim=1), m.stride, 0.5
                    )
                )

        y = None  # åˆå§‹åŒ–è¾“å‡ºä¸ºNone
        for _ in range(2):  # å¹²è·‘
            y = NMSModel(model, self.args)(im) if self.args.nms and not coreml else model(im)  # è¿è¡Œæ¨¡å‹
        if self.args.half and onnx and self.device.type != "cpu":  # å¦‚æœè®¾ç½®äº†halfä¸”æ ¼å¼ä¸ºonnxä¸”è®¾å¤‡ä¸æ˜¯CPU
            im, model = im.half(), model.half()  # è½¬æ¢ä¸ºFP16

        # Filter warnings
        warnings.filterwarnings("ignore", category=torch.jit.TracerWarning)  # æŠ‘åˆ¶TracerWarning
        warnings.filterwarnings("ignore", category=UserWarning)  # æŠ‘åˆ¶å½¢çŠ¶ç¼ºå¤±çš„ONNXè­¦å‘Š
        warnings.filterwarnings("ignore", category=DeprecationWarning)  # æŠ‘åˆ¶CoreML np.boolå¼ƒç”¨è­¦å‘Š

        # Assign
        self.im = im  # è®¾ç½®è¾“å…¥
        self.model = model  # è®¾ç½®æ¨¡å‹
        self.file = file  # è®¾ç½®æ–‡ä»¶è·¯å¾„
        self.output_shape = (
            tuple(y.shape)  # è®¾ç½®è¾“å‡ºå½¢çŠ¶
            if isinstance(y, torch.Tensor)
            else tuple(tuple(x.shape if isinstance(x, torch.Tensor) else []) for x in y)
        )
        self.pretty_name = Path(self.model.yaml.get("yaml_file", self.file)).stem.replace("yolo", "YOLO")  # è®¾ç½®ç¾åŒ–åç§°
        data = model.args["data"] if hasattr(model, "args") and isinstance(model.args, dict) else ""  # è·å–æ•°æ®
        description = f"Ultralytics {self.pretty_name} model {f'trained on {data}' if data else ''}"  # è®¾ç½®æè¿°
        self.metadata = {  # è®¾ç½®æ¨¡å‹å…ƒæ•°æ®
            "description": description,
            "author": "Ultralytics",
            "date": datetime.now().isoformat(),
            "version": __version__,
            "license": "AGPL-3.0 License (https://ultralytics.com/license)",
            "docs": "https://docs.ultralytics.com",
            "stride": int(max(model.stride)),
            "task": model.task,
            "batch": self.args.batch,
            "imgsz": self.imgsz,
            "names": model.names,
            "args": {k: v for k, v in self.args if k in fmt_keys},
        }  # æ¨¡å‹å…ƒæ•°æ®
        if dla is not None:  # å¦‚æœDLAä¸ä¸ºNone
            self.metadata["dla"] = dla  # ç¡®ä¿AutoBackendä½¿ç”¨æ­£ç¡®çš„DLAè®¾å¤‡
        if model.task == "pose":  # å¦‚æœä»»åŠ¡æ˜¯å§¿æ€ä¼°è®¡
            self.metadata["kpt_shape"] = model.model[-1].kpt_shape  # è®¾ç½®å…³é”®ç‚¹å½¢çŠ¶

        LOGGER.info(  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
            f"\n{colorstr('PyTorch:')} starting from '{file}' with input shape {tuple(im.shape)} BCHW and "
            f"output shape(s) {self.output_shape} ({file_size(file):.1f} MB)"
        )

        # Exports
        f = [""] * len(fmts)  # å¯¼å‡ºæ–‡ä»¶å
        if jit or ncnn:  # TorchScript
            f[0], _ = self.export_torchscript()  # å¯¼å‡ºTorchScriptæ¨¡å‹
        if engine:  # TensorRTéœ€è¦åœ¨ONNXä¹‹å‰å¯¼å‡º
            f[1], _ = self.export_engine(dla=dla)  # å¯¼å‡ºTensorRTæ¨¡å‹
        if onnx:  # ONNX
            f[2], _ = self.export_onnx()  # å¯¼å‡ºONNXæ¨¡å‹
        if xml:  # OpenVINO
            f[3], _ = self.export_openvino()  # å¯¼å‡ºOpenVINOæ¨¡å‹
        if coreml:  # CoreML
            f[4], _ = self.export_coreml()  # å¯¼å‡ºCoreMLæ¨¡å‹
        if is_tf_format:  # TensorFlowæ ¼å¼
            self.args.int8 |= edgetpu  # è®¾ç½®int8ä¸ºTrue
            f[5], keras_model = self.export_saved_model()  # å¯¼å‡ºTensorFlow SavedModel
            if pb or tfjs:  # pbæ˜¯tfjsçš„å‰æ
                f[6], _ = self.export_pb(keras_model=keras_model)  # å¯¼å‡ºTensorFlow GraphDef
            if tflite:  # å¯¼å‡ºTensorFlow Lite
                f[7], _ = self.export_tflite(keras_model=keras_model, nms=False, agnostic_nms=self.args.agnostic_nms)
            if edgetpu:  # å¯¼å‡ºEdge TPU
                f[8], _ = self.export_edgetpu(tflite_model=Path(f[5]) / f"{self.file.stem}_full_integer_quant.tflite")
            if tfjs:  # å¯¼å‡ºTensorFlow.js
                f[9], _ = self.export_tfjs()
        if paddle:  # PaddlePaddle
            f[10], _ = self.export_paddle()  # å¯¼å‡ºPaddlePaddleæ¨¡å‹
        if mnn:  # MNN
            f[11], _ = self.export_mnn()  # å¯¼å‡ºMNNæ¨¡å‹
        if ncnn:  # NCNN
            f[12], _ = self.export_ncnn()  # å¯¼å‡ºNCNNæ¨¡å‹
        if imx:  # IMX
            f[13], _ = self.export_imx()  # å¯¼å‡ºIMXæ¨¡å‹
        if rknn:  # RKNN
            f[14], _ = self.export_rknn()  # å¯¼å‡ºRKNNæ¨¡å‹

        # Finish
        f = [str(x) for x in f if x]  # è¿‡æ»¤æ‰ç©ºå­—ç¬¦ä¸²å’ŒNone
        if any(f):  # å¦‚æœæœ‰å¯¼å‡ºæ–‡ä»¶
            f = str(Path(f[-1]))  # è·å–æœ€åä¸€ä¸ªæ–‡ä»¶çš„è·¯å¾„
            square = self.imgsz[0] == self.imgsz[1]  # æ£€æŸ¥æ˜¯å¦ä¸ºæ­£æ–¹å½¢å›¾åƒ
            s = (
                ""
                if square
                else f"WARNING âš ï¸ non-PyTorch val requires square images, 'imgsz={self.imgsz}' will not "
                f"work. Use export 'imgsz={max(self.imgsz)}' if val is required."  # æ—¥å¿—è®°å½•è­¦å‘Š
            )
            imgsz = self.imgsz[0] if square else str(self.imgsz)[1:-1].replace(" ", "")  # è®¾ç½®å›¾åƒå¤§å°
            predict_data = f"data={data}" if model.task == "segment" and fmt == "pb" else ""  # è®¾ç½®é¢„æµ‹æ•°æ®
            q = "int8" if self.args.int8 else "half" if self.args.half else ""  # é‡åŒ–
            LOGGER.info(
                f"\nExport complete ({time.time() - t:.1f}s)"
                f"\nResults saved to {colorstr('bold', file.parent.resolve())}"
                f"\nPredict:         yolo predict task={model.task} model={f} imgsz={imgsz} {q} {predict_data}"
                f"\nValidate:        yolo val task={model.task} model={f} imgsz={imgsz} data={data} {q} {s}"
                f"\nVisualize:       https://netron.app"  # æ—¥å¿—è®°å½•å¯¼å‡ºå®Œæˆä¿¡æ¯
            )

        self.run_callbacks("on_export_end")  # è¿è¡Œå¯¼å‡ºç»“æŸçš„å›è°ƒ
        return f  # è¿”å›å¯¼å‡ºæ–‡ä»¶/ç›®å½•çš„åˆ—è¡¨

    def get_int8_calibration_dataloader(self, prefix=""):
        """Build and return a dataloader suitable for calibration of INT8 models.
        æ„å»ºå¹¶è¿”å›é€‚åˆINT8æ¨¡å‹æ ¡å‡†çš„æ•°æ®åŠ è½½å™¨ã€‚"""
        LOGGER.info(f"{prefix} collecting INT8 calibration images from 'data={self.args.data}'")  # æ—¥å¿—è®°å½•æ ¡å‡†å›¾åƒæ”¶é›†ä¿¡æ¯
        data = (check_cls_dataset if self.model.task == "classify" else check_det_dataset)(self.args.data)  # æ£€æŸ¥æ•°æ®é›†
        # TensorRT INT8 calibration should use 2x batch size
        batch = self.args.batch * (2 if self.args.format == "engine" else 1)  # è®¾ç½®æ‰¹æ¬¡å¤§å°
        dataset = YOLODataset(
            data[self.args.split or "val"],  # è·å–æ•°æ®é›†
            data=data,
            task=self.model.task,
            imgsz=self.imgsz[0],  # è®¾ç½®å›¾åƒå¤§å°
            augment=False,  # ä¸è¿›è¡Œæ•°æ®å¢å¼º
            batch_size=batch,  # è®¾ç½®æ‰¹æ¬¡å¤§å°
        )
        n = len(dataset)  # è·å–æ•°æ®é›†å¤§å°
        if n < self.args.batch:  # å¦‚æœæ•°æ®é›†å¤§å°å°äºæ‰¹æ¬¡å¤§å°
            raise ValueError(
                f"The calibration dataset ({n} images) must have at least as many images as the batch size ('batch={self.args.batch}')."
            )  # æŠ›å‡ºé”™è¯¯
        elif n < 300:  # å¦‚æœæ•°æ®é›†å¤§å°å°äº300
            LOGGER.warning(f"{prefix} WARNING âš ï¸ >300 images recommended for INT8 calibration, found {n} images.")  # æ—¥å¿—è®°å½•è­¦å‘Š
        return build_dataloader(dataset, batch=batch, workers=0)  # è¿”å›æ•°æ®åŠ è½½å™¨

    @try_export
    def export_torchscript(self, prefix=colorstr("TorchScript:")):
        """YOLO TorchScript model export.
        YOLO TorchScriptæ¨¡å‹å¯¼å‡ºã€‚"""
        LOGGER.info(f"\n{prefix} starting export with torch {torch.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºå¼€å§‹ä¿¡æ¯
        f = self.file.with_suffix(".torchscript")  # è®¾ç½®å¯¼å‡ºæ–‡ä»¶å

        ts = torch.jit.trace(NMSModel(self.model, self.args) if self.args.nms else self.model, self.im, strict=False)  # è·Ÿè¸ªæ¨¡å‹
        extra_files = {"config.txt": json.dumps(self.metadata)}  # é™„åŠ æ–‡ä»¶
        if self.args.optimize:  # å¦‚æœè®¾ç½®äº†ä¼˜åŒ–
            LOGGER.info(f"{prefix} optimizing for mobile...")  # æ—¥å¿—è®°å½•ä¼˜åŒ–ä¿¡æ¯
            from torch.utils.mobile_optimizer import optimize_for_mobile  # å¯¼å…¥ä¼˜åŒ–å‡½æ•°

            optimize_for_mobile(ts)._save_for_lite_interpreter(str(f), _extra_files=extra_files)  # ä¿å­˜ä¼˜åŒ–åçš„æ¨¡å‹
        else:
            ts.save(str(f), _extra_files=extra_files)  # ä¿å­˜æ¨¡å‹
        return f, None  # è¿”å›æ–‡ä»¶åå’ŒNone

        
    @try_export
    def export_onnx(self, prefix=colorstr("ONNX:")):
        """YOLO ONNX export."""  # YOLO ONNX å¯¼å‡º
        requirements = ["onnx>=1.12.0"]  # éœ€è¦çš„ä¾èµ–åº“
        if self.args.simplify:
            requirements += ["onnxslim", "onnxruntime" + ("-gpu" if torch.cuda.is_available() else "")]  # å¦‚æœéœ€è¦ç®€åŒ–ï¼Œæ·»åŠ ä¾èµ–
        check_requirements(requirements)  # æ£€æŸ¥ä¾èµ–åº“æ˜¯å¦æ»¡è¶³

        import onnx  # noqa  # å¯¼å…¥ ONNX åº“

        opset_version = self.args.opset or get_latest_opset()  # è·å– opset ç‰ˆæœ¬
        LOGGER.info(f"\n{prefix} starting export with onnx {onnx.__version__} opset {opset_version}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        f = str(self.file.with_suffix(".onnx"))  # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
        output_names = ["output0", "output1"] if isinstance(self.model, SegmentationModel) else ["output0"]  # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®è¾“å‡ºåç§°
        dynamic = self.args.dynamic  # è·å–åŠ¨æ€å‚æ•°
        if dynamic:
            self.model.cpu()  # dynamic=True ä»…æ”¯æŒ CPU
            dynamic = {"images": {0: "batch", 2: "height", 3: "width"}}  # shape(1,3,640,640)
            if isinstance(self.model, SegmentationModel):
                dynamic["output0"] = {0: "batch", 2: "anchors"}  # shape(1, 116, 8400)
                dynamic["output1"] = {0: "batch", 2: "mask_height", 3: "mask_width"}  # shape(1,32,160,160)
            elif isinstance(self.model, DetectionModel):
                dynamic["output0"] = {0: "batch", 2: "anchors"}  # shape(1, 84, 8400)
            if self.args.nms:  # åªæœ‰åœ¨ NMS æ—¶ batch size æ˜¯åŠ¨æ€çš„
                dynamic["output0"].pop(2)  # ç§»é™¤åŠ¨æ€è¾“å‡ºçš„ç¬¬ä¸‰ç»´

        if self.args.nms and self.model.task == "obb":
            self.args.opset = opset_version  # å¯¹äº NMSModel
            # OBB error https://github.com/pytorch/pytorch/issues/110859#issuecomment-1757841865
            try:
                torch.onnx.register_custom_op_symbolic("aten::lift_fresh", lambda g, x: x, opset_version)  # æ³¨å†Œè‡ªå®šä¹‰æ“ä½œ
            except RuntimeError:  # å¦‚æœå·²ç»æ³¨å†Œåˆ™ä¼šå¤±è´¥
                pass
            check_requirements("onnxslim>=0.1.46")  # æ£€æŸ¥ onnxslim ç‰ˆæœ¬

        torch.onnx.export(
            NMSModel(self.model, self.args) if self.args.nms else self.model,  # å¯¼å‡ºæ¨¡å‹
            self.im.cpu() if dynamic else self.im,  # è¾“å…¥å›¾åƒ
            f,  # è¾“å‡ºæ–‡ä»¶
            verbose=False,  # æ˜¯å¦è¯¦ç»†è¾“å‡º
            opset_version=opset_version,  # opset ç‰ˆæœ¬
            do_constant_folding=True,  # è­¦å‘Šï¼štorch>=1.12 å¯èƒ½éœ€è¦ do_constant_folding=False
            input_names=["images"],  # è¾“å…¥åç§°
            output_names=output_names,  # è¾“å‡ºåç§°
            dynamic_axes=dynamic or None,  # åŠ¨æ€è½´
        )

        # Checks
        model_onnx = onnx.load(f)  # åŠ è½½ ONNX æ¨¡å‹

        # Simplify
        if self.args.simplify:
            try:
                import onnxslim  # å¯¼å…¥ onnxslim åº“

                LOGGER.info(f"{prefix} slimming with onnxslim {onnxslim.__version__}...")  # æ—¥å¿—è®°å½•ç®€åŒ–ä¿¡æ¯
                model_onnx = onnxslim.slim(model_onnx)  # ç®€åŒ–æ¨¡å‹

            except Exception as e:
                LOGGER.warning(f"{prefix} simplifier failure: {e}")  # è®°å½•ç®€åŒ–å¤±è´¥çš„ä¿¡æ¯

        # Metadata
        for k, v in self.metadata.items():  # éå†å…ƒæ•°æ®
            meta = model_onnx.metadata_props.add()  # æ·»åŠ å…ƒæ•°æ®å±æ€§
            meta.key, meta.value = k, str(v)  # è®¾ç½®é”®å€¼å¯¹

        onnx.save(model_onnx, f)  # ä¿å­˜ ONNX æ¨¡å‹
        return f, model_onnx  # è¿”å›æ–‡ä»¶è·¯å¾„å’Œæ¨¡å‹

    @try_export
    def export_openvino(self, prefix=colorstr("OpenVINO:")):
        """YOLO OpenVINO export."""  # YOLO OpenVINO å¯¼å‡º
        check_requirements("openvino>=2024.5.0")  # æ£€æŸ¥ OpenVINO ç‰ˆæœ¬
        import openvino as ov  # å¯¼å…¥ OpenVINO åº“

        LOGGER.info(f"\n{prefix} starting export with openvino {ov.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        assert TORCH_1_13, f"OpenVINO export requires torch>=1.13.0 but torch=={torch.__version__} is installed"  # æ£€æŸ¥ PyTorch ç‰ˆæœ¬
        ov_model = ov.convert_model(
            NMSModel(self.model, self.args) if self.args.nms else self.model,  # è½¬æ¢æ¨¡å‹
            input=None if self.args.dynamic else [self.im.shape],  # è¾“å…¥å½¢çŠ¶
            example_input=self.im,  # ç¤ºä¾‹è¾“å…¥
        )

        def serialize(ov_model, file):
            """Set RT info, serialize and save metadata YAML."""  # è®¾ç½®è¿è¡Œæ—¶ä¿¡æ¯ï¼Œåºåˆ—åŒ–å¹¶ä¿å­˜å…ƒæ•°æ® YAML
            ov_model.set_rt_info("YOLO", ["model_info", "model_type"])  # è®¾ç½®æ¨¡å‹ç±»å‹
            ov_model.set_rt_info(True, ["model_info", "reverse_input_channels"])  # è®¾ç½®åè½¬è¾“å…¥é€šé“
            ov_model.set_rt_info(114, ["model_info", "pad_value"])  # è®¾ç½®å¡«å……å€¼
            ov_model.set_rt_info([255.0], ["model_info", "scale_values"])  # è®¾ç½®ç¼©æ”¾å€¼
            ov_model.set_rt_info(self.args.iou, ["model_info", "iou_threshold"])  # è®¾ç½® IOU é˜ˆå€¼
            ov_model.set_rt_info([v.replace(" ", "_") for v in self.model.names.values()], ["model_info", "labels"])  # è®¾ç½®æ ‡ç­¾
            if self.model.task != "classify":
                ov_model.set_rt_info("fit_to_window_letterbox", ["model_info", "resize_type"])  # è®¾ç½®è°ƒæ•´ç±»å‹

            ov.runtime.save_model(ov_model, file, compress_to_fp16=self.args.half)  # ä¿å­˜æ¨¡å‹
            yaml_save(Path(file).parent / "metadata.yaml", self.metadata)  # æ·»åŠ å…ƒæ•°æ® YAML

        if self.args.int8:
            fq = str(self.file).replace(self.file.suffix, f"_int8_openvino_model{os.sep}")  # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
            fq_ov = str(Path(fq) / self.file.with_suffix(".xml").name)  # è®¾ç½® OpenVINO è¾“å‡ºæ–‡ä»¶å
            check_requirements("nncf>=2.14.0")  # æ£€æŸ¥ NNCF ç‰ˆæœ¬
            import nncf  # å¯¼å…¥ NNCF åº“

            def transform_fn(data_item) -> np.ndarray:
                """Quantization transform function."""  # é‡åŒ–è½¬æ¢å‡½æ•°
                data_item: torch.Tensor = data_item["img"] if isinstance(data_item, dict) else data_item  # è·å–å›¾åƒæ•°æ®
                assert data_item.dtype == torch.uint8, "Input image must be uint8 for the quantization preprocessing"  # æ£€æŸ¥æ•°æ®ç±»å‹
                im = data_item.numpy().astype(np.float32) / 255.0  # uint8 è½¬æ¢ä¸º fp16/32ï¼Œå¹¶å°†èŒƒå›´ä» 0-255 è½¬æ¢ä¸º 0.0 - 1.0
                return np.expand_dims(im, 0) if im.ndim == 3 else im  # è¿”å›å¤„ç†åçš„å›¾åƒ

            # Generate calibration data for integer quantization
            ignored_scope = None  # åˆå§‹åŒ–å¿½ç•¥èŒƒå›´
            if isinstance(self.model.model[-1], Detect):  # å¦‚æœæ¨¡å‹æœ€åä¸€å±‚æ˜¯ Detect
                # Includes all Detect subclasses like Segment, Pose, OBB, WorldDetect
                head_module_name = ".".join(list(self.model.named_modules())[-1][0].split(".")[:2])  # è·å–å¤´æ¨¡å—åç§°
                ignored_scope = nncf.IgnoredScope(  # å¿½ç•¥æ“ä½œ
                    patterns=[
                        f".*{head_module_name}/.*/Add",
                        f".*{head_module_name}/.*/Sub*",
                        f".*{head_module_name}/.*/Mul*",
                        f".*{head_module_name}/.*/Div*",
                        f".*{head_module_name}\\.dfl.*",
                    ],
                    types=["Sigmoid"],
                )

            quantized_ov_model = nncf.quantize(
                model=ov_model,
                calibration_dataset=nncf.Dataset(self.get_int8_calibration_dataloader(prefix), transform_fn),  # é‡åŒ–æ•°æ®é›†
                preset=nncf.QuantizationPreset.MIXED,  # é‡åŒ–é¢„è®¾
                ignored_scope=ignored_scope,  # å¿½ç•¥èŒƒå›´
            )
            serialize(quantized_ov_model, fq_ov)  # åºåˆ—åŒ–é‡åŒ–æ¨¡å‹
            return fq, None  # è¿”å›æ–‡ä»¶è·¯å¾„

        f = str(self.file).replace(self.file.suffix, f"_openvino_model{os.sep}")  # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
        f_ov = str(Path(f) / self.file.with_suffix(".xml").name)  # è®¾ç½® OpenVINO è¾“å‡ºæ–‡ä»¶å

        serialize(ov_model, f_ov)  # åºåˆ—åŒ–æ¨¡å‹
        return f, None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_paddle(self, prefix=colorstr("PaddlePaddle:")):
        """YOLO Paddle export."""  # YOLO Paddle å¯¼å‡º
        check_requirements(("paddlepaddle-gpu" if torch.cuda.is_available() else "paddlepaddle", "x2paddle"))  # æ£€æŸ¥ PaddlePaddle ä¾èµ–
        import x2paddle  # noqa  # å¯¼å…¥ x2paddle åº“
        from x2paddle.convert import pytorch2paddle  # noqa  # ä» x2paddle å¯¼å…¥è½¬æ¢å‡½æ•°

        LOGGER.info(f"\n{prefix} starting export with X2Paddle {x2paddle.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        f = str(self.file).replace(self.file.suffix, f"_paddle_model{os.sep}")  # è®¾ç½®è¾“å‡ºæ–‡ä»¶å

        pytorch2paddle(module=self.model, save_dir=f, jit_type="trace", input_examples=[self.im])  # å¯¼å‡ºæ¨¡å‹
        yaml_save(Path(f) / "metadata.yaml", self.metadata)  # æ·»åŠ å…ƒæ•°æ® YAML
        return f, None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_mnn(self, prefix=colorstr("MNN:")):
        """YOLOv8 MNN export using MNN https://github.com/alibaba/MNN."""  # ä½¿ç”¨ MNN å¯¼å‡º YOLOv8
        f_onnx, _ = self.export_onnx()  # é¦–å…ˆè·å– ONNX æ¨¡å‹

        check_requirements("MNN>=2.9.6")  # æ£€æŸ¥ MNN ç‰ˆæœ¬
        import MNN  # noqa  # å¯¼å…¥ MNN åº“
        from MNN.tools import mnnconvert  # å¯¼å…¥ MNN è½¬æ¢å·¥å…·

        # Setup and checks
        LOGGER.info(f"\n{prefix} starting export with MNN {MNN.version()}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        assert Path(f_onnx).exists(), f"failed to export ONNX file: {f_onnx}"  # æ£€æŸ¥ ONNX æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        f = str(self.file.with_suffix(".mnn"))  # è®¾ç½® MNN æ¨¡å‹æ–‡ä»¶
        args = ["", "-f", "ONNX", "--modelFile", f_onnx, "--MNNModel", f, "--bizCode", json.dumps(self.metadata)]  # è®¾ç½®è½¬æ¢å‚æ•°
        if self.args.int8:
            args.extend(("--weightQuantBits", "8"))  # æ·»åŠ æƒé‡é‡åŒ–ä½æ•°å‚æ•°
        if self.args.half:
            args.append("--fp16")  # æ·»åŠ  FP16 å‚æ•°
        mnnconvert.convert(args)  # æ‰§è¡Œè½¬æ¢
        # remove scratch file for model convert optimize
        convert_scratch = Path(self.file.parent / ".__convert_external_data.bin")  # è®¾ç½®ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        if convert_scratch.exists():
            convert_scratch.unlink()  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        return f, None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_ncnn(self, prefix=colorstr("NCNN:")):
        """YOLO NCNN export using PNNX https://github.com/pnnx/pnnx."""  # ä½¿ç”¨ PNNX å¯¼å‡º YOLO NCNN
        check_requirements("ncnn")  # æ£€æŸ¥ NCNN ä¾èµ–
        import ncnn  # noqa  # å¯¼å…¥ NCNN åº“

        LOGGER.info(f"\n{prefix} starting export with NCNN {ncnn.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        f = Path(str(self.file).replace(self.file.suffix, f"_ncnn_model{os.sep}"))  # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
        f_ts = self.file.with_suffix(".torchscript")  # è®¾ç½® TorchScript æ–‡ä»¶å

        name = Path("pnnx.exe" if WINDOWS else "pnnx")  # PNNX æ–‡ä»¶å
        pnnx = name if name.is_file() else (ROOT / name)  # è·å– PNNX è·¯å¾„
        if not pnnx.is_file():
            LOGGER.warning(
                f"{prefix} WARNING âš ï¸ PNNX not found. Attempting to download binary file from "
                "https://github.com/pnnx/pnnx/.\nNote PNNX Binary file must be placed in current working directory "
                f"or in {ROOT}. See PNNX repo for full installation instructions."
            )  # æ—¥å¿—è®°å½• PNNX æœªæ‰¾åˆ°çš„è­¦å‘Š
            system = "macos" if MACOS else "windows" if WINDOWS else "linux-aarch64" if ARM64 else "linux"  # è·å–ç³»ç»Ÿç±»å‹
            try:
                release, assets = get_github_assets(repo="pnnx/pnnx")  # è·å– GitHub èµ„äº§
                asset = [x for x in assets if f"{system}.zip" in x][0]  # è·å–å¯¹åº”ç³»ç»Ÿçš„èµ„äº§
                assert isinstance(asset, str), "Unable to retrieve PNNX repo assets"  # æ£€æŸ¥èµ„äº§ç±»å‹
                LOGGER.info(f"{prefix} successfully found latest PNNX asset file {asset}")  # æ—¥å¿—è®°å½•æˆåŠŸæ‰¾åˆ°èµ„äº§
            except Exception as e:
                release = "20240410"  # é»˜è®¤ç‰ˆæœ¬
                asset = f"pnnx-{release}-{system}.zip"  # é»˜è®¤èµ„äº§
                LOGGER.warning(f"{prefix} WARNING âš ï¸ PNNX GitHub assets not found: {e}, using default {asset}")  # æ—¥å¿—è®°å½•æœªæ‰¾åˆ°èµ„äº§çš„è­¦å‘Š
            unzip_dir = safe_download(f"https://github.com/pnnx/pnnx/releases/download/{release}/{asset}", delete=True)  # ä¸‹è½½èµ„äº§
            if check_is_path_safe(Path.cwd(), unzip_dir):  # é¿å…è·¯å¾„éå†å®‰å…¨æ¼æ´
                shutil.move(src=unzip_dir / name, dst=pnnx)  # ç§»åŠ¨äºŒè¿›åˆ¶æ–‡ä»¶åˆ° ROOT
                pnnx.chmod(0o777)  # è®¾ç½®æƒé™
                shutil.rmtree(unzip_dir)  # åˆ é™¤è§£å‹ç›®å½•

        ncnn_args = [
            f"ncnnparam={f / 'model.ncnn.param'}",  # NCNN å‚æ•°æ–‡ä»¶
            f"ncnnbin={f / 'model.ncnn.bin'}",  # NCNN äºŒè¿›åˆ¶æ–‡ä»¶
            f"ncnnpy={f / 'model_ncnn.py'}",  # NCNN Python æ–‡ä»¶
        ]

        pnnx_args = [
            f"pnnxparam={f / 'model.pnnx.param'}",  # PNNX å‚æ•°æ–‡ä»¶
            f"pnnxbin={f / 'model.pnnx.bin'}",  # PNNX äºŒè¿›åˆ¶æ–‡ä»¶
            f"pnnxpy={f / 'model_pnnx.py'}",  # PNNX Python æ–‡ä»¶
            f"pnnxonnx={f / 'model.pnnx.onnx'}",  # PNNX ONNX æ–‡ä»¶
        ]

        cmd = [
            str(pnnx),  # PNNX å‘½ä»¤
            str(f_ts),  # TorchScript æ–‡ä»¶
            *ncnn_args,  # NCNN å‚æ•°
            *pnnx_args,  # PNNX å‚æ•°
            f"fp16={int(self.args.half)}",  # FP16 å‚æ•°
            f"device={self.device.type}",  # è®¾å¤‡ç±»å‹
            f'inputshape="{[self.args.batch, 3, *self.imgsz]}"',  # è¾“å…¥å½¢çŠ¶
        ]
        f.mkdir(exist_ok=True)  # åˆ›å»º ncnn_model ç›®å½•
        LOGGER.info(f"{prefix} running '{' '.join(cmd)}'")  # æ—¥å¿—è®°å½•è¿è¡Œå‘½ä»¤
        subprocess.run(cmd, check=True)  # æ‰§è¡Œå‘½ä»¤

        # Remove debug files
        pnnx_files = [x.split("=")[-1] for x in pnnx_args]  # è·å– PNNX æ–‡ä»¶åˆ—è¡¨
        for f_debug in ("debug.bin", "debug.param", "debug2.bin", "debug2.param", *pnnx_files):  # éå†è°ƒè¯•æ–‡ä»¶
            Path(f_debug).unlink(missing_ok=True)  # åˆ é™¤è°ƒè¯•æ–‡ä»¶

        yaml_save(f / "metadata.yaml", self.metadata)  # æ·»åŠ å…ƒæ•°æ® YAML
        return str(f), None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_coreml(self, prefix=colorstr("CoreML:")):
        """YOLO CoreML export."""  # YOLO CoreML å¯¼å‡º
        mlmodel = self.args.format.lower() == "mlmodel"  # æ£€æŸ¥æ˜¯å¦è¯·æ±‚ legacy *.mlmodel å¯¼å‡ºæ ¼å¼
        check_requirements("coremltools>=6.0,<=6.2" if mlmodel else "coremltools>=7.0")  # æ£€æŸ¥ coremltools ç‰ˆæœ¬
        import coremltools as ct  # noqa  # å¯¼å…¥ coremltools åº“

        LOGGER.info(f"\n{prefix} starting export with coremltools {ct.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        assert not WINDOWS, "CoreML export is not supported on Windows, please run on macOS or Linux."  # æ£€æŸ¥æ“ä½œç³»ç»Ÿ
        assert self.args.batch == 1, "CoreML batch sizes > 1 are not supported. Please retry at 'batch=1'."  # æ£€æŸ¥æ‰¹å¤§å°
        f = self.file.with_suffix(".mlmodel" if mlmodel else ".mlpackage")  # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
        if f.is_dir():
            shutil.rmtree(f)  # åˆ é™¤å·²å­˜åœ¨çš„ç›®å½•

        bias = [0.0, 0.0, 0.0]  # åç½®
        scale = 1 / 255  # ç¼©æ”¾å› å­
        classifier_config = None  # åˆå§‹åŒ–åˆ†ç±»å™¨é…ç½®
        if self.model.task == "classify":
            classifier_config = ct.ClassifierConfig(list(self.model.names.values())) if self.args.nms else None  # è®¾ç½®åˆ†ç±»å™¨é…ç½®
            model = self.model  # è·å–æ¨¡å‹
        elif self.model.task == "detect":
            model = IOSDetectModel(self.model, self.im) if self.args.nms else self.model  # æ£€æŸ¥æ¨¡å‹ç±»å‹
        else:
            if self.args.nms:
                LOGGER.warning(f"{prefix} WARNING âš ï¸ 'nms=True' is only available for Detect models like 'yolo11n.pt'.")  # æ—¥å¿—è®°å½•è­¦å‘Š
                # TODO CoreML Segment and Pose model pipelining
            model = self.model  # è·å–æ¨¡å‹

        ts = torch.jit.trace(model.eval(), self.im, strict=False)  # TorchScript æ¨¡å‹
        ct_model = ct.convert(
            ts,
            inputs=[ct.ImageType("image", shape=self.im.shape, scale=scale, bias=bias)],  # è®¾ç½®è¾“å…¥ç±»å‹
            classifier_config=classifier_config,  # è®¾ç½®åˆ†ç±»å™¨é…ç½®
            convert_to="neuralnetwork" if mlmodel else "mlprogram",  # è½¬æ¢ç±»å‹
        )
        bits, mode = (8, "kmeans") if self.args.int8 else (16, "linear") if self.args.half else (32, None)  # è®¾ç½®é‡åŒ–ä½æ•°å’Œæ¨¡å¼
        if bits < 32:
            if "kmeans" in mode:
                check_requirements("scikit-learn")  # æ£€æŸ¥ scikit-learn ä¾èµ–
            if mlmodel:
                ct_model = ct.models.neural_network.quantization_utils.quantize_weights(ct_model, bits, mode)  # é‡åŒ–æƒé‡
            elif bits == 8:  # mlprogram å·²ç»é‡åŒ–ä¸º FP16
                import coremltools.optimize.coreml as cto  # å¯¼å…¥ä¼˜åŒ–æ¨¡å—

                op_config = cto.OpPalettizerConfig(mode="kmeans", nbits=bits, weight_threshold=512)  # è®¾ç½®ä¼˜åŒ–é…ç½®
                config = cto.OptimizationConfig(global_config=op_config)  # è®¾ç½®å…¨å±€é…ç½®
                ct_model = cto.palettize_weights(ct_model, config=config)  # è¿›è¡Œæƒé‡è°ƒè‰²

        if self.args.nms and self.model.task == "detect":
            if mlmodel:
                # coremltools<=6.2 NMS export requires Python<3.11
                check_version(PYTHON_VERSION, "<3.11", name="Python ", hard=True)  # æ£€æŸ¥ Python ç‰ˆæœ¬
                weights_dir = None  # åˆå§‹åŒ–æƒé‡ç›®å½•
            else:
                ct_model.save(str(f))  # ä¿å­˜æ¨¡å‹ï¼Œå¦åˆ™æƒé‡ç›®å½•ä¸å­˜åœ¨
                weights_dir = str(f / "Data/com.apple.CoreML/weights")  # è·å–æƒé‡ç›®å½•

            ct_model = self._pipeline_coreml(ct_model, weights_dir=weights_dir)  # è¿›è¡Œ CoreML ç®¡é“å¤„ç†

        m = self.metadata  # è·å–å…ƒæ•°æ®å­—å…¸
        ct_model.short_description = m.pop("description")  # è®¾ç½®ç®€çŸ­æè¿°
        ct_model.author = m.pop("author")  # è®¾ç½®ä½œè€…
        ct_model.license = m.pop("license")  # è®¾ç½®è®¸å¯è¯
        ct_model.version = m.pop("version")  # è®¾ç½®ç‰ˆæœ¬
        ct_model.user_defined_metadata.update({k: str(v) for k, v in m.items()})  # æ›´æ–°ç”¨æˆ·å®šä¹‰çš„å…ƒæ•°æ®
        try:
            ct_model.save(str(f))  # ä¿å­˜ *.mlpackage
        except Exception as e:
            LOGGER.warning(
                f"{prefix} WARNING âš ï¸ CoreML export to *.mlpackage failed ({e}), reverting to *.mlmodel export. "
                f"Known coremltools Python 3.11 and Windows bugs https://github.com/apple/coremltools/issues/1928."
            )  # æ—¥å¿—è®°å½•ä¿å­˜å¤±è´¥çš„è­¦å‘Š
            f = f.with_suffix(".mlmodel")  # å›é€€åˆ° *.mlmodel
            ct_model.save(str(f))  # ä¿å­˜æ¨¡å‹
        return f, ct_model  # è¿”å›æ–‡ä»¶è·¯å¾„å’Œæ¨¡å‹

    @try_export
    def export_engine(self, dla=None, prefix=colorstr("TensorRT:")):
        """YOLO TensorRT export https://developer.nvidia.com/tensorrt."""  # YOLO TensorRT å¯¼å‡º
        assert self.im.device.type != "cpu", "export running on CPU but must be on GPU, i.e. use 'device=0'"  # ç¡®ä¿åœ¨ GPU ä¸Šå¯¼å‡º
        f_onnx, _ = self.export_onnx()  # è¿è¡Œ ONNX å¯¼å‡ºï¼Œç¡®ä¿åœ¨ TRT å¯¼å…¥ä¹‹å‰ https://github.com/ultralytics/ultralytics/issues/7016

        try:
            import tensorrt as trt  # noqa  # å¯¼å…¥ TensorRT åº“
        except ImportError:
            if LINUX:
                check_requirements("tensorrt>7.0.0,!=10.1.0")  # æ£€æŸ¥ TensorRT ç‰ˆæœ¬
            import tensorrt as trt  # noqa  # å†æ¬¡å¯¼å…¥ TensorRT åº“
        check_version(trt.__version__, ">=7.0.0", hard=True)  # æ£€æŸ¥ TensorRT ç‰ˆæœ¬æ˜¯å¦å¤§äºç­‰äº 7.0.0
        check_version(trt.__version__, "!=10.1.0", msg="https://github.com/ultralytics/ultralytics/pull/14239")  # æ£€æŸ¥ TensorRT ç‰ˆæœ¬æ˜¯å¦ä¸ç­‰äº 10.1.0

        # Setup and checks
        LOGGER.info(f"\n{prefix} starting export with TensorRT {trt.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        is_trt10 = int(trt.__version__.split(".")[0]) >= 10  # æ£€æŸ¥ TensorRT ç‰ˆæœ¬æ˜¯å¦å¤§äºç­‰äº 10
        assert Path(f_onnx).exists(), f"failed to export ONNX file: {f_onnx}"  # æ£€æŸ¥ ONNX æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        f = self.file.with_suffix(".engine")  # è®¾ç½® TensorRT å¼•æ“æ–‡ä»¶å
        logger = trt.Logger(trt.Logger.INFO)  # åˆ›å»º TensorRT æ—¥å¿—è®°å½•å™¨
        if self.args.verbose:
            logger.min_severity = trt.Logger.Severity.VERBOSE  # å¦‚æœéœ€è¦è¯¦ç»†æ—¥å¿—ï¼Œè®¾ç½®æ—¥å¿—çº§åˆ«

        # Engine builder
        builder = trt.Builder(logger)  # åˆ›å»º TensorRT æ„å»ºå™¨
        config = builder.create_builder_config()  # åˆ›å»ºæ„å»ºé…ç½®
        workspace = int(self.args.workspace * (1 << 30)) if self.args.workspace is not None else 0  # è®¾ç½®å·¥ä½œåŒºå¤§å°
        if is_trt10 and workspace > 0:
            config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, workspace)  # è®¾ç½®å·¥ä½œåŒºå†…å­˜é™åˆ¶
        elif workspace > 0:  # TensorRT ç‰ˆæœ¬ 7 å’Œ 8
            config.max_workspace_size = workspace  # è®¾ç½®æœ€å¤§å·¥ä½œåŒºå¤§å°
        flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)  # è®¾ç½®ç½‘ç»œå®šä¹‰æ ‡å¿—
        network = builder.create_network(flag)  # åˆ›å»ºç½‘ç»œ
        half = builder.platform_has_fast_fp16 and self.args.half  # æ£€æŸ¥æ˜¯å¦æ”¯æŒ FP16
        int8 = builder.platform_has_fast_int8 and self.args.int8  # æ£€æŸ¥æ˜¯å¦æ”¯æŒ INT8

        # Optionally switch to DLA if enabled
        if dla is not None:
            if not IS_JETSON:
                raise ValueError("DLA is only available on NVIDIA Jetson devices")  # DLA ä»…åœ¨ NVIDIA Jetson è®¾å¤‡ä¸Šå¯ç”¨
            LOGGER.info(f"{prefix} enabling DLA on core {dla}...")  # æ—¥å¿—è®°å½•å¯ç”¨ DLA ä¿¡æ¯
            if not self.args.half and not self.args.int8:
                raise ValueError(
                    "DLA requires either 'half=True' (FP16) or 'int8=True' (INT8) to be enabled. Please enable one of them and try again."
                )  # DLA éœ€è¦å¯ç”¨ FP16 æˆ– INT8
            config.default_device_type = trt.DeviceType.DLA  # è®¾ç½®é»˜è®¤è®¾å¤‡ç±»å‹ä¸º DLA
            config.DLA_core = int(dla)  # è®¾ç½® DLA æ ¸å¿ƒ
            config.set_flag(trt.BuilderFlag.GPU_FALLBACK)  # è®¾ç½® GPU å›é€€æ ‡å¿—

        # Read ONNX file
        parser = trt.OnnxParser(network, logger)  # åˆ›å»º ONNX è§£æå™¨
        if not parser.parse_from_file(f_onnx):
            raise RuntimeError(f"failed to load ONNX file: {f_onnx}")  # è§£æ ONNX æ–‡ä»¶å¤±è´¥

        # Network inputs
        inputs = [network.get_input(i) for i in range(network.num_inputs)]  # è·å–ç½‘ç»œè¾“å…¥
        outputs = [network.get_output(i) for i in range(network.num_outputs)]  # è·å–ç½‘ç»œè¾“å‡º
        for inp in inputs:
            LOGGER.info(f'{prefix} input "{inp.name}" with shape{inp.shape} {inp.dtype}')  # æ—¥å¿—è®°å½•è¾“å…¥ä¿¡æ¯
        for out in outputs:
            LOGGER.info(f'{prefix} output "{out.name}" with shape{out.shape} {out.dtype}')  # æ—¥å¿—è®°å½•è¾“å‡ºä¿¡æ¯

        if self.args.dynamic:
            shape = self.im.shape  # è·å–è¾“å…¥å›¾åƒå½¢çŠ¶
            if shape[0] <= 1:
                LOGGER.warning(f"{prefix} WARNING âš ï¸ 'dynamic=True' model requires max batch size, i.e. 'batch=16'")  # æ—¥å¿—è®°å½•åŠ¨æ€æ¨¡å‹çš„è­¦å‘Š
            profile = builder.create_optimization_profile()  # åˆ›å»ºä¼˜åŒ–é…ç½®æ–‡ä»¶
            min_shape = (1, shape[1], 32, 32)  # æœ€å°è¾“å…¥å½¢çŠ¶
            max_shape = (*shape[:2], *(int(max(1, workspace) * d) for d in shape[2:]))  # æœ€å¤§è¾“å…¥å½¢çŠ¶
            for inp in inputs:
                profile.set_shape(inp.name, min=min_shape, opt=shape, max=max_shape)  # è®¾ç½®è¾“å…¥å½¢çŠ¶
            config.add_optimization_profile(profile)  # æ·»åŠ ä¼˜åŒ–é…ç½®æ–‡ä»¶

        LOGGER.info(f"{prefix} building {'INT8' if int8 else 'FP' + ('16' if half else '32')} engine as {f}")  # æ—¥å¿—è®°å½•æ„å»ºå¼•æ“ä¿¡æ¯
        if int8:
            config.set_flag(trt.BuilderFlag.INT8)  # è®¾ç½® INT8 æ ‡å¿—
            config.set_calibration_profile(profile)  # è®¾ç½®æ ¡å‡†é…ç½®æ–‡ä»¶
            config.profiling_verbosity = trt.ProfilingVerbosity.DETAILED  # è®¾ç½®è¯¦ç»†çš„æ€§èƒ½åˆ†æ

            class EngineCalibrator(trt.IInt8Calibrator):
                def __init__(
                    self,
                    dataset,  # ultralytics.data.build.InfiniteDataLoader
                    batch: int,
                    cache: str = "",
                ) -> None:
                    trt.IInt8Calibrator.__init__(self)  # åˆå§‹åŒ–åŸºç±»
                    self.dataset = dataset  # ä¿å­˜æ•°æ®é›†
                    self.data_iter = iter(dataset)  # åˆ›å»ºæ•°æ®è¿­ä»£å™¨
                    self.algo = trt.CalibrationAlgoType.ENTROPY_CALIBRATION_2  # è®¾ç½®æ ¡å‡†ç®—æ³•
                    self.batch = batch  # è®¾ç½®æ‰¹å¤§å°
                    self.cache = Path(cache)  # è®¾ç½®ç¼“å­˜è·¯å¾„

                def get_algorithm(self) -> trt.CalibrationAlgoType:
                    """Get the calibration algorithm to use."""  # è·å–æ ¡å‡†ç®—æ³•
                    return self.algo

                def get_batch_size(self) -> int:
                    """Get the batch size to use for calibration."""  # è·å–ç”¨äºæ ¡å‡†çš„æ‰¹å¤§å°
                    return self.batch or 1  # å¦‚æœæœªè®¾ç½®ï¼Œåˆ™è¿”å› 1

                def get_batch(self, names) -> list:
                    """Get the next batch to use for calibration, as a list of device memory pointers."""  # è·å–ä¸‹ä¸€ä¸ªç”¨äºæ ¡å‡†çš„æ‰¹æ¬¡
                    try:
                        im0s = next(self.data_iter)["img"] / 255.0  # è·å–å›¾åƒå¹¶å½’ä¸€åŒ–
                        im0s = im0s.to("cuda") if im0s.device.type == "cpu" else im0s  # ç§»åŠ¨åˆ° GPU
                        return [int(im0s.data_ptr())]  # è¿”å›è®¾å¤‡å†…å­˜æŒ‡é’ˆ
                    except StopIteration:
                        # Return [] or None, signal to TensorRT there is no calibration data remaining
                        return None  # è¿”å› Noneï¼Œè¡¨ç¤ºæ²¡æœ‰å‰©ä½™çš„æ ¡å‡†æ•°æ®

                def read_calibration_cache(self) -> bytes:
                    """Use existing cache instead of calibrating again, otherwise, implicitly return None."""  # ä½¿ç”¨ç°æœ‰ç¼“å­˜è€Œä¸æ˜¯é‡æ–°æ ¡å‡†
                    if self.cache.exists() and self.cache.suffix == ".cache":
                        return self.cache.read_bytes()  # è¯»å–ç¼“å­˜æ•°æ®

                def write_calibration_cache(self, cache) -> None:
                    """Write calibration cache to disk."""  # å°†æ ¡å‡†ç¼“å­˜å†™å…¥ç£ç›˜
                    _ = self.cache.write_bytes(cache)  # å†™å…¥ç¼“å­˜

            # Load dataset w/ builder (for batching) and calibrate
            config.int8_calibrator = EngineCalibrator(
                dataset=self.get_int8_calibration_dataloader(prefix),  # è·å– INT8 æ ¡å‡†æ•°æ®åŠ è½½å™¨
                batch=2 * self.args.batch,  # TensorRT INT8 æ ¡å‡†åº”ä½¿ç”¨ 2 å€çš„æ‰¹å¤§å°
                cache=str(self.file.with_suffix(".cache")),  # è®¾ç½®ç¼“å­˜æ–‡ä»¶è·¯å¾„
            )

        elif half:
            config.set_flag(trt.BuilderFlag.FP16)  # è®¾ç½® FP16 æ ‡å¿—

        # Free CUDA memory
        del self.model  # åˆ é™¤æ¨¡å‹ä»¥é‡Šæ”¾ CUDA å†…å­˜
        gc.collect()  # åƒåœ¾å›æ”¶
        torch.cuda.empty_cache()  # æ¸…ç©º CUDA ç¼“å­˜

        # Write file
        build = builder.build_serialized_network if is_trt10 else builder.build_engine  # æ ¹æ® TensorRT ç‰ˆæœ¬é€‰æ‹©æ„å»ºæ–¹æ³•
        with build(network, config) as engine, open(f, "wb") as t:  # æ„å»ºå¼•æ“å¹¶æ‰“å¼€æ–‡ä»¶è¿›è¡Œå†™å…¥
            # Metadata
            meta = json.dumps(self.metadata)  # å°†å…ƒæ•°æ®è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
            t.write(len(meta).to_bytes(4, byteorder="little", signed=True))  # å†™å…¥å…ƒæ•°æ®é•¿åº¦
            t.write(meta.encode())  # å†™å…¥å…ƒæ•°æ®
            # Model
            t.write(engine if is_trt10 else engine.serialize())  # å†™å…¥æ¨¡å‹æ•°æ®

        return f, None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_saved_model(self, prefix=colorstr("TensorFlow SavedModel:")):
        """YOLO TensorFlow SavedModel export."""  # YOLO TensorFlow SavedModel å¯¼å‡º
        cuda = torch.cuda.is_available()  # æ£€æŸ¥æ˜¯å¦å¯ç”¨ CUDA
        try:
            import tensorflow as tf  # noqa  # å¯¼å…¥ TensorFlow åº“
        except ImportError:
            suffix = "-macos" if MACOS else "-aarch64" if ARM64 else "" if cuda else "-cpu"  # æ ¹æ®å¹³å°è®¾ç½®åç¼€
            version = ">=2.0.0"  # è®¾ç½®ç‰ˆæœ¬è¦æ±‚
            check_requirements(f"tensorflow{suffix}{version}")  # æ£€æŸ¥ TensorFlow ä¾èµ–
            import tensorflow as tf  # noqa  # å†æ¬¡å¯¼å…¥ TensorFlow åº“
        check_requirements(
            (
                "keras",  # required by 'onnx2tf' package
                "tf_keras",  # required by 'onnx2tf' package
                "sng4onnx>=1.0.1",  # required by 'onnx2tf' package
                "onnx_graphsurgeon>=0.3.26",  # required by 'onnx2tf' package
                "onnx>=1.12.0",  # ONNX ç‰ˆæœ¬è¦æ±‚
                "onnx2tf>1.17.5,<=1.26.3",  # ONNX2TF ç‰ˆæœ¬è¦æ±‚
                "onnxslim>=0.1.31",  # ONNX Slim ç‰ˆæœ¬è¦æ±‚
                "tflite_support<=0.4.3" if IS_JETSON else "tflite_support",  # ä¿®å¤ Jetson çš„å¯¼å…¥é”™è¯¯
                "flatbuffers>=23.5.26,<100",  # æ›´æ–° TensorFlow åŒ…å†…çš„æ—§ flatbuffers
                "onnxruntime-gpu" if cuda else "onnxruntime",  # æ ¹æ®æ˜¯å¦å¯ç”¨ CUDA è®¾ç½® ONNX Runtime
            ),
            cmds="--extra-index-url https://pypi.ngc.nvidia.com",  # ONNX GraphSurgeon ä»…åœ¨ NVIDIA ä¸Šå¯ç”¨
        )

        LOGGER.info(f"\n{prefix} starting export with tensorflow {tf.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        check_version(
            tf.__version__,
            ">=2.0.0",
            name="tensorflow",
            verbose=True,
            msg="https://github.com/ultralytics/ultralytics/issues/5161",
        )  # æ£€æŸ¥ TensorFlow ç‰ˆæœ¬

        import onnx2tf  # å¯¼å…¥ ONNX2TF åº“

        f = Path(str(self.file).replace(self.file.suffix, "_saved_model"))  # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
        if f.is_dir():
            shutil.rmtree(f)  # åˆ é™¤è¾“å‡ºæ–‡ä»¶å¤¹

        # Pre-download calibration file to fix https://github.com/PINTO0309/onnx2tf/issues/545
        onnx2tf_file = Path("calibration_image_sample_data_20x128x128x3_float32.npy")  # æ ¡å‡†æ–‡ä»¶è·¯å¾„
        if not onnx2tf_file.exists():
            attempt_download_asset(f"{onnx2tf_file}.zip", unzip=True, delete=True)  # ä¸‹è½½æ ¡å‡†æ–‡ä»¶

        # Export to ONNX
        self.args.simplify = True  # è®¾ç½®ç®€åŒ–å‚æ•°
        f_onnx, _ = self.export_onnx()  # å¯¼å‡º ONNX æ¨¡å‹

        # Export to TF
        np_data = None  # åˆå§‹åŒ– NumPy æ•°æ®
        if self.args.int8:
            tmp_file = f / "tmp_tflite_int8_calibration_images.npy"  # INT8 æ ¡å‡†å›¾åƒæ–‡ä»¶
            if self.args.data:
                f.mkdir()  # åˆ›å»ºè¾“å‡ºç›®å½•
                images = [batch["img"] for batch in self.get_int8_calibration_dataloader(prefix)]  # è·å–æ ¡å‡†å›¾åƒ
                images = torch.nn.functional.interpolate(torch.cat(images, 0).float(), size=self.imgsz).permute(
                    0, 2, 3, 1
                )  # è°ƒæ•´å›¾åƒå¤§å°å¹¶è°ƒæ•´ç»´åº¦
                np.save(str(tmp_file), images.numpy().astype(np.float32))  # ä¿å­˜å›¾åƒä¸º NumPy æ–‡ä»¶
                np_data = ["images", tmp_file, [[[[0, 0, 0]]]], [[[[255, 255, 255]]]]]  # è®¾ç½®è¾“å…¥æ•°æ®

        LOGGER.info(f"{prefix} starting TFLite export with onnx2tf {onnx2tf.__version__}...")  # æ—¥å¿—è®°å½• TFLite å¯¼å‡ºä¿¡æ¯
        keras_model = onnx2tf.convert(
            input_onnx_file_path=f_onnx,  # è¾“å…¥ ONNX æ–‡ä»¶è·¯å¾„
            output_folder_path=str(f),  # è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
            not_use_onnxsim=True,  # ä¸ä½¿ç”¨ ONNX ç®€åŒ–
            verbosity="error",  # è®¾ç½®æ—¥å¿—è¯¦ç»†ç¨‹åº¦
            output_integer_quantized_tflite=self.args.int8,  # æ˜¯å¦è¾“å‡º INT8 TFLite æ¨¡å‹
            quant_type="per-tensor",  # é‡åŒ–ç±»å‹
            custom_input_op_name_np_data_path=np_data,  # è‡ªå®šä¹‰è¾“å…¥æ“ä½œåç§°çš„ NumPy æ•°æ®è·¯å¾„
            disable_group_convolution=True,  # ç¦ç”¨åˆ†ç»„å·ç§¯ä»¥å…¼å®¹æ¨¡å‹
            enable_batchmatmul_unfold=True,  # å¯ç”¨æ‰¹é‡çŸ©é˜µå±•å¼€ä»¥å…¼å®¹æ¨¡å‹
        )
        yaml_save(f / "metadata.yaml", self.metadata)  # æ·»åŠ å…ƒæ•°æ® YAML

        # Remove/rename TFLite models
        if self.args.int8:
            tmp_file.unlink(missing_ok=True)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            for file in f.rglob("*_dynamic_range_quant.tflite"):  # éå†åŠ¨æ€èŒƒå›´é‡åŒ–æ–‡ä»¶
                file.rename(file.with_name(file.stem.replace("_dynamic_range_quant", "_int8") + file.suffix))  # é‡å‘½åæ–‡ä»¶
            for file in f.rglob("*_integer_quant_with_int16_act.tflite"):  # éå†é¢å¤–çš„ FP16 æ¿€æ´» TFLite æ–‡ä»¶
                file.unlink()  # åˆ é™¤é¢å¤–çš„æ–‡ä»¶

        # Add TFLite metadata
        for file in f.rglob("*.tflite"):  # éå†æ‰€æœ‰ TFLite æ–‡ä»¶
            f.unlink() if "quant_with_int16_act.tflite" in str(f) else self._add_tflite_metadata(file)  # æ·»åŠ å…ƒæ•°æ®

        return str(f), None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_pb(self, keras_model, prefix=colorstr("TensorFlow GraphDef:")):
        """YOLO TensorFlow GraphDef *.pb export https://github.com/leimao/Frozen_Graph_TensorFlow."""  # YOLO TensorFlow GraphDef å¯¼å‡º
        import tensorflow as tf  # noqa  # å¯¼å…¥ TensorFlow åº“
        from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2  # noqa  # å¯¼å…¥è½¬æ¢å‡½æ•°

        LOGGER.info(f"\n{prefix} starting export with tensorflow {tf.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        f = self.file.with_suffix(".pb")  # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„

        m = tf.function(lambda x: keras_model(x))  # å®Œæ•´æ¨¡å‹
        m = m.get_concrete_function(tf.TensorSpec(keras_model.inputs[0].shape, keras_model.inputs[0].dtype))  # è·å–å…·ä½“å‡½æ•°
        frozen_func = convert_variables_to_constants_v2(m)  # è½¬æ¢ä¸ºå¸¸é‡
        frozen_func.graph.as_graph_def()  # è·å–å›¾å½¢å®šä¹‰
        tf.io.write_graph(graph_or_graph_def=frozen_func.graph, logdir=str(f.parent), name=f.name, as_text=False)  # å†™å…¥å›¾å½¢
        return f, None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_tflite(self, keras_model, nms, agnostic_nms, prefix=colorstr("TensorFlow Lite:")):
        """YOLO TensorFlow Lite export."""  # YOLO TensorFlow Lite å¯¼å‡º
        # BUG https://github.com/ultralytics/ultralytics/issues/13436
        import tensorflow as tf  # noqa  # å¯¼å…¥ TensorFlow åº“

        LOGGER.info(f"\n{prefix} starting export with tensorflow {tf.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        saved_model = Path(str(self.file).replace(self.file.suffix, "_saved_model"))  # è®¾ç½®ä¿å­˜æ¨¡å‹è·¯å¾„
        if self.args.int8:
            f = saved_model / f"{self.file.stem}_int8.tflite"  # è®¾ç½® INT8 è¾“å‡ºæ–‡ä»¶è·¯å¾„
        elif self.args.half:
            f = saved_model / f"{self.file.stem}_float16.tflite"  # è®¾ç½® FP16 è¾“å‡ºæ–‡ä»¶è·¯å¾„
        else:
            f = saved_model / f"{self.file.stem}_float32.tflite"  # è®¾ç½® FP32 è¾“å‡ºæ–‡ä»¶è·¯å¾„
        return str(f), None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_edgetpu(self, tflite_model="", prefix=colorstr("Edge TPU:")):
        """YOLO Edge TPU export https://coral.ai/docs/edgetpu/models-intro/."""  # YOLO Edge TPU å¯¼å‡º
        LOGGER.warning(f"{prefix} WARNING âš ï¸ Edge TPU known bug https://github.com/ultralytics/ultralytics/issues/1185")  # æ—¥å¿—è®°å½•è­¦å‘Š

        cmd = "edgetpu_compiler --version"  # æ£€æŸ¥ Edge TPU ç¼–è¯‘å™¨ç‰ˆæœ¬
        help_url = "https://coral.ai/docs/edgetpu/compiler/"  # Edge TPU ç¼–è¯‘å™¨å¸®åŠ©é“¾æ¥
        assert LINUX, f"export only supported on Linux. See {help_url}"  # ç¡®ä¿åœ¨ Linux ä¸Šå¯¼å‡º
        if subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True).returncode != 0:
            LOGGER.info(f"\n{prefix} export requires Edge TPU compiler. Attempting install from {help_url}")  # æ—¥å¿—è®°å½•å®‰è£…ä¿¡æ¯
            for c in (
                "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -",  # æ·»åŠ  GPG å¯†é’¥
                'echo "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main" | '
                "sudo tee /etc/apt/sources.list.d/coral-edgetpu.list",  # æ·»åŠ  Edge TPU æº
                "sudo apt-get update",  # æ›´æ–°åŒ…åˆ—è¡¨
                "sudo apt-get install edgetpu-compiler",  # å®‰è£… Edge TPU ç¼–è¯‘å™¨
            ):
                subprocess.run(c if is_sudo_available() else c.replace("sudo ", ""), shell=True, check=True)  # æ‰§è¡Œå®‰è£…å‘½ä»¤
        ver = subprocess.run(cmd, shell=True, capture_output=True, check=True).stdout.decode().split()[-1]  # è·å– Edge TPU ç¼–è¯‘å™¨ç‰ˆæœ¬

        LOGGER.info(f"\n{prefix} starting export with Edge TPU compiler {ver}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        f = str(tflite_model).replace(".tflite", "_edgetpu.tflite")  # è®¾ç½® Edge TPU æ¨¡å‹æ–‡ä»¶å

        cmd = (
            "edgetpu_compiler "
            f'--out_dir "{Path(f).parent}" '  # è®¾ç½®è¾“å‡ºç›®å½•
            "--show_operations "  # æ˜¾ç¤ºæ“ä½œ
            "--search_delegate "  # æœç´¢å§”æ‰˜
            "--delegate_search_step 30 "  # å§”æ‰˜æœç´¢æ­¥é•¿
            "--timeout_sec 180 "  # è®¾ç½®è¶…æ—¶æ—¶é—´
            f'"{tflite_model}"'  # è¾“å…¥ TFLite æ¨¡å‹
        )
        LOGGER.info(f"{prefix} running '{cmd}'")  # æ—¥å¿—è®°å½•è¿è¡Œå‘½ä»¤
        subprocess.run(cmd, shell=True)  # æ‰§è¡Œå‘½ä»¤
        self._add_tflite_metadata(f)  # æ·»åŠ  TFLite å…ƒæ•°æ®
        return f, None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_tfjs(self, prefix=colorstr("TensorFlow.js:")):
        """YOLO TensorFlow.js export."""  # YOLO TensorFlow.js å¯¼å‡º
        check_requirements("tensorflowjs")  # æ£€æŸ¥ TensorFlow.js ä¾èµ–
        if ARM64:
            # Fix error: `np.object` was a deprecated alias for the builtin `object` when exporting to TF.js on ARM64
            check_requirements("numpy==1.23.5")  # æ£€æŸ¥ NumPy ç‰ˆæœ¬
        import tensorflow as tf  # å¯¼å…¥ TensorFlow åº“
        import tensorflowjs as tfjs  # noqa  # å¯¼å…¥ TensorFlow.js åº“

        LOGGER.info(f"\n{prefix} starting export with tensorflowjs {tfjs.__version__}...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯
        f = str(self.file).replace(self.file.suffix, "_web_model")  # è®¾ç½® JS ç›®å½•
        f_pb = str(self.file.with_suffix(".pb"))  # è®¾ç½® *.pb è·¯å¾„

        gd = tf.Graph().as_graph_def()  # TF å›¾å½¢å®šä¹‰
        with open(f_pb, "rb") as file:
            gd.ParseFromString(file.read())  # ä»æ–‡ä»¶è¯»å–å›¾å½¢å®šä¹‰
        outputs = ",".join(gd_outputs(gd))  # è·å–è¾“å‡ºèŠ‚ç‚¹åç§°
        LOGGER.info(f"\n{prefix} output node names: {outputs}")  # æ—¥å¿—è®°å½•è¾“å‡ºèŠ‚ç‚¹åç§°

        quantization = "--quantize_float16" if self.args.half else "--quantize_uint8" if self.args.int8 else ""  # è®¾ç½®é‡åŒ–å‚æ•°
        with spaces_in_path(f_pb) as fpb_, spaces_in_path(f) as f_:  # å¯¼å‡ºå™¨æ— æ³•å¤„ç†è·¯å¾„ä¸­çš„ç©ºæ ¼
            cmd = (
                "tensorflowjs_converter "
                f'--input_format=tf_frozen_model {quantization} --output_node_names={outputs} "{fpb_}" "{f_}"'  # è®¾ç½®è½¬æ¢å‘½ä»¤
            )
            LOGGER.info(f"{prefix} running '{cmd}'")  # æ—¥å¿—è®°å½•è¿è¡Œå‘½ä»¤
            subprocess.run(cmd, shell=True)  # æ‰§è¡Œå‘½ä»¤

        if " " in f:
            LOGGER.warning(f"{prefix} WARNING âš ï¸ your model may not work correctly with spaces in path '{f}'.")  # æ—¥å¿—è®°å½•è·¯å¾„ä¸­çš„ç©ºæ ¼è­¦å‘Š

        # Add metadata
        yaml_save(Path(f) / "metadata.yaml", self.metadata)  # æ·»åŠ å…ƒæ•°æ® YAML
        return f, None  # è¿”å›æ–‡ä»¶è·¯å¾„

    @try_export
    def export_rknn(self, prefix=colorstr("RKNN:")):
        """YOLO RKNN model export."""  # YOLO RKNN æ¨¡å‹å¯¼å‡º
        LOGGER.info(f"\n{prefix} starting export with rknn-toolkit2...")  # æ—¥å¿—è®°å½•å¯¼å‡ºä¿¡æ¯

        check_requirements("rknn-toolkit2")  # æ£€æŸ¥ RKNN å·¥å…·åŒ…ä¾èµ–
        if IS_COLAB:
            # Prevent 'exit' from closing the notebook https://github.com/airockchip/rknn-toolkit2/issues/259
            import builtins

            builtins.exit = lambda: None  # é˜²æ­¢é€€å‡ºå…³é—­ç¬”è®°æœ¬

        from rknn.api import RKNN  # å¯¼å…¥ RKNN API

        f, _ = self.export_onnx()  # å¯¼å‡º ONNX æ¨¡å‹
        export_path = Path(f"{Path(f).stem}_rknn_model")  # è®¾ç½®å¯¼å‡ºè·¯å¾„
        export_path.mkdir(exist_ok=True)  # åˆ›å»ºå¯¼å‡ºç›®å½•

        rknn = RKNN(verbose=False)  # åˆ›å»º RKNN å®ä¾‹
        rknn.config(mean_values=[[0, 0, 0]], std_values=[[255, 255, 255]], target_platform=self.args.name)  # è®¾ç½®å‡å€¼å’Œæ ‡å‡†å·®
        rknn.load_onnx(model=f)  # åŠ è½½ ONNX æ¨¡å‹
        rknn.build(do_quantization=False)  # æ„å»º RKNN æ¨¡å‹ï¼Œä¸è¿›è¡Œé‡åŒ–
        f = f.replace(".onnx", f"-{self.args.name}.rknn")  # è®¾ç½® RKNN æ–‡ä»¶å
        rknn.export_rknn(f"{export_path / f}")  # å¯¼å‡º RKNN æ¨¡å‹
        yaml_save(export_path / "metadata.yaml", self.metadata)  # æ·»åŠ å…ƒæ•°æ® YAML
        return export_path, None  # è¿”å›å¯¼å‡ºè·¯å¾„

    @try_export
    def export_imx(self, prefix=colorstr("IMX:")):
        """YOLO IMX export."""  # YOLO IMX å¯¼å‡º
        gptq = False  # è®¾ç½® gptq ä¸º Falseï¼Œè¡¨ç¤ºä¸ä½¿ç”¨æ¢¯åº¦åè®­ç»ƒé‡åŒ–
        assert LINUX, (  # ç¡®ä¿åœ¨ Linux ç³»ç»Ÿä¸Šè¿è¡Œ
            "export only supported on Linux. See https://developer.aitrios.sony-semicon.com/en/raspberrypi-ai-camera/documentation/imx500-converter"
        )
        if getattr(self.model, "end2end", False):  # æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸ºç«¯åˆ°ç«¯æ¨¡å‹
            raise ValueError("IMX export is not supported for end2end models.")  # ä¸æ”¯æŒç«¯åˆ°ç«¯æ¨¡å‹çš„å¯¼å‡º
        if "C2f" not in self.model.__str__():  # æ£€æŸ¥æ¨¡å‹å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å« "C2f"
            raise ValueError("IMX export is only supported for YOLOv8n detection models")  # ä»…æ”¯æŒ YOLOv8n æ£€æµ‹æ¨¡å‹çš„å¯¼å‡º
        check_requirements(("model-compression-toolkit==2.1.1", "sony-custom-layers==0.2.0", "tensorflow==2.12.0"))  # æ£€æŸ¥ä¾èµ–é¡¹
        check_requirements("imx500-converter[pt]==3.14.3")  # æ£€æŸ¥ imx500-converter çš„ä¾èµ–é¡¹
    
        import model_compression_toolkit as mct  # å¯¼å…¥æ¨¡å‹å‹ç¼©å·¥å…·åŒ…
        import onnx  # å¯¼å…¥ ONNX åº“
        from sony_custom_layers.pytorch.object_detection.nms import multiclass_nms  # ä»è‡ªå®šä¹‰å±‚å¯¼å…¥å¤šç±»éæå¤§å€¼æŠ‘åˆ¶
    
        LOGGER.info(f"\n{prefix} starting export with model_compression_toolkit {mct.__version__}...")  # è®°å½•å¯¼å‡ºå¼€å§‹çš„ä¿¡æ¯
    
        try:
            out = subprocess.run(
                ["java", "--version"], check=True, capture_output=True
            )  # æ£€æŸ¥ Java ç‰ˆæœ¬ï¼Œimx500-converter éœ€è¦ Java 17
            if "openjdk 17" not in str(out.stdout):  # å¦‚æœè¾“å‡ºä¸åŒ…å« OpenJDK 17
                raise FileNotFoundError  # æŠ›å‡ºæ–‡ä»¶æœªæ‰¾åˆ°å¼‚å¸¸
        except FileNotFoundError:
            c = ["apt", "install", "-y", "openjdk-17-jdk", "openjdk-17-jre"]  # å®‰è£… OpenJDK 17
            if is_sudo_available():  # æ£€æŸ¥æ˜¯å¦æœ‰ sudo æƒé™
                c.insert(0, "sudo")  # å¦‚æœæœ‰ï¼Œæ·»åŠ  sudo
            subprocess.run(c, check=True)  # æ‰§è¡Œå®‰è£…å‘½ä»¤
    
        def representative_dataset_gen(dataloader=self.get_int8_calibration_dataloader(prefix)):  # ç”Ÿæˆä»£è¡¨æ€§æ•°æ®é›†
            for batch in dataloader:  # éå†æ•°æ®åŠ è½½å™¨ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡
                img = batch["img"]  # è·å–å›¾åƒ
                img = img / 255.0  # æ ‡å‡†åŒ–å›¾åƒ
                yield [img]  # ç”Ÿæˆæ ‡å‡†åŒ–åçš„å›¾åƒ
    
        tpc = mct.get_target_platform_capabilities(  # è·å–ç›®æ ‡å¹³å°èƒ½åŠ›
            fw_name="pytorch", target_platform_name="imx500", target_platform_version="v1"
        )
    
        config = mct.core.CoreConfig(  # é…ç½®æ ¸å¿ƒè®¾ç½®
            mixed_precision_config=mct.core.MixedPrecisionQuantizationConfig(num_of_images=10),  # è®¾ç½®æ··åˆç²¾åº¦é…ç½®
            quantization_config=mct.core.QuantizationConfig(concat_threshold_update=True),  # è®¾ç½®é‡åŒ–é…ç½®
        )
    
        resource_utilization = mct.core.ResourceUtilization(weights_memory=3146176 * 0.76)  # è®¾ç½®èµ„æºåˆ©ç”¨ç‡
    
        quant_model = (  # é‡åŒ–æ¨¡å‹
            mct.gptq.pytorch_gradient_post_training_quantization(  # æ‰§è¡ŒåŸºäºæ¢¯åº¦çš„åè®­ç»ƒé‡åŒ–
                model=self.model,
                representative_data_gen=representative_dataset_gen,
                target_resource_utilization=resource_utilization,
                gptq_config=mct.gptq.get_pytorch_gptq_config(n_epochs=1000, use_hessian_based_weights=False),
                core_config=config,
                target_platform_capabilities=tpc,
            )[0]
            if gptq  # å¦‚æœ gptq ä¸º True
            else mct.ptq.pytorch_post_training_quantization(  # æ‰§è¡Œåè®­ç»ƒé‡åŒ–
                in_module=self.model,
                representative_data_gen=representative_dataset_gen,
                target_resource_utilization=resource_utilization,
                core_config=config,
                target_platform_capabilities=tpc,
            )[0]
        )
    
        class NMSWrapper(torch.nn.Module):  # å®šä¹‰ NMS åŒ…è£…ç±»
            def __init__(self, model: torch.nn.Module, score_threshold: float = 0.001, iou_threshold: float = 0.7, max_detections: int = 300):
                """
                Wrapping PyTorch Module with multiclass_nms layer from sony_custom_layers.
    
                Args:
                    model (nn.Module): Model instance.  # æ¨¡å‹å®ä¾‹
                    score_threshold (float): Score threshold for non-maximum suppression.  # éæå¤§å€¼æŠ‘åˆ¶çš„åˆ†æ•°é˜ˆå€¼
                    iou_threshold (float): Intersection over union threshold for non-maximum suppression.  # éæå¤§å€¼æŠ‘åˆ¶çš„äº¤å¹¶æ¯”é˜ˆå€¼
                    max_detections (float): The number of detections to return.  # è¿”å›çš„æ£€æµ‹æ•°é‡
                """
                super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
                self.model = model  # ä¿å­˜æ¨¡å‹
                self.score_threshold = score_threshold  # ä¿å­˜åˆ†æ•°é˜ˆå€¼
                self.iou_threshold = iou_threshold  # ä¿å­˜äº¤å¹¶æ¯”é˜ˆå€¼
                self.max_detections = max_detections  # ä¿å­˜æœ€å¤§æ£€æµ‹æ•°é‡
    
            def forward(self, images):  # å‰å‘ä¼ æ’­
                # model inference
                outputs = self.model(images)  # æ¨¡å‹æ¨ç†
    
                boxes = outputs[0]  # è·å–è¾¹ç•Œæ¡†
                scores = outputs[1]  # è·å–åˆ†æ•°
                nms = multiclass_nms(  # æ‰§è¡Œå¤šç±»éæå¤§å€¼æŠ‘åˆ¶
                    boxes=boxes,
                    scores=scores,
                    score_threshold=self.score_threshold,
                    iou_threshold=self.iou_threshold,
                    max_detections=self.max_detections,
                )
                return nms  # è¿”å› NMS ç»“æœ
    
        quant_model = NMSWrapper(  # åŒ…è£…é‡åŒ–æ¨¡å‹
            model=quant_model,
            score_threshold=self.args.conf or 0.001,  # ä½¿ç”¨é…ç½®ä¸­çš„åˆ†æ•°é˜ˆå€¼
            iou_threshold=self.args.iou,  # ä½¿ç”¨é…ç½®ä¸­çš„äº¤å¹¶æ¯”é˜ˆå€¼
            max_detections=self.args.max_det,  # ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§æ£€æµ‹æ•°é‡
        ).to(self.device)  # ç§»åŠ¨åˆ°è®¾å¤‡ä¸Š
    
        f = Path(str(self.file).replace(self.file.suffix, "_imx_model"))  # åˆ›å»ºä¿å­˜æ¨¡å‹è·¯å¾„
        f.mkdir(exist_ok=True)  # åˆ›å»ºç›®å½•
        onnx_model = f / Path(str(self.file.name).replace(self.file.suffix, "_imx.onnx"))  # è®¾ç½® ONNX æ¨¡å‹è·¯å¾„
        mct.exporter.pytorch_export_model(  # å¯¼å‡º PyTorch æ¨¡å‹
            model=quant_model, save_model_path=onnx_model, repr_dataset=representative_dataset_gen
        )
    
        model_onnx = onnx.load(onnx_model)  # åŠ è½½ ONNX æ¨¡å‹
        for k, v in self.metadata.items():  # éå†å…ƒæ•°æ®
            meta = model_onnx.metadata_props.add()  # æ·»åŠ å…ƒæ•°æ®å±æ€§
            meta.key, meta.value = k, str(v)  # è®¾ç½®å…ƒæ•°æ®é”®å€¼å¯¹
    
        onnx.save(model_onnx, onnx_model)  # ä¿å­˜ ONNX æ¨¡å‹
    
        subprocess.run(  # æ‰§è¡Œ imxconv-pt å‘½ä»¤
            ["imxconv-pt", "-i", str(onnx_model), "-o", str(f), "--no-input-persistency", "--overwrite-output"],
            check=True,
        )
    
        # Needed for imx models.
        with open(f / "labels.txt", "w") as file:  # åˆ›å»ºæ ‡ç­¾æ–‡ä»¶
            file.writelines([f"{name}\n" for _, name in self.model.names.items()])  # å†™å…¥æ¨¡å‹åç§°
    
        return f, None  # è¿”å›æ¨¡å‹è·¯å¾„å’Œ None
    
    def _add_tflite_metadata(self, file):  # æ·»åŠ  TFLite æ¨¡å‹çš„å…ƒæ•°æ®
        """Add metadata to *.tflite models per https://www.tensorflow.org/lite/models/convert/metadata."""  # æ ¹æ®æ–‡æ¡£æ·»åŠ å…ƒæ•°æ®
        import flatbuffers  # å¯¼å…¥ flatbuffers åº“
    
        try:
            # TFLite Support bug https://github.com/tensorflow/tflite-support/issues/954#issuecomment-2108570845
            from tensorflow_lite_support.metadata import metadata_schema_py_generated as schema  # noqa
            from tensorflow_lite_support.metadata.python import metadata  # noqa
        except ImportError:  # ARM64 ç³»ç»Ÿå¯èƒ½æ²¡æœ‰ 'tensorflow_lite_support' åŒ…
            from tflite_support import metadata  # noqa
            from tflite_support import metadata_schema_py_generated as schema  # noqa
    
        # Create model info
        model_meta = schema.ModelMetadataT()  # åˆ›å»ºæ¨¡å‹å…ƒæ•°æ®
        model_meta.name = self.metadata["description"]  # è®¾ç½®æ¨¡å‹åç§°
        model_meta.version = self.metadata["version"]  # è®¾ç½®æ¨¡å‹ç‰ˆæœ¬
        model_meta.author = self.metadata["author"]  # è®¾ç½®æ¨¡å‹ä½œè€…
        model_meta.license = self.metadata["license"]  # è®¾ç½®æ¨¡å‹è®¸å¯è¯
    
        # Label file
        tmp_file = Path(file).parent / "temp_meta.txt"  # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with open(tmp_file, "w") as f:  # æ‰“å¼€ä¸´æ—¶æ–‡ä»¶ä»¥å†™å…¥
            f.write(str(self.metadata))  # å†™å…¥å…ƒæ•°æ®
    
        label_file = schema.AssociatedFileT()  # åˆ›å»ºå…³è”æ–‡ä»¶
        label_file.name = tmp_file.name  # è®¾ç½®æ–‡ä»¶å
        label_file.type = schema.AssociatedFileType.TENSOR_AXIS_LABELS  # è®¾ç½®æ–‡ä»¶ç±»å‹
    
        # Create input info
        input_meta = schema.TensorMetadataT()  # åˆ›å»ºè¾“å…¥å…ƒæ•°æ®
        input_meta.name = "image"  # è®¾ç½®è¾“å…¥åç§°
        input_meta.description = "Input image to be detected."  # è®¾ç½®è¾“å…¥æè¿°
        input_meta.content = schema.ContentT()  # åˆ›å»ºå†…å®¹å¯¹è±¡
        input_meta.content.contentProperties = schema.ImagePropertiesT()  # è®¾ç½®å†…å®¹å±æ€§
        input_meta.content.contentProperties.colorSpace = schema.ColorSpaceType.RGB  # è®¾ç½®é¢œè‰²ç©ºé—´
        input_meta.content.contentPropertiesType = schema.ContentProperties.ImageProperties  # è®¾ç½®å†…å®¹å±æ€§ç±»å‹
    
        # Create output info
        output1 = schema.TensorMetadataT()  # åˆ›å»ºè¾“å‡ºå…ƒæ•°æ®
        output1.name = "output"  # è®¾ç½®è¾“å‡ºåç§°
        output1.description = "Coordinates of detected objects, class labels, and confidence score"  # è®¾ç½®è¾“å‡ºæè¿°
        output1.associatedFiles = [label_file]  # å…³è”æ ‡ç­¾æ–‡ä»¶
        if self.model.task == "segment":  # å¦‚æœæ¨¡å‹ä»»åŠ¡æ˜¯åˆ†å‰²
            output2 = schema.TensorMetadataT()  # åˆ›å»ºç¬¬äºŒä¸ªè¾“å‡ºå…ƒæ•°æ®
            output2.name = "output"  # è®¾ç½®è¾“å‡ºåç§°
            output2.description = "Mask protos"  # è®¾ç½®è¾“å‡ºæè¿°
            output2.associatedFiles = [label_file]  # å…³è”æ ‡ç­¾æ–‡ä»¶
    
        # Create subgraph info
        subgraph = schema.SubGraphMetadataT()  # åˆ›å»ºå­å›¾å…ƒæ•°æ®
        subgraph.inputTensorMetadata = [input_meta]  # è®¾ç½®è¾“å…¥å¼ é‡å…ƒæ•°æ®
        subgraph.outputTensorMetadata = [output1, output2] if self.model.task == "segment" else [output1]  # è®¾ç½®è¾“å‡ºå¼ é‡å…ƒæ•°æ®
        model_meta.subgraphMetadata = [subgraph]  # è®¾ç½®æ¨¡å‹å…ƒæ•°æ®çš„å­å›¾å…ƒæ•°æ®
    
        b = flatbuffers.Builder(0)  # åˆ›å»º flatbuffers æ„å»ºå™¨
        b.Finish(model_meta.Pack(b), metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)  # å®Œæˆæ„å»º
        metadata_buf = b.Output()  # è·å–è¾“å‡ºç¼“å†²åŒº
    
        populator = metadata.MetadataPopulator.with_model_file(str(file))  # åˆ›å»ºå…ƒæ•°æ®å¡«å……å™¨
        populator.load_metadata_buffer(metadata_buf)  # åŠ è½½å…ƒæ•°æ®ç¼“å†²åŒº
        populator.load_associated_files([str(tmp_file)])  # åŠ è½½å…³è”æ–‡ä»¶
        populator.populate()  # å¡«å……å…ƒæ•°æ®
        tmp_file.unlink()  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    
    def _pipeline_coreml(self, model, weights_dir=None, prefix=colorstr("CoreML Pipeline:")):  # YOLO CoreML ç®¡é“
        """YOLO CoreML pipeline."""  # YOLO CoreML ç®¡é“
        import coremltools as ct  # noqa
    
        LOGGER.info(f"{prefix} starting pipeline with coremltools {ct.__version__}...")  # è®°å½•ç®¡é“å¼€å§‹çš„ä¿¡æ¯
        _, _, h, w = list(self.im.shape)  # BCHW
    
        # Output shapes
        spec = model.get_spec()  # è·å–æ¨¡å‹è§„æ ¼
        out0, out1 = iter(spec.description.output)  # è·å–è¾“å‡º
        if MACOS:
            from PIL import Image  # å¯¼å…¥å›¾åƒå¤„ç†åº“
    
            img = Image.new("RGB", (w, h))  # åˆ›å»ºæ–°çš„ RGB å›¾åƒ
            out = model.predict({"image": img})  # è¿›è¡Œé¢„æµ‹
            out0_shape = out[out0.name].shape  # è·å–ç¬¬ä¸€ä¸ªè¾“å‡ºçš„å½¢çŠ¶
            out1_shape = out[out1.name].shape  # è·å–ç¬¬äºŒä¸ªè¾“å‡ºçš„å½¢çŠ¶
        else:  # linux å’Œ windows æ— æ³•è¿è¡Œ model.predict()ï¼Œä» PyTorch æ¨¡å‹è¾“å‡º y è·å–å¤§å°
            out0_shape = self.output_shape[2], self.output_shape[1] - 4  # è·å–ç¬¬ä¸€ä¸ªè¾“å‡ºçš„å½¢çŠ¶
            out1_shape = self.output_shape[2], 4  # è·å–ç¬¬äºŒä¸ªè¾“å‡ºçš„å½¢çŠ¶
    
        # Checks
        names = self.metadata["names"]  # è·å–æ¨¡å‹åç§°
        nx, ny = spec.description.input[0].type.imageType.width, spec.description.input[0].type.imageType.height  # è·å–è¾“å…¥å›¾åƒçš„å®½é«˜
        _, nc = out0_shape  # è·å–é”šç‚¹æ•°é‡å’Œç±»åˆ«æ•°é‡
        assert len(names) == nc, f"{len(names)} names found for nc={nc}"  # æ£€æŸ¥åç§°æ•°é‡ä¸ç±»åˆ«æ•°é‡æ˜¯å¦ä¸€è‡´
    
        # Define output shapes (missing)
        out0.type.multiArrayType.shape[:] = out0_shape  # è®¾ç½®ç¬¬ä¸€ä¸ªè¾“å‡ºçš„å½¢çŠ¶
        out1.type.multiArrayType.shape[:] = out1_shape  # è®¾ç½®ç¬¬äºŒä¸ªè¾“å‡ºçš„å½¢çŠ¶
    
        # Model from spec
        model = ct.models.MLModel(spec, weights_dir=weights_dir)  # åˆ›å»º CoreML æ¨¡å‹
    
        # 3. Create NMS protobuf
        nms_spec = ct.proto.Model_pb2.Model()  # åˆ›å»º NMS protobuf æ¨¡å‹
        nms_spec.specificationVersion = 5  # è®¾ç½®è§„æ ¼ç‰ˆæœ¬
        for i in range(2):
            decoder_output = model._spec.description.output[i].SerializeToString()  # åºåˆ—åŒ–è¾“å‡º
            nms_spec.description.input.add()  # æ·»åŠ è¾“å…¥
            nms_spec.description.input[i].ParseFromString(decoder_output)  # è§£æè¾“å…¥
            nms_spec.description.output.add()  # æ·»åŠ è¾“å‡º
            nms_spec.description.output[i].ParseFromString(decoder_output)  # è§£æè¾“å‡º
    
        nms_spec.description.output[0].name = "confidence"  # è®¾ç½®ç¬¬ä¸€ä¸ªè¾“å‡ºåç§°ä¸º confidence
        nms_spec.description.output[1].name = "coordinates"  # è®¾ç½®ç¬¬äºŒä¸ªè¾“å‡ºåç§°ä¸º coordinates
    
        output_sizes = [nc, 4]  # å®šä¹‰è¾“å‡ºå¤§å°
        for i in range(2):
            ma_type = nms_spec.description.output[i].type.multiArrayType  # è·å–å¤šç»´æ•°ç»„ç±»å‹
            ma_type.shapeRange.sizeRanges.add()  # æ·»åŠ å¤§å°èŒƒå›´
            ma_type.shapeRange.sizeRanges[0].lowerBound = 0  # è®¾ç½®ä¸‹ç•Œ
            ma_type.shapeRange.sizeRanges[0].upperBound = -1  # è®¾ç½®ä¸Šç•Œ
            ma_type.shapeRange.sizeRanges.add()  # æ·»åŠ å¤§å°èŒƒå›´
            ma_type.shapeRange.sizeRanges[1].lowerBound = output_sizes[i]  # è®¾ç½®ä¸‹ç•Œ
            ma_type.shapeRange.sizeRanges[1].upperBound = output_sizes[i]  # è®¾ç½®ä¸Šç•Œ
            del ma_type.shape[:]  # åˆ é™¤åŸæœ‰å½¢çŠ¶
    
        nms = nms_spec.nonMaximumSuppression  # è·å–éæå¤§å€¼æŠ‘åˆ¶å¯¹è±¡
        nms.confidenceInputFeatureName = out0.name  # è®¾ç½®ç½®ä¿¡åº¦è¾“å…¥ç‰¹å¾åç§°
        nms.coordinatesInputFeatureName = out1.name  # è®¾ç½®åæ ‡è¾“å…¥ç‰¹å¾åç§°
        nms.confidenceOutputFeatureName = "confidence"  # è®¾ç½®ç½®ä¿¡åº¦è¾“å‡ºç‰¹å¾åç§°
        nms.coordinatesOutputFeatureName = "coordinates"  # è®¾ç½®åæ ‡è¾“å‡ºç‰¹å¾åç§°
        nms.iouThresholdInputFeatureName = "iouThreshold"  # è®¾ç½® IoU é˜ˆå€¼è¾“å…¥ç‰¹å¾åç§°
        nms.confidenceThresholdInputFeatureName = "confidenceThreshold"  # è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼è¾“å…¥ç‰¹å¾åç§°
        nms.iouThreshold = self.args.iou  # è®¾ç½® IoU é˜ˆå€¼
        nms.confidenceThreshold = self.args.conf  # è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼
        nms.pickTop.perClass = True  # æ¯ä¸ªç±»åˆ«é€‰æ‹©å‰ N ä¸ª
        nms.stringClassLabels.vector.extend(names.values())  # æ·»åŠ ç±»åˆ«æ ‡ç­¾
        nms_model = ct.models.MLModel(nms_spec)  # åˆ›å»º NMS æ¨¡å‹
    
        # 4. Pipeline models together
        pipeline = ct.models.pipeline.Pipeline(  # åˆ›å»ºç®¡é“æ¨¡å‹
            input_features=[
                ("image", ct.models.datatypes.Array(3, ny, nx)),  # è¾“å…¥ç‰¹å¾
                ("iouThreshold", ct.models.datatypes.Double()),  # IoU é˜ˆå€¼ç‰¹å¾
                ("confidenceThreshold", ct.models.datatypes.Double()),  # ç½®ä¿¡åº¦é˜ˆå€¼ç‰¹å¾
            ],
            output_features=["confidence", "coordinates"],  # è¾“å‡ºç‰¹å¾
        )
        pipeline.add_model(model)  # æ·»åŠ æ¨¡å‹
        pipeline.add_model(nms_model)  # æ·»åŠ  NMS æ¨¡å‹
    
        # Correct datatypes
        pipeline.spec.description.input[0].ParseFromString(model._spec.description.input[0].SerializeToString())  # è§£æè¾“å…¥ç‰¹å¾
        pipeline.spec.description.output[0].ParseFromString(nms_model._spec.description.output[0].SerializeToString())  # è§£æè¾“å‡ºç‰¹å¾
        pipeline.spec.description.output[1].ParseFromString(nms_model._spec.description.output[1].SerializeToString())  # è§£æè¾“å‡ºç‰¹å¾
    
        # Update metadata
        pipeline.spec.specificationVersion = 5  # æ›´æ–°è§„æ ¼ç‰ˆæœ¬
        pipeline.spec.description.metadata.userDefined.update(  # æ›´æ–°ç”¨æˆ·å®šä¹‰çš„å…ƒæ•°æ®
            {"IoU threshold": str(nms.iouThreshold), "Confidence threshold": str(nms.confidenceThreshold)}
        )
    
        # Save the model
        model = ct.models.MLModel(pipeline.spec, weights_dir=weights_dir)  # ä¿å­˜æ¨¡å‹
        model.input_description["image"] = "Input image"  # è®¾ç½®è¾“å…¥æè¿°
        model.input_description["iouThreshold"] = f"(optional) IoU threshold override (default: {nms.iouThreshold})"  # è®¾ç½® IoU é˜ˆå€¼æè¿°
        model.input_description["confidenceThreshold"] = (  # è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼æè¿°
            f"(optional) Confidence threshold override (default: {nms.confidenceThreshold})"
        )
        model.output_description["confidence"] = 'Boxes Ã— Class confidence (see user-defined metadata "classes")'  # è®¾ç½®ç½®ä¿¡åº¦è¾“å‡ºæè¿°
        model.output_description["coordinates"] = "Boxes Ã— [x, y, width, height] (relative to image size)"  # è®¾ç½®åæ ‡è¾“å‡ºæè¿°
        LOGGER.info(f"{prefix} pipeline success")  # è®°å½•ç®¡é“æˆåŠŸçš„ä¿¡æ¯
        return model  # è¿”å›æ¨¡å‹
    
    def add_callback(self, event: str, callback):  # æ·»åŠ å›è°ƒå‡½æ•°
        """Appends the given callback."""  # é™„åŠ ç»™å®šçš„å›è°ƒ
        self.callbacks[event].append(callback)  # å°†å›è°ƒæ·»åŠ åˆ°äº‹ä»¶åˆ—è¡¨ä¸­
    
    def run_callbacks(self, event: str):  # è¿è¡ŒæŒ‡å®šäº‹ä»¶çš„æ‰€æœ‰å›è°ƒ
        """Execute all callbacks for a given event."""  # æ‰§è¡Œç»™å®šäº‹ä»¶çš„æ‰€æœ‰å›è°ƒ
        for callback in self.callbacks.get(event, []):  # éå†äº‹ä»¶çš„æ‰€æœ‰å›è°ƒ
            callback(self)  # æ‰§è¡Œå›è°ƒ

class IOSDetectModel(torch.nn.Module):  # å®šä¹‰ IOSDetectModel ç±»ï¼Œç»§æ‰¿è‡ª torch.nn.Module
    """Wrap an Ultralytics YOLO model for Apple iOS CoreML export."""  # ä¸º Apple iOS CoreML å¯¼å‡ºåŒ…è£… Ultralytics YOLO æ¨¡å‹

    def __init__(self, model, im):  # åˆå§‹åŒ– IOSDetectModel ç±»ï¼Œæ¥å—ä¸€ä¸ª YOLO æ¨¡å‹å’Œç¤ºä¾‹å›¾åƒ
        """Initialize the IOSDetectModel class with a YOLO model and example image."""  # ä½¿ç”¨ YOLO æ¨¡å‹å’Œç¤ºä¾‹å›¾åƒåˆå§‹åŒ– IOSDetectModel ç±»
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        _, _, h, w = im.shape  # è·å–å›¾åƒçš„å½¢çŠ¶ï¼Œåˆ†åˆ«ä¸º batch, channel, height, width
        self.model = model  # ä¿å­˜ä¼ å…¥çš„ YOLO æ¨¡å‹
        self.nc = len(model.names)  # è·å–ç±»åˆ«æ•°é‡
        if w == h:  # å¦‚æœå®½åº¦å’Œé«˜åº¦ç›¸ç­‰
            self.normalize = 1.0 / w  # è®¾ç½®å½’ä¸€åŒ–å› å­ä¸ºå®½åº¦çš„å€’æ•°ï¼ˆæ ‡é‡ï¼‰
        else:  # å¦‚æœå®½åº¦å’Œé«˜åº¦ä¸ç›¸ç­‰
            self.normalize = torch.tensor([1.0 / w, 1.0 / h, 1.0 / w, 1.0 / h])  # è®¾ç½®å½’ä¸€åŒ–å› å­ä¸ºå¼ é‡ï¼ˆå¹¿æ’­æ–¹å¼ï¼Œè¾ƒæ…¢ï¼Œè¾ƒå°ï¼‰

    def forward(self, x):  # å‰å‘ä¼ æ’­æ–¹æ³•
        """Normalize predictions of object detection model with input size-dependent factors."""  # ä½¿ç”¨è¾“å…¥å¤§å°ç›¸å…³å› å­æ¥å½’ä¸€åŒ–ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„é¢„æµ‹
        xywh, cls = self.model(x)[0].transpose(0, 1).split((4, self.nc), 1)  # è·å–æ¨¡å‹çš„è¾“å‡ºï¼Œå¹¶è¿›è¡Œè½¬ç½®å’Œæ‹†åˆ†
        return cls, xywh * self.normalize  # è¿”å›ç±»åˆ«å’Œå½’ä¸€åŒ–åçš„åæ ‡ï¼ˆç½®ä¿¡åº¦ (3780, 80)ï¼Œåæ ‡ (3780, 4)ï¼‰


class NMSModel(torch.nn.Module):  # å®šä¹‰ NMSModel ç±»ï¼Œç»§æ‰¿è‡ª torch.nn.Module
    """Model wrapper with embedded NMS for Detect, Segment, Pose and OBB."""  # åŒ…å«åµŒå…¥å¼ NMS çš„æ¨¡å‹åŒ…è£…å™¨ï¼Œç”¨äºæ£€æµ‹ã€åˆ†å‰²ã€å§¿æ€å’Œ OBB

    def __init__(self, model, args):  # åˆå§‹åŒ– NMSModel ç±»ï¼Œæ¥å—ä¸€ä¸ªæ¨¡å‹å’Œå‚æ•°
        """
        Initialize the NMSModel.

        Args:
            model (torch.nn.module): The model to wrap with NMS postprocessing.  # è¦åŒ…è£…çš„æ¨¡å‹ï¼Œå¸¦æœ‰ NMS åå¤„ç†
            args (Namespace): The export arguments.  # å¯¼å‡ºå‚æ•°
        """
        super().__init__()  # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        self.model = model  # ä¿å­˜ä¼ å…¥çš„æ¨¡å‹
        self.args = args  # ä¿å­˜ä¼ å…¥çš„å‚æ•°
        self.obb = model.task == "obb"  # æ£€æŸ¥æ¨¡å‹ä»»åŠ¡æ˜¯å¦ä¸º OBB
        self.is_tf = self.args.format in frozenset({"saved_model", "tflite", "tfjs"})  # æ£€æŸ¥æ ¼å¼æ˜¯å¦ä¸º TensorFlow ç›¸å…³æ ¼å¼

    def forward(self, x):  # å‰å‘ä¼ æ’­æ–¹æ³•
        """
        Performs inference with NMS post-processing. Supports Detect, Segment, OBB and Pose.

        Args:
            x (torch.Tensor): The preprocessed tensor with shape (N, 3, H, W).  # é¢„å¤„ç†åçš„å¼ é‡ï¼Œå½¢çŠ¶ä¸º (N, 3, H, W)

        Returns:
            out (torch.Tensor): The post-processed results with shape (N, max_det, 4 + 2 + extra_shape).  # åå¤„ç†ç»“æœï¼Œå½¢çŠ¶ä¸º (N, max_det, 4 + 2 + extra_shape)
        """
        from functools import partial  # å¯¼å…¥ partial å‡½æ•°

        from torchvision.ops import nms  # ä» torchvision å¯¼å…¥ nms å‡½æ•°

        preds = self.model(x)  # æ‰§è¡Œæ¨¡å‹æ¨ç†
        pred = preds[0] if isinstance(preds, tuple) else preds  # è·å–é¢„æµ‹ç»“æœ
        pred = pred.transpose(-1, -2)  # å°†å½¢çŠ¶ä» (1, 84, 6300) è½¬æ¢ä¸º (1, 6300, 84)
        extra_shape = pred.shape[-1] - (4 + len(self.model.names))  # è®¡ç®—é¢å¤–çš„å½¢çŠ¶ï¼Œæ¥è‡ª Segmentã€OBBã€Pose
        boxes, scores, extras = pred.split([4, len(self.model.names), extra_shape], dim=2)  # æ‹†åˆ†é¢„æµ‹ç»“æœä¸ºè¾¹ç•Œæ¡†ã€åˆ†æ•°å’Œé¢å¤–ä¿¡æ¯
        scores, classes = scores.max(dim=-1)  # è·å–æ¯ä¸ªæ¡†çš„æœ€å¤§åˆ†æ•°å’Œå¯¹åº”çš„ç±»åˆ«
        self.args.max_det = min(pred.shape[1], self.args.max_det)  # ç¡®ä¿ max_det ä¸è¶…è¿‡é¢„æµ‹æ•°é‡
        # (N, max_det, 4 coords + 1 class score + 1 class label + extra_shape).
        out = torch.zeros(  # åˆå§‹åŒ–è¾“å‡ºå¼ é‡
            boxes.shape[0],  # N
            self.args.max_det,  # max_det
            boxes.shape[-1] + 2 + extra_shape,  # 4 ä¸ªåæ ‡ + 1 ä¸ªç±»åˆ†æ•° + 1 ä¸ªç±»æ ‡ç­¾ + é¢å¤–å½¢çŠ¶
            device=boxes.device,  # ä½¿ç”¨ç›¸åŒçš„è®¾å¤‡
            dtype=boxes.dtype,  # ä½¿ç”¨ç›¸åŒçš„æ•°æ®ç±»å‹
        )
        for i, (box, cls, score, extra) in enumerate(zip(boxes, classes, scores, extras)):  # éå†æ¯ä¸ªæ¡†ã€ç±»åˆ«ã€åˆ†æ•°å’Œé¢å¤–ä¿¡æ¯
            mask = score > self.args.conf  # åˆ›å»ºæ©ç ï¼Œç­›é€‰å‡ºåˆ†æ•°å¤§äºé˜ˆå€¼çš„æ¡†
            if self.is_tf:  # å¦‚æœæ˜¯ TensorFlow æ ¼å¼
                # TFLite GatherND error if mask is empty
                score *= mask  # å°†åˆ†æ•°ä¹˜ä»¥æ©ç 
                # Explicit length otherwise reshape error, hardcoded to `self.args.max_det * 5`
                mask = score.topk(min(self.args.max_det * 5, score.shape[0])).indices  # è·å–å‰ N ä¸ªåˆ†æ•°çš„ç´¢å¼•
            box, score, cls, extra = box[mask], score[mask], cls[mask], extra[mask]  # æ ¹æ®æ©ç ç­›é€‰æ¡†ã€åˆ†æ•°ã€ç±»åˆ«å’Œé¢å¤–ä¿¡æ¯
            if not self.obb:  # å¦‚æœä¸æ˜¯ OBB
                box = xywh2xyxy(box)  # å°†åæ ‡ä» xywh è½¬æ¢ä¸º xyxy
                if self.is_tf:  # å¦‚æœæ˜¯ TensorFlow æ ¼å¼
                    # TFlite bug returns less boxes
                    box = torch.nn.functional.pad(box, (0, 0, 0, mask.shape[0] - box.shape[0]))  # å¡«å……æ¡†ä»¥åŒ¹é…æœ€å¤§æ•°é‡
            nmsbox = box.clone()  # å…‹éš†æ¡†ä»¥è¿›è¡Œ NMS
            # `8` is the minimum value experimented to get correct NMS results for obb
            multiplier = 8 if self.obb else 1  # è®¾ç½®ä¹˜æ•°ï¼ŒOBB ä½¿ç”¨ 8
            # Normalize boxes for NMS since large values for class offset causes issue with int8 quantization
            if self.args.format == "tflite":  # å¦‚æœæ ¼å¼ä¸º TFLite
                nmsbox *= multiplier  # ä¹˜ä»¥ä¹˜æ•°
            else:
                nmsbox = multiplier * nmsbox / torch.tensor(x.shape[2:], device=box.device, dtype=box.dtype).max()  # å½’ä¸€åŒ–æ¡†
            if not self.args.agnostic_nms:  # å¦‚æœä¸æ˜¯ç±»åˆ«æ— å…³çš„ NMS
                end = 2 if self.obb else 4  # è®¾ç½®ç»“æŸç´¢å¼•
                # fully explicit expansion otherwise reshape error
                # large max_wh causes issues when quantizing
                cls_offset = cls.reshape(-1, 1).expand(nmsbox.shape[0], end)  # æ‰©å±•ç±»åˆ«åç§»é‡
                offbox = nmsbox[:, :end] + cls_offset * multiplier  # è®¡ç®—åç§»æ¡†
                nmsbox = torch.cat((offbox, nmsbox[:, end:]), dim=-1)  # æ‹¼æ¥åç§»æ¡†å’Œ NMS æ¡†
            nms_fn = (  # é€‰æ‹© NMS å‡½æ•°
                partial(
                    nms_rotated,  # ä½¿ç”¨æ—‹è½¬ NMS
                    use_triu=not (
                        self.is_tf
                        or (self.args.opset or 14) < 14
                        or (self.args.format == "openvino" and self.args.int8)  # OpenVINO int8 error with triu
                    ),
                )
                if self.obb  # å¦‚æœæ˜¯ OBB
                else nms  # å¦åˆ™ä½¿ç”¨æ™®é€š NMS
            )
            keep = nms_fn(  # æ‰§è¡Œ NMS
                torch.cat([nmsbox, extra], dim=-1) if self.obb else nmsbox,  # å¦‚æœæ˜¯ OBBï¼Œæ‹¼æ¥é¢å¤–ä¿¡æ¯
                score,  # ä½¿ç”¨åˆ†æ•°
                self.args.iou,  # ä½¿ç”¨ IoU é˜ˆå€¼
            )[: self.args.max_det]  # ä¿ç•™å‰ max_det ä¸ªç»“æœ
            dets = torch.cat(  # æ‹¼æ¥æ£€æµ‹ç»“æœ
                [box[keep], score[keep].view(-1, 1), cls[keep].view(-1, 1).to(out.dtype), extra[keep]], dim=-1
            )
            # Zero-pad to max_det size to avoid reshape error
            pad = (0, 0, 0, self.args.max_det - dets.shape[0])  # è®¡ç®—å¡«å……å¤§å°
            out[i] = torch.nn.functional.pad(dets, pad)  # å¡«å……æ£€æµ‹ç»“æœ
        return (out, preds[1]) if self.model.task == "segment" else out  # å¦‚æœä»»åŠ¡æ˜¯åˆ†å‰²ï¼Œè¿”å› (out, preds[1])ï¼Œå¦åˆ™è¿”å› out